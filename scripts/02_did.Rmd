# (PART\*) Impact analysis {.unnumbered}

# Difference-in-difference

In this script, the treatment effect are computed from the control and treated units defined from the matching process. The treatment effect are first computed at PA level, then aggregated at country, region and world level to obtain average treatement effects.

DESCRIPTION

## Initial settings

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

```{r, eval = FALSE}
#Install some libraries
install.packages(c("tictoc", "fixest", "cobalt", "future", "progressr", "did"))

# Load Libraries
library(dplyr)
library(tictoc) #For timing
library(xtable)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(RColorBrewer)
library(ggrepel)
library(aws.s3)
library(fixest) #For estimating the models
library(did)
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_did.R")
```

```{r, eval = F}
#Saving directories
##Temporary
tmp_did = paste(tempdir(), "did", sep = "/")
##SSPCloud
# save_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/")
load_dir = paste("impact_analysis/matching", "2023-08-29", sep = "/")
save_dir = paste("impact_analysis/did", "2023-08-29", sep = "/")

#Load data 
data_pa = 
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_AFD_ie.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  #Sangha trinational (555547988) created in 2012 actually gathers three former PAs 
  #in CAF (31458), CMR (1245) and COG (72332) implemented in 
  #1990, 2001 and 1993 respectively.
  # Evaluating the trinational PA is not relevant here : our method relies on pre-treatment obervsations (for matching and DiD) and the outcome is likely to be affected by the initial PAs. On the other hand, evaluating the three earlier PAs might be irrelevant for us : are they funded by the AFD ?? In a first approach, the trinational is removed.
  filter(is.na(wdpaid) == TRUE | wdpaid != 555547988)
# 
# list_iso = data_pa %>%
#   filter(region == "Africa") %>%
#   filter(!(iso3 %in% c("ZZ", "GAB")))
# list_iso = unique(list_iso$iso3)

list_iso = c("KEN")

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

```

## Computing treatment effects at PA level

```{r, eval = F}
#For each country in the list, the different steps of the pre-processing are performed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic = tic() #Start timer
#Initialize a dataframe to store annual deforestation rate for each PA
df_fl_annual_wolf = data.frame()
#Initialize a dataframe to store ATT  of all PA analyzed
df_fc_att_m = data.frame() #Effect on forest cover for matched units
df_fc_att_unm = data.frame() #Effect on forest cover for unmacthed units
df_fl_att = data.frame() #Effect on deforestation relative to 2000

for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Load the matching frame
  print("--Loading the list of PAs in the country considered")
  df_pa_i = fn_did_list_pa(iso = i, load_dir = load_dir)
  list_pa_i = df_pa_i$wdpaid
  
  count_j = 0
  max_j = length(list_pa_i)
  
  for(j in list_pa_i)
  {
    
    count_j = count_j+1
    print(paste0("WDPA ID ", j, " : ", count_j, "/", max_j))
    
    #Load the datasets
    # print("--Loading the working datasets")
    # df_j = fn_did_load_df(iso = i,
    #                       wdpaid = j, 
    #                       load_dir = load_dir,
    #                       ext_input = ".csv")
    # 
    # df_wide_m_j = df_j$df_matched_wide
    # df_long_m_j = df_j$df_matched_long
    # df_wide_unm_j = df_j$df_unmatched_wide
    # df_long_unm_j = df_j$df_unmatched_long
    
    #Compute annual deforestation rates in treated and control matched areas
    print("--Compute average deforestation rates Ã  la Wolf et al. 2021")
    df_fl_wolf_m_j = fn_fl_wolf(iso = i, 
                                wdpaid = j, 
                                alpha = 0.05, 
                                load_dir = load_dir,
                                ext_input = ".csv")
    
    df_fl_annual_wolf = rbind(df_fl_annual_wolf, df_fl_wolf_m_j)
    
    #Compute treatment effects
    print("--Compute treatment effects")
    print("----For matched units")
    df_att_m_j = fn_did_att(iso = i, wdpaid = j, 
                          is_m = TRUE,
                      data_pa = data_pa,
                      alpha = 0.05,
                      load_dir = load_dir,
                      ext_input = ".csv",
                      save_dir = save_dir)
    
    df_fc_att_m = rbind(df_fc_att_m, df_att_m_j$df_fc_att)
    df_fl_att = rbind(df_fl_att, df_att_m_j$df_fl_att)
        
    print("----For unmatched units")
    df_att_unm_j = fn_did_att(iso = i, wdpaid = j, 
                          is_m = FALSE,
                      data_pa = data_pa,
                      alpha = 0.05,
                      load_dir = load_dir,
                      ext_input = ".csv",
                      save_dir = save_dir)
    
    df_fc_att_unm = rbind(df_fc_att_unm, df_att_unm_j$df_fc_att)
    df_fl_att_unm = rbind(df_fl_att, df_att_unm_j$df_fl_att)
    
    #Plot visual evidence before-after matching
    print("--Plot visual evidence before-after matching")
    fn_plot_forest_loss(iso = i, 
                        wdpaid = j, 
                        data_pa = data_pa, 
                        load_dir = load_dir, 
                        ext_input = ".csv", 
                        save_dir = save_dir)

  }

  
}

toc = toc()


#Finally ATT are aggregated by region and country
#For total avoided deforestation in ha, ATT are summed and so are CI.
## If the CI of an ATT is NA, then the CI for total ATT is NA also. Otherwise CI will be ## downward biased
#For avoided deforestation in % of 2000 forest cover, ATT are averaged and so are CI
## CI being NA is less a problem here as e use a mean, not a sum
avg_att_fc_ctry_m = df_fc_att_m %>%
  group_by(wdpaid) %>%
  mutate(has_effect = att_pa[time == max(time)] > 0 & sig_95[time == max(time)] == TRUE) %>%
  ungroup() %>%
  group_by(region, iso3, time) %>%
  summarize(n_obs = n(),
            att_per_mean = mean(att_per, na.rm = TRUE),
            cband_lower_per_95 = mean(cband_lower_per_95, na.rm = TRUE),
            cband_upper_per_95 = mean(cband_upper_per_95, na.rm = TRUE),
            att_pa_tot = sum(att_pa, na.rm = TRUE),
            cband_lower_pa_95 = sum(cband_lower_pa_95, na.rm = FALSE),
            cband_upper_pa_95 = sum(cband_upper_pa_95, na.rm = FALSE)) 

avg_att_fc_region_m = df_fc_att_m %>%
  group_by(region, time) %>%
  summarize(n_obs = n(),
            att_per_mean = mean(att_per, na.rm = TRUE),
            cband_lower_per_95 = mean(cband_lower_per_95, na.rm = TRUE),
            cband_upper_per_95 = mean(cband_upper_per_95, na.rm = TRUE),
            att_pa_tot = sum(att_pa, na.rm = TRUE),
            cband_lower_pa_95 = sum(cband_lower_pa_95, na.rm = FALSE),
            cband_upper_pa_95 = sum(cband_upper_pa_95, na.rm = FALSE))

avg_att_fl = df_fl_att %>%
  group_by(region, iso3, time) %>%
  summarize(n_obs = n(),
            att_mean = mean(att, na.rm = TRUE))

avg_fl_annual_wolf = df_fl_annual_wolf
```
