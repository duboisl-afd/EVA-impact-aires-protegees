# (PART\*) Impact analysis {.unnumbered}

# Matching

In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to compute the treatment effect. The treatment here is to be under protected area status, and we look at the impact on deforestation.

The steps are the following

1.  Pre-processing : in a loop for each country

    1.  Create a grid of the country

    2.  Import geospatial data on PAs from the WDPA dataset, and assign each observation unit/pixel to a group : PA funded by the AFD (treated), PA non-funded by the AFD, buffer (closed to but not a PA), other (so potential control).

    3.  Compute the covariates and outcome of interest in all pixels thanks to the mapme.biodiversity package

    4.  Build the matching data frame : each pixel is assigned to a group and has covariates and outcome values.

2.  Post-processing : in a loop for each country

    1.  Load the matching dataframe of the given country

    2.  Perform the matching

    3.  Plot covariate balance and density plots to ensure relevant matching

    4.  Panelize the dataframe

    5.  Perform regressions

## Initial settings

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 

```

```{r eval=, message=FALSE, warning=FALSE}
#Install some libraries
install.packages(c("tictoc", "geodata", "wdpar", "exactextractr", "MatchIt", "fixest", "cobalt", "future", "progressr", "mapme.biodiversity", "future.callr", "janitor"))
#remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")

#Install the web driver to download wdpa data directly
webdriver::install_phantomjs()

# Load Libraries
library(dplyr)
library(janitor)
library(tictoc) #For timing
library(xtable)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(RColorBrewer)
library(ggrepel)
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(rgeos)
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
library(mapme.biodiversity)
library(aws.s3)
library(MatchIt) #For matching
library(fixest) #For estimating the models
library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes
library(future) #For parallel computing in mapme.biodiversity
library(future.callr)
library(progressr) # To display progress bar
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_matching.R")
```

```{r, eval = FALSE}
# Define the path to a temporary, working directory for pre- and post-processing steps
tmp_pre = paste(tempdir(), "matching_pre", sep = "/")
tmp_post = paste(tempdir(), "matching_post", sep = "/")


#####
###Pre-processing
#####

#(Down)load WDPA database
##Download
# wdpa_wld_raw = wdpa_fetch(x = "global", wait = TRUE, download_dir = tmp_pre, page_wait = 2, verbose = TRUE)
# s3write_using(wdpa_wld_raw,
#               sf::st_write,
#               delete_dsn = TRUE,
#               object = paste0("data_raw/wdpa/wdpa_shp_global_raw.gpkg"),
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

##Load
wdpa_wld_raw = s3read_using(
              sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
#gridSize = 10000 
n_sampling = 1000

#Load data 
data_pa = 
  #fread("data_tidy/BDD_nofund_nodupl.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_nofund_nodupl.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) 

#List of countries in the sample
list_iso = "VNM"
#list_iso = unique(data_pa[data_pa$direction_regionale == "Dr Asie Du Sud-Est", ]$iso3)
# Specify a list of WDPA IDs of funded protected areas (treated areas)
# paid = data_stat_nodupl[data_stat_nodupl$iso3 == country,]$wdpaid

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Minimum treatment year
yr_min = yr_first

#####
###Post-processing
#####

# Define Column Names of Covariates
colname.travelTime = "minutes_median_5k_110mio"
colname.clayContent = "clay_0.5cm_mean"
# colname.elevation = "elevation_mean"
# colname.tri = "tri_mean"
colname.fcIni = "treecover_2000"


# Prefix of columns for forest cover
colfc.prefix = "treecover"
# Separation between prefix and year
colfc.bind = "_"
# Prefix of columns for forest loss
colfl.prefix = "treeloss"
#Prefix of columns for average forest loss pre-funding
colname.flAvg = "avgLoss_pre_fund"

```

## Matching process

For pre- and post-processing steps, the different functions are called in a loop (one iteration per country).

### Pre-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the pre-processing are performed
count = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_pre = tic() #Start timer
for (i in list_iso)
{
  #Update counter and display progress
  count = count+1
  print(paste0(i, " : country ", count, "/", max_i))
  
  #Generate observation units
  print("--Generating observation units")
  output_pre_grid = fn_pre_grid(iso = i, 
                                path_tmp = tmp_pre, 
                                data_pa = data_pa,
                                sampling = n_sampling)
  
  #Load the outputs 
  utm_code = output_pre_grid$utm_code
  gadm_prj = output_pre_grid$ctry_shp_prj
  grid = output_pre_grid$grid
  gridSize = output_pre_grid$gridSize
  
  #Determining Group IDs and WDPA IDs for all observation units
  print("--Determining Group IDs and WDPA IDs")
  grid_param = fn_pre_group(iso = i, wdpa_raw = wdpa_wld_raw,
                            yr_min = yr_min,
                            path_tmp = tmp_pre, utm_code = utm_code,
                            buffer_m = buffer_m, data_pa = data_pa,
                            gadm_prj = gadm_prj, grid = grid, 
                            gridSize = gridSize)

  #Calculating outcome and other covariates for all observation units
  print("--Calculating outcome and other covariates")
  tic_parallel = tic()
  fn_pre_mf_parallel(grid.param = grid_param, path_tmp = tmp_pre, iso = i,
          name_output = paste0("matching_frame_spling", n_sampling),
          ext_output = ".gpkg",
          yr_first = yr_first, yr_last = yr_last)
  toc_parallel = toc()
  
  # ##Without parallel computing
  # tic = tic()
  # fn_pre_mf(grid.param = grid_param, path_tmp = tmp_pre, iso = i,
  #           name_output = paste0("matching_frame_spling", n_sampling),
  #           ext_output = ".gpkg",
  #           yr_first = yr_first, yr_last = yr_last)
  # toc = toc()

  tmp_files = list.files(tmp_pre, include.dirs = T, full.names = T, recursive = T)
  file.remove(tmp_files)
  
}

toc_pre = toc() #end timer

```

### Post-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the post-processing are performed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_post = tic() #start timer
for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Load the matching frame
  print("--Loading the matching frame")
  mf_ini = fn_post_load_mf(iso = i, 
                           yr_min = yr_min,
                           name_input = paste0("matching_frame_spling", n_sampling),
                           ext_input = ".gpkg")
  
  list_pa = unique(mf_ini[mf_ini$wdpaid != 0, ]$wdpaid)
  
  #Initialization
  ##Counter
  count_j = 0
  max_j = length(list_pa)
  ##List of control and treatment pixels matched
  df_pix_matched = data.frame()
  
  #Loop over the different PAs
  for (j in list_pa)
  {
    #Update counter and show progress
    count_j = count_j+1
    print(paste0("WDPA ID ", j, " : ", count_j, "/", max_j))
  
    mf_ini_j = mf_ini %>%
      filter(group == 1 | (group == 2 & wdpaid == j))
    
    #Add average pre-loss
    print("--Add covariate : average tree loss pre-funding")
    mf_j = fn_post_avgLoss_prefund(mf = mf_ini_j, colfl.prefix = colfl.prefix)
    
    #Define cut-offs
    print("--Define cutoffs")
    
    #Run Coarsened Exact Matching
    print("--Run CEM")
    lst_cem_res_j = fn_post_match_auto(mf = mf_j, iso = i, 
                                   dummy_int = TRUE,
                                     th_mean = 0.1, 
                                     th_var_min = 0.5, th_var_max = 2)

    out.cem_j = lst_cem_res_j$out.cem
    
    #Plots : covariates
    print("--Some plots : covariates")
    print("----Covariate balance")
    fn_post_covbal(out.cem = out.cem_j,
                   mf = mf_j,
                   colname.travelTime = colname.travelTime, 
                   colname.clayContent = colname.clayContent,
                   colname.fcIni = colname.fcIni, 
                   colname.flAvg = colname.flAvg,
                   iso = i,
                   path_tmp = tmp_post,
                   wdpaid = j)
    print("----Density plots")
    fn_post_plot_density(out.cem = out.cem_j, 
                         mf = mf_j,
                      colname.travelTime = colname.travelTime, 
                       colname.clayContent = colname.clayContent,
                       colname.fcIni = colname.fcIni, 
                       colname.flAvg = colname.flAvg,
                      iso = i,
                      path_tmp = tmp_post,
                      wdpaid = j)
    
    #Panelize dataframes
    print("----Panelize (Un-)Matched Dataframe")
    output_post_panel_j = fn_post_panel(out.cem = out.cem_j, 
                                        mf = mf_j, 
                                        colfc.prefix = colfc.prefix, 
                                        colfc.bind = colfc.bind,
                                        ext_output = ".csv", 
                                        iso = i,
                                        wdpaid = j)
    matched.wide.j = output_post_panel_j$matched.wide
    unmatched.wide.j = output_post_panel_j$unmatched.wide
    matched.long.j = output_post_panel_j$matched.long
    unmatched.long.j = output_post_panel_j$unmatched.long 
    
    #Extract matched units and plot them on a grid
    print("----Extract matched units and plot them on a grid")
    ##Extract ID of treated and control pixels
    df_pix_matched_j = matched.wide.j %>%
      st_drop_geometry() %>%
      as.data.frame() %>%
      dplyr::select(c(group, assetid)) %>%
      rename("group_matched" = "group") 
    df_pix_matched = rbind(df_pix_matched, df_pix_matched_j)
    ##Plot the grid with matched control and treated for the PA
    fn_post_plot_grid(iso = i, wdpaid = j,
                      is_pa = TRUE,
                      df_pix_matched = df_pix_matched_j,
                      path_tmp = tmp_post)
  
    
  
    #Plots : trend
    print("----Plots again : trend")
    fn_post_plot_trend(matched.long = matched.long.j, 
                       unmatched.long = unmatched.long.j, 
                       mf = mf_j,
                       iso = i,
                       wdpaid = j)
  }
  
  # Plot the grid with matched control and treated for the country 
  fn_post_plot_grid(iso = i, wdpaid = j,
                    is_pa = FALSE,
                    df_pix_matched = df_pix_matched,
                    path_tmp = tmp_post)
  
}

toc_post = toc() #end timer

#Notes
## Automate the definition of cutoffs for CEM
### Coder 5.5.3 de Iacus et al. 2012 ? Permet de savoir le gain de matched units pour une modification des seuils d'une variable
## Loop for different treatment years : need to adapt fn_post_avgLoss_prefund function
## Allow to enter a list of any covariates to perform the matching
## Function to plot Fig. 3 in Iacus et al. 2012
## Il faut contrôler le nombre de paired units à la fin ! Typiquement on veut que tous les pixels traités soient retenus, idéalement.
## On veut ATE ou ATT ?? Je dirai ATT car on ne veut pas estimer l'effet de mettre une AP, mais l'effet des AP financés par l'AFD 
```
