# (PART\*) Impact analysis {.unnumbered}

# Matching

In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to compute the treatment effect. The treatment here is to be under protected area status, and we look at the impact on deforestation.

The steps are the following

1.  Pre-processing : in a loop for each country

    1.  Create a grid of the country

    2.  Import geospatial data on PAs from the WDPA dataset, and assign each observation unit/pixel to a group : PA funded by the AFD (treated), PA non-funded by the AFD, buffer (closed to but not a PA), other (so potential control).

    3.  Compute the covariates and outcome of interest in all pixels thanks to the mapme.biodiversity package

    4.  Build the matching data frame : each pixel is assigned to a group and has covariates and outcome values.

2.  Post-processing : in a loop for each country

    1.  Load the matching dataframe of the given country

    2.  Perform the matching

    3.  Plot covariate balance and density plots to ensure relevant matching

    4.  Panelize the dataframe

    5.  Perform regressions

## Initial settings

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 

```

```{r, eval = FALSE}
#Install some libraries
install.packages(c("tictoc", "geodata", "wdpar", "exactextractr", "MatchIt", "fixest", "cobalt", "future", "progressr", "mapme.biodiversity"))
#remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")

#Install the web driver to download wdpa data directly
webdriver::install_phantomjs()

# Load Libraries
library(dplyr)
library(tictoc) #For timing
library(xtable)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(RColorBrewer)
library(ggrepel)
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(rgeos)
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
library(mapme.biodiversity)
library(aws.s3)
library(MatchIt) #For matching
library(fixest) #For estimating the models
library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes
library(future) #For parallel computing in mapme.biodiversity
library(progressr) # To display progress bar
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_matching.R")
```

```{r, eval = FALSE}
# Define the path to a temporary, working directory for pre- and post-processing steps
tmp_pre = paste(tempdir(), "matching_pre", sep = "/")
tmp_post = paste(tempdir(), "matching_post", sep = "/")


#####
###Pre-processing
#####

#(Down)load WDPA database
##Download
#wdpa_wld_raw = wdpa_fetch(x = "global", wait = TRUE, download_dir = tmp_pre, page_wait = 2, verbose = TRUE)
# s3write_using(wdpa_wld_raw,
#               sf::st_write,
#               object = paste0("data_raw/wdpa/wdpa_shp_global_raw.gpkg"),
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

##Load
# wdpa_wld_raw = s3read_using(
#               sf::st_read,
#               object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
#gridSize = 10000 

#Load data 
data_pa = 
  #fread("data_tidy/BDD_DesStat_nofund_nodupl.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_DesStat_nofund_nodupl.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) 

#List of countries in the sample
#list_iso = unique(data_pa$iso3)
list_iso = c("CMR")
# Specify a list of WDPA IDs of funded protected areas (treated areas)
# paid = data_stat_nodupl[data_stat_nodupl$iso3 == country,]$wdpaid

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Minimum treatment year
yr_min = yr_first

#####
###Post-processing
#####

# Define Column Names of Covariates
colname.travelTime = "minutes_median_5k_110mio"
colname.clayContent = "clay_0.5cm_mean"
# colname.elevation = "elevation_mean"
# colname.tri = "tri_mean"
colname.fcIni = "treecover_2000"


# Prefix of columns for forest cover
colfc.prefix = "treecover"
# Separation between prefix and year
colfc.bind = "_"
# Prefix of columns for forest loss
colfl.prefix = "treeloss"
#Prefix of columns for average forest loss pre-funding
colname.flAvg = "avgLoss_pre_fund"

```

## Matching process

For pre- and post-processing steps, the different functions are called in a loop (one iteration per country).

### Pre-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the pre-processing are performed
count = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_pre = tic() #Start timer
for (i in list_iso)
{
  #Update counter and display progress
  count = count+1
  print(paste0(i, " : country ", count, "/", max_i))
  
  #Generate observation units
  print("--Generating observation units")
  output_pre_grid = fn_pre_grid(iso = i, 
                                path_tmp = tmp_pre, 
                                data_pa = data_pa,
                                sampling = 10)
  
  #Load the outputs 
  utm_code = output_pre_grid$utm_code
  gadm_prj = output_pre_grid$ctry_shp_prj
  grid = output_pre_grid$grid
  gridSize = output_pre_grid$gridSize
  
  #Determining Group IDs and WDPA IDs for all observation units
  print("--Determining Group IDs and WDPA IDs")
  grid_param = fn_pre_group(iso = i, wdpa_raw = wdpa_wld_raw,
                            yr_min = yr_min,
                            path_tmp = tmp_pre, utm_code = utm_code,
                            buffer_m = buffer_m, data_pa = data_pa,
                            gadm_prj = gadm_prj, grid = grid, 
                            gridSize = gridSize)

  #Calculating outcome and other covariates for all observation units
  print("--Calculating outcome and other covariates")
  ##Parallel computing : must be activated here and not in a function
  #plan(multisession, workers = availableCores())
  tic_parallel = tic()
  fn_pre_mf_parallel(grid.param = grid_param, path_tmp = tmp_pre, iso = i,
          name_output = "matching_frame_10km", ext_output = ".gpkg",
          yr_first = yr_first, yr_last = yr_last)
  toc_parallel = toc()
  #plan(sequential)
  
  # ##Without parallel computing
  # tic = tic()
  # fn_pre_mf(grid.param = grid_param, path_tmp = tmp_pre, iso = i,
  #           name_output = "matching_frame_10km", ext_output = ".gpkg",
  #           yr_first = yr_first, yr_last = yr_last)
  # toc = toc()

  
  
}

toc_pre = toc() #end timer

```

### Post-processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#For each country in the list, the different steps of the post-processing are performed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_post = tic() #start timer
for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Load the matching frame
  print("--Loading the matching frame")
  mf_ini = fn_post_load_mf(iso = i, 
                           yr_min = yr_min,
                           name_input = "matching_frame_10km",
                           ext_input = ".gpkg")
  
  list_pa = unique(mf_ini[mf_ini$wdpaid != 0, ]$wdpaid)
  
  #Initialization
  ##Counter
  count_j = 0
  max_j = length(list_pa)
  ##List of control and treatment pixels matched
  df_pix_matched = data.frame()
  
  #Loop over the different PAs
  for (j in list_pa)
  {
    #Update counter and show progress
    count_j = count_j+1
    print(paste0("WDPA ID ", j, " : ", count_j, "/", max_j))
  
    mf_ini_j = mf_ini %>%
      filter(group == 0 | (group == 1 & wdpaid == j))
    
    #Add average pre-loss
    print("--Add covariate : average tree loss pre-funding")
    mf_j = fn_post_avgLoss_prefund(mf = mf_ini_j, colfl.prefix = colfl.prefix)
    
    #Define cut-offs
    print("--Define cutoffs")
    ##CAREFUL : ADD elevation and TRI when available
    lst_cutoffs_j = fn_post_cutoff(mf = mf_j, 
                               colname.travelTime = colname.travelTime, 
                               colname.clayContent = colname.clayContent,
                               colname.fcIni = colname.fcIni, 
                               colname.flAvg = colname.flAvg
                               )
    
    #Run Coarsened Exact Matching
    print("--Run CEM")
    out.cem_j = fn_post_cem(mf = mf_j, iso = i, path_tmp = tmp_post,
                        lst_cutoffs = lst_cutoffs_j,
                       colname.travelTime = colname.travelTime, 
                       colname.clayContent = colname.clayContent,
                       colname.fcIni = colname.fcIni, 
                       colname.flAvg = colname.flAvg)
    
    #Plots : covariates
    print("--Some plots : covariates")
    print("----Covariate balance")
    fn_post_covbal(out.cem = out.cem_j, 
                      colname.travelTime = colname.travelTime, 
                       colname.clayContent = colname.clayContent,
                       colname.fcIni = colname.fcIni, 
                       colname.flAvg = colname.flAvg,
                      iso = i,
                      path_tmp = tmp_post,
                      wdpaid = j)
    print("----Density plots")
    fn_post_plot_density(out.cem = out.cem_j, 
                      colname.travelTime = colname.travelTime, 
                       colname.clayContent = colname.clayContent,
                       colname.fcIni = colname.fcIni, 
                       colname.flAvg = colname.flAvg,
                      iso = i,
                      path_tmp = tmp_post,
                      wdpaid = j)
    
    #Panelize dataframes
    print("----Panelize (Un-)Matched Dataframe")
    output_post_panel_j = fn_post_panel(out.cem = out.cem_j, 
                                        mf = mf_j, 
                                        colfc.prefix = colfc.prefix, 
                                        colfc.bind = colfc.bind,
                                        ext_output = ".csv", 
                                        iso = i,
                                        wdpaid = j)
    matched.wide.j = output_post_panel_j$matched.wide
    unmatched.wide.j = output_post_panel_j$unmatched.wide
    matched.long.j = output_post_panel_j$matched.long
    unmatched.long.j = output_post_panel_j$unmatched.long 
    
    #Extract matched units and plot them on a grid
    print("----Extract matched units and plot them on a grid")
    ##Extract ID of treated and control pixels
    df_pix_matched_j = matched.wide.j %>%
      st_drop_geometry() %>%
      as.data.frame() %>%
      dplyr::select(c(group, assetid)) %>%
      rename("group_matched" = "group") 
    df_pix_matched = rbind(df_pix_matched, df_pix_matched_j)
    ##Plot the grid with matched control and treated for the PA
    fn_post_plot_grid(iso = i, wdpaid = j,
                      is_pa = TRUE,
                      df_pix_matched = df_pix_matched_j,
                      path_tmp = tmp_post)
  
    
  
    #Plots : trend
    print("----Plots again : trend")
    fn_post_plot_trend(matched.long = matched.long.j, 
                       unmatched.long = unmatched.long.j, 
                       mf = mf_j,
                       iso = i,
                       wdpaid = j)
  }
  
  # Plot the grid with matched control and treated for the country 
  fn_post_plot_grid(iso = i, wdpaid = j,
                    is_pa = FALSE,
                    df_pix_matched = df_pix_matched,
                    path_tmp = tmp_post)
  
}

toc_post = toc() #end timer

#Notes
## Automate the definition of cutoffs for CEM
### Coder 5.5.3 de Iacus et al. 2012 ? Permet de savoir le gain de matched units pour une modification des seuils d'une variable
## Loop for different treatment years : need to adapt fn_post_avgLoss_prefund function
## Allow to enter a list of any covariates to perform the matching
## Function to plot Fig. 3 in Iacus et al. 2012
## Il faut contrôler le nombre de paired units à la fin ! Typiquement on veut que tous les pixels traités soient retenus, idéalement.
## On veut ATE ou ATT ?? Je dirai ATT car on ne veut pas estimer l'effet de mettre une AP, mais l'effet des AP financés par l'AFD 
```

### TEST FOR PARALLEL COMPUTING

#### One indicator

```{r} aoi = init_portfolio(grid_param,                       years = yr_first:yr_last,                       outdir = tmp_pre,                       #cores = 12,                       add_resources = FALSE)      ##Non-parallel  tic_np1 = tic()  get.soil_np1 = get_resources(aoi,                         resources = c("soilgrids"),                         layers = c("clay"), # resource specific argument                         depths = c("0-5cm"), # resource specific argument                         stats = c("mean")) %>%  calc_indicators(.,                  indicators = "soilproperties",                  stats_soil = c("mean"),                  engine = "zonal") %>%  unnest(soilproperties) %>%  mutate(across(mean, round, 3)) %>% # Round numeric columns  pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean")  toc_np1 = toc()  #Parallel    plan(multisession, workers = availableCores()) # set up parallel plan with 6 concurrent threads    tic_p1 = tic()    dl.soil_p1 = get_resources(aoi,                           resources = c("soilgrids"),                           layers = c("clay"), # resource specific argument                           depths = c("0-5cm"), # resource specific argument                           stats = c("mean"))  with_progress({  calc.soil_p1 %<-% calc_indicators(dl.soil_p1,                                    indicators = "soilproperties",                                    stats_soil = c("mean"),                                    engine = "zonal"  )  })  get.soil_p1 = unnest(calc.soil_p1, soilproperties) %>%    mutate(across(mean, round, 3)) %>% # Round numeric columns    pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean")  toc_p1 = toc()  plan(sequential) # close child processes}
```

#### Two indicators

```{r} aoi = init_portfolio(grid_param,                       years = yr_first:yr_last,                       outdir = tmp_pre,                       add_resources = FALSE)      ##Non-parallel  tic_np2 = tic()  get.soil_np2 = get_resources(aoi,                         resources = c("soilgrids"),                         layers = c("clay"), # resource specific argument                         depths = c("0-5cm"), # resource specific argument                         stats = c("mean")) %>%  calc_indicators(.,                  indicators = "soilproperties",                  stats_soil = c("mean"),                  engine = "zonal") %>%  unnest(soilproperties) %>%  mutate(across(mean, round, 3)) %>% # Round numeric columns  pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean")  get.travelT_np2 = get_resources(aoi, resources = "nelson_et_al",                              range_traveltime = c("5k_110mio")) %>% # resource specific argument    calc_indicators(.,                     indicators = "traveltime",                    stats_accessibility = c("median")) %>%    unnest(traveltime) %>%    pivot_wider(names_from = "distance", values_from = "minutes_median", names_prefix = "minutes_median_")  toc_np2 = toc()  #Parallel    plan(multisession, workers = availableCores()) # set up parallel plan with 6 concurrent threads    tic_p2 = tic()    #Download    dl.soil_p2 = get_resources(aoi,                           resources = c("soilgrids"),                           layers = c("clay"), # resource specific argument                           depths = c("0-5cm"), # resource specific argument                           stats = c("mean"))    dl.travelT_p2 = get_resources(aoi, resources = "nelson_et_al",                              range_traveltime = c("5k_110mio"))        #Compute indicators  with_progress({  calc.soil_p2 %<-% calc_indicators(dl.soil_p2,                                    indicators = "soilproperties",                                    stats_soil = c("mean"),                                    engine = "zonal"                                    )      calc.travelT_p2 %<-% calc_indicators(dl.travelT_p2,                 indicators = "traveltime",                stats_accessibility = c("median")                )      })    #Compute dataframe  get.soil_p2 = unnest(calc.soil_p2, soilproperties) %>%    mutate(across(mean, round, 3)) %>% # Round numeric columns    pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean")  get.travelT_p2 = unnest(calc.travelT_p2, traveltime) %>%    pivot_wider(names_from = "distance", values_from = "minutes_median", names_prefix = "minutes_median_")  toc_p2 = toc()  plan(sequential) # close child processes}
```

#### Three indicators

```{r}  aoi = init_portfolio(grid_param,                      years = yr_first:yr_last,                      outdir = tmp_pre,                      add_resources = FALSE)  ##Non-parallel  tic_np3 = tic()  get.soil_np3 = get_resources(aoi,                        resources = c("soilgrids"),                        layers = c("clay"), # resource specific argument                        depths = c("0-5cm"), # resource specific argument                        stats = c("mean")) %>% calc_indicators(.,                 indicators = "soilproperties",                 stats_soil = c("mean"),                 engine = "zonal") %>% unnest(soilproperties) %>% mutate(across(mean, round, 3)) %>% # Round numeric columns pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean")  get.travelT_np3 = get_resources(aoi, resources = "nelson_et_al",                             range_traveltime = c("5k_110mio")) %>% # resource specific argument   calc_indicators(.,                    indicators = "traveltime",                   stats_accessibility = c("median")) %>%   unnest(traveltime) %>%   pivot_wider(names_from = "distance", values_from = "minutes_median", names_prefix = "minutes_median_")  get.tree_np3 = get_resources(aoi, resources = c("gfw_treecover", "gfw_lossyear")) %>%   calc_indicators(.,                   indicators = "treecover_area",                    min_size=1, # indicator-specific argument                  min_cover=10) %>% # indicator-specific argument   unnest(treecover_area) %>%   mutate(across(treecover, round, 3)) %>% # Round numeric columns   pivot_wider(names_from = "years", values_from = "treecover", names_prefix = "treecover_")  toc_np3 = toc()  #Parallel   toc_p3 = toc()}
```

### 
