# Building the datasets

## Importing relevant packages

```{r setup, include = FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r message=TRUE, warning=TRUE, eval = FALSE}
library(tidyverse)
library(stargazer)
library(dplyr)
library(data.table)
library(readxl)
library(splitstackshape) 
library(janitor)
library(stringi)
library(sf)
library(mapview)
library(wdpar)

#Install webdriver to download WDPA data
webdriver::install_phantomjs()

```

This script builds the different datasets for the analysis. Data on PAs funded by the AFD are combined with the WDPA. A confidential dataset is created to perform descriptive statistics on fundings. Also, datasets on PAs aggregated size at country and regional level are created.

Note that the raw dataset is not made publicly available, as it contains confidential data. Apart from the dataset on funding, all datasets created here can be provided upon request.

## Datasets for analysis

The datasets are built from the raw BDD_joint.xlsx file. The latter comes from the merging of AFD project data (SIOP), and information on PAs reported ARB and covering 2000-2017 period. Information on the PAs is also found on the WDPA database (polygon, year of implementation, IUCN category, etc.). Majority of PAs reported by ARB had no WDPA ID, so it was found and reported manually on WDPA website.

Different datasets are built. First a dataset (data_PA_tidy) enriched of information on co-investors and ISO codes for the countries hosting the PA.

From this dataset are extracted : (1) a dataset with only project related variables from the AFD, to facilitate merging with datasets other than WDPA; (2) a dataset to perform most analysis, except confidential statistics related to funding; (3) a confidential dataset with funding data.

Then a dataset of PAs polygons is imported from the WDPA, and confidential data are also removed.

### Cleaning the raw dataset

```{r, eval = FALSE}
#import a dataset with country names and corresponding ISO3 code
data_iso = fread("data_raw/liste-197-etats-2020.csv") %>%
  rename("iso3" = "CODE",
         "nom_alpha" = "NOM_ALPHA") %>%
  dplyr::select(c("nom_alpha", "iso3")) %>%
  #get rid of accentuations and change name by hand to correspond with BDD_joint
  mutate(nom_alpha2 = iconv(nom_alpha, to = "ASCII//TRANSLIT"),
         nom_alpha2 = case_when(
           nom_alpha2 == "Cook (Iles)" ~ "Cook",
           nom_alpha2 == "Cote d'Ivoire" ~ "Cote D Ivoire",
           nom_alpha2 == "Sao Tome-et-Principe" ~ "Sao Tome",
           nom_alpha2 == "Palaos" ~ "Palau",
           nom_alpha2 == "Guinee-Bissao" ~ "Guinee-Bissau",
           !(nom_alpha %in% c("Cook (Iles)", "Cote d'Ivoire", "Sao Tome-et-Principe",
                              "Palaos", "Guinée-Bissao")) ~ nom_alpha2
         ))

#Import the manually reported dataset
data_pa = read_excel("data_raw/BDD_PA_AFD.xlsx") %>%
  as.data.frame() %>%
  rename("wdpaid" = "ID_WDPA",
         "name_pa" = "Nom de l'aire protégée") %>%
  clean_names() %>%
  # Change encoding of characters
  mutate(across(.cols = names(.),
                .fns = ~stri_enc_toutf8(.x))) %>%
  # Convert WDPAID to numeric, with NA values for unknown WDPAID
  mutate(wdpaid = case_when(wdpaid %in% c("NA", "") ~ NA,
                          TRUE ~ wdpaid)) %>%
  mutate(wdpaid = as.numeric(wdpaid)) 

#Import SIOP extract
#/!\ Attention need a more recent verison
data_siop = read_excel("data_raw/AP_BO_2000-2017_V3.xlsx") %>%
  clean_names() %>%
  rename("id_projet" = "idprojet") %>%
  select(c(id_projet, id_concours, 
           montant_prevu_concours_euro_octroi, 
           mt_global_projet_prevu_devise, 
           engagements_nets_euro_octroi, 
           montant_total_projet, 
           produit, libelle_produit, 
           cofinancier,
           division_technique, 
           agence, libelle_agence, 
           date_octroi, annee_octroi,
           pays_de_realisation, direction_regionale))

#Import WDPA data
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)
data_wdpa = st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg")

#Merge the datasets
data_raw = data_pa %>%
  #Add the ISO3 code corresponding to the country hosting the PA.             #Facilitate future mergings
  left_join(data_iso, by = c("pays" = "nom_alpha2")) %>%
  #Add information from WDPA to PAs funded and with WDPAID
  left_join(data_wdpa, by = "wdpaid") %>%
  #Add information from SIOP
  left_join(data_siop, by = c("id_projet", "id_concours"))
```

### Tidy the datasets

```{r}
#Pivot along cofinancier

data_tidy = data_raw %>%
  #Pivot on "cofinancier" so information on co-funders is on different        #columns, not rows
  pivot_wider(names_from = "Cofinancier", values_from ="cofinancier") %>%
  #Create dummy variables for main investors
  #AFD is always funder, so no need of a dummy. 
  mutate(kfw_bin = ifelse(cofinancier_1 == "KFW" | cofinancier_2 == "KFW" 
                          | cofinancier_3 == "KFW" |cofinancier_4 == "KFW" 
                          | cofinancier_5 == "KFW" | cofinancier_6 == "KFW",
                          yes = TRUE, 
                          no = FALSE),
         kfw_bin = ifelse(is.na(kfw_bin), yes = FALSE, no = kfw_bin),
         ffem_bin = ifelse(cofinancier_1 == "FFEM"|cofinancier_2 == "FFEM"
                           |cofinancier_3 == "FFEM"|cofinancier_4 == "FFEM"
                           |cofinancier_5 == "FFEM"|cofinancier_6 == "FFEM"
                           ,
                          yes = TRUE, 
                          no = FALSE),
         ffem_bin = ifelse(is.na(ffem_bin), yes = FALSE, no = ffem_bin),
         .after = "cofinancier_6") %>%
  #Nouvelle-Calédonie is divided in two provinces : north and south. 
  #This subdivision is irrelevant in our analysis so we keep 
  #only "Nouvelle Caledonie"
  mutate(pays = case_when(pays %in% c("P-N N.Caléd", "P-S N.Caléd", "Nlle Caledonie") ~ "Nouvelle-Caledonie",
         TRUE ~ pays)) %>%
  #Some entries in "pays" are French department, DROM-COM, "Ocean Indien" or   #"Multi-Pays".
  #French related : the ISO3 code 
  #Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP dataset
  mutate(iso3 = case_when(
    pays == "Mayotte" ~ "MYT",
    pays == "Nouvelle-Caledonie" ~ "NCL",
    pays == "Polynesie Francaise" ~ "PYF",
    pays %in% c("Multi-Pays", "Ocean Indien") ~ "ZZ",
    !(pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie", "Multi-Pays")) ~ iso3
  )) %>%
  #Add the description of IUCN from its category
    mutate(iucn_des = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
  #Keep only year in "annee_octroi"
  mutate(annee_octroi = year(annee_octroi)) %>%
    #Modify class of some variables
  mutate(across(.cols = c("wdpaid", "superficie",
                          "montant_prevu_concours_euro_octroi",
                          "mt_global_projet_prevu_devise" ,
                          "engagements_nets_euro_octroi",
                          "montant_total_projet"),
                .fns = ~as.numeric(.x))) %>%
  mutate(across(.cols = -c("wdpaid", "superficie",
                                  "montant_prevu_concours_euro_octroi",
                          "mt_global_projet_prevu_devise" ,
                          "engagements_nets_euro_octroi",
                          "montant_total_projet"), 
                .fns = ~stri_enc_toutf8(.x))) 




```

### Correct errors

```{r}
#Modify errors in the dataset
##WDPAID 797 in Senegal : the ID project corresponds to APAC de Kawawana in Senegal, with no WDPAID
data_raw[data_raw$wdpaid == "797" & data_raw$id_projet == "CZZ3056",]$name_pa = "APAC de Kawawana"
data_raw[data_raw$wdpaid == "797" & data_raw$id_projet == "CZZ3056",]$wdpaid = NA
##4223, 4224, 4226, 4228, 4229 : all in PS-N.Caledonie
data_raw[data_raw$wdpaid %in% c("4223", "4224", "4226", "4228", "4229") & data_raw$pays == "Fidji",]$pays = "P-S N.Caléd"
##305082 : Vanuatu instead of Fidji
data_raw[data_raw$wdpaid %in% c("305082") & data_raw$pays == "Fidji",]$pays = "Vanuatu"
##31459 : Central African Republic instead of Cameroon. /!\ Vérifier le nom : anglais ou français ??
data_raw[data_raw$wdpaid %in% c("31459") & data_raw$pays == "Cameroun",]$pays = "Centrafrique"
##Rio Grande de Buba : Guinee Bissau instead of Gambia
data_raw[data_raw$wdpaid %in% c("317051") & data_raw$pays == "Gambie",]$pays = "Guinee-Bissau"
##WDPAID 20267 : in GNQ instead of GIN
data_raw[data_raw$wdpaid %in% c("20267") ,]$pays = "Guinee-Equatoriale"
data_raw[data_raw$wdpaid %in% c("20267") ,]$iso3 = "GNQ"

#Create a clean dataset with relevant variables
data_PA_tidy = data_raw %>%
  #Get rid of the iso code in the initial dataset, to avoid confusion when merging with data_iso
  dplyr::select(-iso3) %>%
  #Create dummy variables for main investors
  #AFD is always funder, so no need of a dummy. 
  mutate(kfw_bin = ifelse(cofinancier_1 == "KFW" | cofinancier_2 == "KFW" | cofinancier_3 == "KFW" |
                          cofinancier_4 == "KFW" | cofinancier_5 == "KFW" | cofinancier_6 == "KFW",
                          yes = TRUE, 
                          no = FALSE),
         kfw_bin = ifelse(is.na(kfw_bin), yes = FALSE, no = kfw_bin),
         ffem_bin = ifelse(cofinancier_1 == "FFEM" | cofinancier_2 == "FFEM" | cofinancier_3 == "FFEM" |
                          cofinancier_4 == "FFEM" | cofinancier_5 == "FFEM" | cofinancier_6 == "FFEM",
                          yes = TRUE, 
                          no = FALSE),
         ffem_bin = ifelse(is.na(ffem_bin), yes = FALSE, no = ffem_bin),
         .after = "cofinancier_6") %>%
  #Add the ISO3 code corresponding to the country hosting the PA. Facilitate future mergings
  left_join(data_iso, by = c("pays" = "nom_alpha2")) %>%
  # Nouvelle-Calédonie is divided in two provinces : north and south. This subdivision is irrelevant in our analysis so we keep only "Nouvelle Caledonie"
  mutate(pays = case_when(pays %in% c("P-N N.Caléd", "P-S N.Caléd", "Nlle Caledonie") ~ "Nouvelle-Caledonie",
         TRUE ~ pays)) %>%
  #Some entries in "pays" are French department, DROM-COM, "Ocean Indien" or "Multi-Pays".
  #French related : the ISO3 code 
  #Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP dataset
  mutate(iso3 = case_when(
    pays == "Mayotte" ~ "MYT",
    pays == "Nouvelle-Caledonie" ~ "NCL",
    pays == "Polynesie Francaise" ~ "PYF",
    pays %in% c("Multi-Pays", "Ocean Indien") ~ "ZZ",
    !(pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie", "Multi-Pays")) ~ iso3
  )) %>%
  #Add the description of IUCN from its category
    mutate(iucn_des = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
    #Modify class of some variables
  mutate(across(.cols = c("wdpaid", "superficie",
                          "montant_prevu_concours_euro_octroi",
                          "mt_global_projet_prevu_devise" ,
                          "engagements_nets_euro_octroi",
                          "montant_total_projet"),
                .fns = ~as.numeric(.x))) %>%
    mutate(across(.cols = -c("wdpaid", "superficie",
                                  "montant_prevu_concours_euro_octroi",
                          "mt_global_projet_prevu_devise" ,
                          "engagements_nets_euro_octroi",
                          "montant_total_projet"), 
                .fns = ~stri_enc_toutf8(.x))) 
#fwrite(data_PA_tidy, "data_tidy/BDD_joint_tidy.csv")

```

### Dataset with only SIOP variables

```{r, eval = FALSE}
#Select info corresponding to SIOP extract and AP 
list_var_siop_AP = c( "id_projet", "nom_du_projet", "nom_de_projet_pour_les_instances",
                      "id_concours", "libelle_du_concours", "description_du_projet",
                      "wdpaid", "wdpaid_2", "wdpaid_3",
                      "montant_prevu_concours_euro_octroi", "mt_global_projet_prevu_devise", 
                      "engagements_nets_euro_octroi", "montant_total_projet", "produit", 
                      "libelle_produit", "division_technique", "libelle_division_technique", "agence", 
                      "libelle_agence", "annee_octroi", "date_octroi",
                      "date_de_1er_versement_projet", "dernier_versement_en_date_projet", 
                      "date_signature_convention_cf", "duree_du_concours_annee",
                      "duree_du_concours_annee_et_mois", "id_pays_de_realisation", "pays", "iso3",
                      "direction_regionale", "autres_pays_de_realisation", 
                      "etat_du_projet", "libelle_etat_du_projet", "beneficiaire_primaire",
                      "responsable_equipe_projet", "directeur_trice_dagence",
                      "date_de_remise_du_rapport_final", "cofinancier_1", "cofinancier_2", 
                      "cofinancier_3","cofinancier_4", "cofinancier_5", "cofinancier_6",
                      "kfw_bin", "ffem_bin",
                      "maitrise_ouvrage", "superf_interne", "nb_ap_nombre_potentiel", "detail", "projet", "commentaires")

#Definining dataset for future work with dataset other than WDPA 
data_siop_tidy = data_tidy %>%
  dplyr::select(all_of(list_var_siop_AP), iso3)
#write_csv(data_siop_tidy, "data_tidy/BDD_siop_tidy.xlsx")

```

### Dataset for non-confidential analysis

To perform analysis we want to keep one row per PA, characterized by WDPA ID or a name (if no ID reported). Some PAs can have several lines if they receive funds at different time or by different investors.

```{r, eval = FALSE}

#Listing relevant variables for analysis that are NOT confidential (i.e not concern funding)
list_var_PA_nofund = 
  c("id_projet", "nom_du_projet", "name_pa", "id_concours", 
    "wdpaid", 
    "pays", "iso3", "direction_regionale",
    "annee_octroi", "nb_ap_nombre_potentiel", "detail",
    "iucn_cat", "iucn_des", "marine", "superficie",
    "status", "status_yr", "gov_type","own_type", "mang_auth")

#Defining dataset for descriptive statistics
data_nofund = data_tidy %>%
  select(all_of(list_var_PA_nofund), iso3)

#fwrite(data_nofund, "data_tidy/BDD_nofund.csv")

#Then to keep only one row per PA, we need to consider separately PAs having WDPA ID and PAs which do not.
## Observations with WDPAID
data_nofund_wdpa = data_nofund %>%
  subset(is.na(wdpaid) == FALSE) %>%
  group_by(wdpaid) %>% 
  #Keep the earlier annee_octroi (year of the first funding)
  arrange(annee_octroi) %>%
  #Keep only one observation for rows with same WDPAID
  slice(1) %>%
  ungroup()

#Observations without WDPAID
data_nofund_na = data_nofund %>%
  subset(is.na(wdpaid) == TRUE) %>%
  #Create a unique key for a PA : project ID from AFD, country (ISO code) and PA name
  mutate(id1 = paste(id_projet, iso3, name_pa, sep = "_"),
       .before = id_projet) %>%
  group_by(id1) %>%
  #Keep the earlier year of funding
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup() %>%
  #remove id1 variable, to bind data_stat_na and data_stat_wdpa by row
  select(-id1)

#Finally bind both datasets
data_nofund_nodupl = rbind(data_nofund_wdpa, data_nofund_na) 

#fwrite(data_nofund_nodupl, "data_tidy/BDD_nofund_nodupl.csv")
```

### Dataset for confidential analysis

Variables related to the funding are removed.

```{r, eval = FALSE}

#Listing relevant variables for descriptive statistics
list_var_PA_fund = c("id_projet", "nom_du_projet", "name_pa", "id_concours", 
                "wdpaid",
                "pays", "iso3", "direction_regionale",
                "montant_prevu_concours_euro_octroi",
                "mt_global_projet_prevu_devise",
                "engagements_nets_euro_octroi",
                "montant_total_projet", "libelle_produit", "annee_octroi",
                "cofinancier_1", "cofinancier_2", "cofinancier_3", 
                "cofinancier_4", "cofinancier_5", "cofinancier_6",
                 "kfw_bin", "ffem_bin")

#Defining dataset for descriptive statistics
#Duplicates are not revmoved here, as we want the information on the different concours for instance. Peculiar datasets 
data_fund = data_PA_tidy %>%
  select(all_of(list_var_PA_fund), iso3)

#fwrite(data_fund, "data_tidy/BDD_fund.csv")
```

### A polygon dataset without confidential information

Removing confidential variables from the polygon dataset. This is temporary code, as in the future we will download information from WDPA through the WDPA package, and extract the WDPA ID of interest. No confidential data will then be contained in the polygon datasets.

```{r, eval = FALSE}
#The confidential information removed concern funding or nominative variables
pa_shp = read_sf("data_raw/WDPA_SHP/BDD_SHP_nodupl.shp") %>%
  clean_names() %>%
  select(-c(mntnt, mtglb, e, mnt, prodt, lbllp, dt_ct, d_1, d, d_c, durdcncrs_a, drdcncrs_an, atrsp, ett, lbllt, rspns, dr, mtrs, detal, projt, cmmnt, cmmnt_1))

# st_write(pa_shp,
#          dsn = "data_tidy/BDD_shp_pub.gpkg",
#          delete_dsn = TRUE)

rm(pa_shp)
```

## Computing total areas covered by PAs in the sample

Knowing the total area covered by PAs at different level of aggregation is interesting per se. It is also necessary to compute several statistics (e.g average funding by unit of area). According to the WDPA documentation, it is likely that some reported polygons overlap. Simply summing the areas would thus lead to a biased estimate of the total area at a given level of aggregation. We follow the procedure of the WDPA (<https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage>). Our case is simpler as all of the PAs we consider are given a polygon.

1.  The layer is converted to Mollweide (an equal area projection) and the area of each polygon is calculated, in km2.

2.  Intersection of polygons and the corresponding area are computed.

3.  Then the intersection can be aggregated at country, region or world level. Then it is subtracted to the sum of areas at country, region or world level. Note that intersections between PAs whose polygon is unknown won't be taken into account.

Note that the following codes are about computing total area at country/region/world level, taking potential intersections into account. It is not about generating a new shape files for the impact analysis. Indeed the overlap should be taken into account in the impact evaluation analysis codes.

### Computations of polygons' area

```{r, eval = FALSE}

#Importing shapefiles
sf_use_s2(FALSE)
pa_shp = 
  read_sf("data_tidy/BDD_shp_pub.gpkg") %>%
  # aws.s3::s3read_using(
  # FUN = sf::read_sf,
  # # Mettre les options de FUN ici
  # object = "data_tidy/BDD_SHP_nodupl_pub.gpkg",
  # bucket = "projet-afd-eva-ap",
  # opts = list("region" = "")) %>%
  #Ensure all geometries are valid
  st_make_valid() %>%
  #From multipolygon to polygon
  sf::st_cast(to="POLYGON") %>%
  clean_names() %>%
  #Select relevant variables
  #Note ann_c = annee_octroi in the initial database data_raw
  dplyr::select(c(wdpaid, sprfc, rep_a, gis_a, geom, iso3, drct, ann_c)) %>%
  #Variable sprfc corresponds to AFD internal reported size
  rename("sprfc_int" = "sprfc") %>%
  mutate(wdpaid = as.numeric(wdpaid),
         sprfc_int = as.numeric(sprfc_int)) 

#Spatial definition of wdpaid 555547988 overlaps CMR and CAF. Wdpaid 1245 corresponds to the CMR part. The overlap is removed and iso3 redefined so that 555547988 is CAF only. 
geom_555547988_1245 = st_difference(pa_shp[pa_shp$wdpaid == 555547988,]$geom, pa_shp[pa_shp$wdpaid == 1245,]$geom)
pa_shp[pa_shp$wdpaid == 555547988,]$geom = geom_555547988_1245
pa_shp[pa_shp$wdpaid == 555547988,]$iso3 = "CAF"

#Define a tidy version of the former dataset, with modifications on wdpaid 555547988
pa_shp_tidy = pa_shp %>%
  #Project to Mollweide to compute relevant areas in km2
  st_transform(crs = "+proj=moll +datum=WGS84") %>%
  #Compute areas in km2 from the geometry, in km2. It must be equal to gis_a by definition 
  #Then to take into account potential refinements of the geometries (as for wdpaid 55547988), a variable for relevant area is defined. It takes rep_a value except for modified geometries where area_sf_moll is taken
  mutate(area_sf_moll = as.numeric(st_area(geom)/1e6),
         sprfc_km2 = ifelse(wdpaid == 555547988, yes = area_sf_moll, no = rep_a))
```

### Computing the intersection at country, region, world level

```{r, eval = FALSE}

#Compute intersecting areas of polygons
pa_int = st_intersection(pa_shp_tidy, pa_shp_tidy) %>%
  #Remove intersection of polygons with themselves
  subset(wdpaid != wdpaid.1) %>%
  #If one of the two intersectin polygon have unknwon area, then it is not necessary to subtract the interesction area. Indeed there is no double-counting of the intersection in this case, when both polygon areas are summed.
  subset(is.na(sprfc_km2) == FALSE & is.na(sprfc_km2.1) == FALSE) %>%
  #Compute the intersecting areas (pa_shp already in Mollweide projection) in km2
  mutate(area_int = as.numeric(st_area(geom)/1e6)) %>%
  #Now duplicates need to be removed : intersection of X with Y AND intersection of Y with X are reported. We need only one.
  #An id_int to identify the intersection of a given pair
  mutate(id_int = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  mutate(id_int_temp = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  #create a mirror idX_idY --> idY_idX so that we identify the both member of a pair with the same id
  separate(id_int_temp, into = c("id_temp1", "id_temp2"), sep = "_") %>%
  mutate(id_int_rev = case_when(
    id_temp1 < id_temp2 ~ paste(id_temp1, id_temp2, sep = "_"),
    id_temp1 > id_temp2 ~ paste(id_temp2, id_temp1, sep = "_"),
    TRUE ~ paste(id_temp1, id_temp2, sep = "_")),
    .after = id_int) %>%
  #finally, get rid of the duplicates (have the same id_int_rev)
  group_by(id_int_rev) %>%
  slice(1) %>%
  ungroup() %>%
  #select relevant variables only
  select(wdpaid, iso3, drct, ann_c, wdpaid.1, iso3.1, drct.1, ann_c.1, geom, area_int)

#Computing the total area of intersections
#At country level ...
pa_int_ctry = pa_int %>%
  #Only overlapping PAs in the same country are considered
  subset(iso3 ==  iso3.1) %>%
  group_by(iso3) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

#At region level
pa_int_dr = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(drct == drct.1) %>%
  group_by(drct) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

##At world level : all overlap are considered
pa_int_wld = sum(pa_int$area_int) 

#Compute the total intersection for each year
pa_int_yr = pa_int %>%
  #Define intersection year : the date ann_c of the later PA in the pair
  rowwise() %>%
  mutate(annee_int = max(ann_c, ann_c.1)) %>% 
  group_by(annee_int) %>%
  summarize(tot_int_km2 = sum(area_int)) %>%
  st_drop_geometry()

# fwrite(pa_int_yr,
#        "data_tidy/area/pa_int_yr.csv")
```

### Computing total areas without intersection

```{r, eval = FALSE}
#At country level ...
pa_area_ctry = data_nofund_nodupl %>%
  #Compute total area at country level
  group_by(iso3) %>%
  summarize(sprfc_tot_km2 = sum(superficie)) %>%
  ungroup() %>%
  #Add information on intersection area in each country. Modify the variable so that NA value -> 0
  left_join(pa_int_ctry, by = "iso3") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~ 0, TRUE ~ tot_area_int)) %>%
  #Compute the total area at country level without intersection
  mutate(sprfc_tot_noint_km2 = sprfc_tot_km2 - tot_area_int) 

#fwrite(pa_area_ctry, "data_tidy/area/pa_area_ctry.csv")

#At DR level ...
pa_area_dr = data_nofund_nodupl %>%
  #Compute total area at dr level
  group_by(direction_regionale) %>%
  summarize(sprfc_tot_km2 = sum(superficie)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_dr, by = c("direction_regionale" = "drct")) %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
  mutate(sprfc_tot_noint_km2 = sprfc_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")

#At world level
pa_area_wld = sum(data_nofund_nodupl$superficie) - pa_int_wld %>%
  as.data.frame() %>%
  rename("sprfc_tot_noint_km2" = ".")
#fwrite(pa_area_wld, "data_tidy/area/pa_area_wld.csv")

```

## Old code

```{r, eval = FALSE}
#Listing variables public or confidential

#Public variables in the PAs dataset
list_var_PA_open = c("id_projet", "nom_du_projet", "name_pa", "id_concours", 
                "wdpaid", "wdpaid_2", "wdpaid_3", "wdpa_pid",
                "pays", "iso3", "direction_regionale", "annee_octroi",
                "cofinancier_1", "cofinancier_2", "cofinancier_3", 
                "cofinancier_4", "cofinancier_5", "cofinancier_6",
                "kfw_bin", "ffem_bin", "nb_ap_nombre_potentiel", "detail",
                "iucn_cat", "iucn_des", "marine", "superficie",
                "status", "status_yr", "gov_type","own_type", "mang_auth")
#Confidential variables in the PAs dataset
list_var_PA_conf = list_var_joint_conf = 
  c("montant_prevu_concours_euro_octroi", "mt_global_projet_prevu_devise",
    "engagements_nets_euro_octroi" , "montant_total_projet",
    "produit", "libelle_produit",
    "date_de_1er_versement_projet", "dernier_versement_en_date_projet",
    "date_signature_convention_cf", "duree_du_concours_annee",
    "duree_du_concours_annee_et_mois", "beneficiaire_primaire",
    "responsable_equipe_projet", "directeur_trice_dagence", "maitrise_ouvrage"
    )
#Confidential variables among shapefiles
list_var_shp_conf = c("mntnt", "mtglb", "e", "mnt", "prodt", "lbllp",
                      "rspns", "dr", "detal", "projt", "cmmnt")
```

```{r, eval = FALSE}
base_nodupl_lea = 
  #fread("data_tidy/base_nodupl_lea.xlsx")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_DesStat_nodupl_lea_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  select(any_of(names(data_stat_nodupl)))
  
#import a dataset with country anmes and corresponding ISO3 code
data_iso = data_stat %>%
  select(c(pays, iso3)) %>%
  group_by(iso3) %>%
  slice(1)

base_nodupl_old = 
  #fread("data_tidy/base_nodupl_old.csv") 
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_DesStat_nodupl_old_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))%>%
  select(any_of(names(data_stat_nodupl))) %>%
  select(-iso3) %>%
  left_join(data_iso, by = "pays") %>%
  mutate(iso3 = case_when(
    pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie") ~ "FRA",
    pays == "Multi-Pays" ~ "ZZ",
    !(pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie", "Multi-Pays")) ~ iso3
  ))

# projet_nodupl_old = 
#   #readxl::read_xlsx("data_tidy/projet_nodupl_old.xlsx")
#   aws.s3::s3read_using(
#   FUN = readxl::read_xlsx,
#   # Mettre les options de FUN ici
#   object = "data_tidy/projet_nodupl_old.xlsx",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))

bdd_joint = 
  #fread("data_raw/BDD_joint.xlsx")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  # Mettre les options de FUN ici
  encoding = "UTF-8",
  object = "data_tidy/BDD_joint_tidy_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  select(any_of(names(data_stat_nodupl)))
```

```{r, eval = FALSE}
#Test : differences between Léa's figures and my results

#PA identified with unique WDPAID. If more than 1 WDPAID, take the earlier annee_octroi
base_id = data_stat %>% 
  filter(!is.na(wdpaid)) %>% 
  group_by(wdpaid) %>% 
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

test = base_id[duplicated(base_id$wdpaid),]

base_old_id = base_nodupl_old %>% 
  filter(grepl("NA", wdpaid) == FALSE)  %>%
  group_by(wdpaid) %>% 
  slice(1) %>%
  mutate(wdpaid = as.numeric(wdpaid)) %>%
  ungroup()

#Identify PA in common among them with WDPAID reported
test_id = base_old_id %>%
  select(c(id_projet, nom_du_projet, name_pa, id_concours, wdpaid)) %>%
  left_join(select(base_id, 
                   c(id_projet, nom_du_projet, name_pa, id_concours, wdpaid)),
            by = "wdpaid")

#PA whose WDPAID is unknown, identified by id1 uniquely
#The duplicates comes from different concours ID, so do not correspond to different PA
base_na = data_stat %>% filter(is.na(wdpaid)) %>%
  mutate(id1 = paste(id_projet, iso3, name_pa, sep = "_"),
         .before = id_projet) %>%
  group_by(id1) %>%
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

base_old_na = base_nodupl_old %>% 
  filter(grepl("NA", wdpaid) == TRUE) %>%
  mutate(id1 = paste(id_projet, iso3, name_pa, sep = "_"),
         .before = id_projet) %>%
  group_by(id1) %>%
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

test_na = base_na %>%
  select(c(id1, id_projet, nom_du_projet, name_pa, id_concours)) %>%
  left_join(select(base_old_na, 
                   c(id1, id_projet, nom_du_projet, name_pa, id_concours)),
            by = "id1")

nrow(test_na %>% subset(is.na(id_projet.y) == TRUE))

#base_nodupl

base_nodupl = rbind(select(base_na, -id1), base_id)
```
