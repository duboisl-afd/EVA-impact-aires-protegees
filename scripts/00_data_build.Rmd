# Building the datasets

## Importing relevant packages

```{r setup, include = FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r message=TRUE, warning=TRUE, eval = FALSE}
install.packages(c("janitor", "wdpar", "countrycode"))
library(tidyverse)
library(dplyr)
library(data.table)
library(readxl)
library(janitor)
library(stringi)
library(sf)
library(terra)
library(mapview)
library(wdpar)
library(aws.s3)
library(countrycode)

#Install webdriver to download WDPA data
#webdriver::install_phantomjs()

```

This script builds the different datasets for the analysis. Protected areas (PAs) reported by AFD employees are combined, merged with AFD project database ("SIOP") and the World Database on Protected Areas (WDPA). A confidential dataset is created to perform descriptive statistics on fundings. Also, datasets on PAs aggregated size at country and regional level are created.

Note that not all datasets are made publicly available, as some contain confidential data. Please contact authors for special requests.

## Datasets for analysis

The datasets are built from the list of PAs funded by the AFD, provided by AFD employees. For each PA, further information are gathered from the SIOP and the WDPA.

Then, several datasets are built : (1) a dataset with only project related variables from the AFD, to facilitate merging with datasets other than WDPA; (2) a dataset to perform most analysis, except confidential statistics related to funding; (3) a confidential dataset with funding data.

### Merge PAs reporting (ARB, EVA ...)

A first step has been to collect information on the PAs funded by the AFD. A first bunch was collected by Léa Poulin, Ingrid Dallmann and Pierre-Yves Durand (form EVA department). Others was reported to us by the ARB department. These datasets are combined with only relevant variables for future merging with WDPA and SIOP databases.

```{r}
#PAs gathered by EVA
##BDD_joint created by Léa Poulin. 
##Create a dataset with a merged column for cofunders, instead of a variable ##for each. Only relevant variables are kept, and the date/author of the report are added.
data_pa_eva = 
  #read_excel("data_raw/BDD_joint.xlsx") %>%
  s3read_using(readxl::read_excel,
               object = "data_raw/BDD_joint.xlsx",
               bucket = "projet-afd-eva-ap",
               opts = list("region" = "")) %>%
  as.data.frame() %>%
  unite(cofinanciers, starts_with("cofinancier"),
        sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(c(id_projet, id_concours, cofinanciers, 
           nom_ap, wdpaid, superficie)) %>%
  rename("superficie_km2" = "superficie") %>%
  mutate(superficie_km2 = as.numeric(superficie_km2),
         wdpaid = as.numeric(wdpaid),
         date_entree = "2022-12-06",
         auteur_entree = "Léa Poulin,Pierre-Yves Durand,Ingrid Dallmann") %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x)))

#PAs gathered by ARB (10-08-2023)
data_pa_arb = 
  #read_excel("data_raw/BDD_ARB_10082023.xlsx") %>%
  s3read_using(readxl::read_excel,
             object = "data_raw/BDD_ARB_10082023.xlsx",
             bucket = "projet-afd-eva-ap",
             opts = list("region" = "")) %>%
  as.data.frame() %>%
  clean_names() %>%
  select(c(id_projet, id_concours, nom_cofinanciers,
           nom_de_laire_protegee, id_wdpa, superficie_km2)) %>%
  rename("cofinanciers" = "nom_cofinanciers",
         "nom_ap" = "nom_de_laire_protegee",
         "wdpaid" = "id_wdpa",
         "superficie_raw" = "superficie_km2") %>%
  #Create variables:
  ## Replace "NA" by NA values in wdpaid
  ## Check unit of area given reported by ARB
  ## Convert the area reported in km2, controlling for NA values, unreported values ("Non requis (information délivrée par la WDPA)"), values in hectares or km2. Note in some rows, unit must be removed and "," replaced by "." for the numeric conversion
  mutate(wdpaid = as.numeric(case_when(wdpaid == "NA" ~ NA,
                            TRUE ~ wdpaid)),
         date_entree = "2023-08-10",
         auteur_entree = "ARB",
         superficie_unit = case_when(grepl("km2", superficie_raw) ~ "km2",
                                     grepl("ha|Ha", superficie_raw) ~ "ha",
                                     TRUE ~ "km2"),
         superficie_km2 = case_when(grepl("Non", superficie_raw) ~ NA,
                                is.na(superficie_raw) ~ NA,
                                superficie_unit == "ha" ~ as.numeric(gsub(",", ".", gsub("ha|Ha", "", superficie_raw)))/1e2,
                                superficie_unit == "km2" ~ as.numeric(gsub(",", ".", gsub("km2", "", superficie_raw))),
                                TRUE ~ as.numeric(superficie_raw))) %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x))) %>%
  select(c("id_projet", "id_concours", "cofinanciers", "nom_ap",
           "wdpaid", "superficie_km2", "date_entree", "auteur_entree"))
  
#Create a dataset gathering EVA and ARB datasets, and remove duplicates
data_pa_afd = rbind(data_pa_eva, data_pa_arb)

#Finally, writing the dataset in csv file. Careful to the delimiter : ";" used as "," present in some variables values.
# write_delim(data_pa_afd, "data_raw/BDD_PA_AFD.csv",
#             delim = ";",
#             na = "NA")
# s3write_using(x = data_pa_afd,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_AFD.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Import and merge raw datasets

```{r, eval = FALSE}


#Import the manually reported dataset (merge from ARB, EVA reports)
#Careful to the delimiter choice
data_pa_afd = 
  #read_delim("data_raw/BDD_PA_AFD.csv", delim = ";")
  s3read_using(readr::read_delim,
                delim = ";",
               show_col_types = FALSE,
                object = "data_raw/BDD_PA_AFD.csv",
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))

#Import SIOP extract

fn_ucfirst <- function (str) {
  paste(toupper(substring(str, 1, 1)), tolower(substring(str, 2)), sep = "")
}

data_siop_pa = 
  #read_excel("data_raw/BO_AP_16082023.xlsx") %>%
  s3read_using(readxl::read_excel,
              object = "data_raw/BO_AP_16082023.xlsx",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  filter(id_projet %in% data_pa_afd$id_projet) %>%
  select(c(id_projet, id_concours,
           libelle_court_direction_regionale,
           pays_de_realisation, autres_pays_de_realisation,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           cofinancier,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_doctroi_projet, annee_doctroi_projet)) %>%
  rename("cofinanciers_siop" = "cofinancier",
         "pays" = "pays_de_realisation",
         "pays2" = "autres_pays_de_realisation") %>%
  mutate(pays = case_when(is.na(pays) == TRUE ~ NA,
                         is.na(pays) == FALSE ~ fn_ucfirst(pays)),
         pays2 = case_when(is.na(pays2) == TRUE ~ NA,
                          is.na(pays2) == FALSE ~ fn_ucfirst(pays2))) %>%
  #Add ISO code from countrycode package, reading "pays"
  mutate(iso3_siop = countrycode(sourcevar = pays, 
                                 origin = "country.name.fr",
                                 destination = "iso3c",
                                 custom_match = c("Multi-pays" = "ZZ",
                                                  "Multi-Pays" = "ZZ",
                                                  "Inde" = "IND")),
         .after = "pays")
  
#Import WDPA data
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)
data_wdpa = 
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  st_drop_geometry() %>%
  select(-geom) %>%
  clean_names() %>%
  rename("iso3_wdpa" = "iso3")

#Merge the datasets
data_raw = data_pa_afd %>%
  #Add information from WDPA to PAs funded and with WDPAID
  left_join(data_wdpa, by = "wdpaid") %>%
  #Add information from SIOP
  left_join(data_siop_pa, by = c("id_projet", "id_concours")) %>%
  #Keep only one ISO information : priority WDPA, then SIOP if NA value
  mutate(iso3 = iso3_wdpa,
         iso3 = case_when(is.na(iso3) == TRUE ~ iso3_siop,
                          TRUE ~ iso3),
         region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3_wdpa")
  

# s3write_using(x = data_raw,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Correct errors

Here errors in the reported information are corrected manually. Note the SIOP can be updated and the error not present anymore.

```{r}
#Loading the raw dataset
data_raw = 
  #fread("data_raw/BDD_PA_raw.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
data_raw_corr = data_raw

#Modify errors in the dataset
##WDPAID 797 with ID project CZZ3056 corresponds to APAC de Kawawana in Senegal, with no WDPAID (https://kawawana.iccaconsortium.org/)
data_raw_corr[data_raw_corr$wdpaid == "797" & data_raw_corr$id_projet == "CZZ3056",]$nom_ap = "APAC de Kawawana"
data_raw_corr[data_raw_corr$wdpaid == "797" & data_raw_corr$id_projet == "CZZ3056",]$iso3 = "SEN"
data_raw_corr[data_raw_corr$wdpaid == "797" & data_raw_corr$id_projet == "CZZ3056",]$wdpaid = NA

##4223, 4224, 4226, 4228, 4229 : all in PS-N.Caledonie
## -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("4223", "4224", "4226", "4228", "4229") & data_raw_corr$pays == "Fidji",]$pays = "P-S N.Caléd"
##305082 : Vanuatu instead of Fidji
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("305082") & data_raw_corr$pays == "Fidji",]$pays = "Vanuatu"
##31459 : Central African Republic instead of Cameroon. 
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("31459") & data_raw_corr$pays == "Cameroun",]$pays = "Centrafrique"
##Rio Grande de Buba : Guinee Bissau instead of Gambia
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("317051") & data_raw_corr$pays == "Gambie",]$pays = "Guinee-Bissau"
##WDPAID 20267 : in GNQ instead of GIN
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$pays = "Guinee-Equatoriale"
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$iso3 = "GNQ"

# s3write_using(x = data_raw_corr,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw_corr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Tidy the datasets

```{r}
#Import raw dataset corrected from report errors
data_raw_corr = 
  #fread("data_raw/BDD_PA_raw_corr.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw_corr.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

data_tidy = data_raw_corr %>%
  #Select relevant variables
  select(c(libelle_court_direction_regionale, region, sub_region,
           country_en, country_fr, pays_siop, pays2_siop, parent_iso3, iso3,
           id_projet, id_concours, nom_ap, wdpaid, wdpa_pid, 
           date_doctroi_projet, annee_doctroi_projet, status, status_yr,
           iucn_cat, marine, superficie_km2, rep_m_area, rep_area,
           gov_type, own_type,
           cofinanciers, cofinanciers_siop,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_entree, auteur_entree)) %>%
  #Create dummy variables for main investors
  #AFD is always funder, so no need of a dummy. 
  mutate(kfw_bin = grepl("KFW|kfw|KfW", cofinanciers),
         ffem_bin = grepl("ffem|FFEM", cofinanciers),
         cof_bin = is.na(cofinanciers) == FALSE & !(cofinanciers %in% c("AFD", "afd")),
         .after = "cofinanciers") %>%
  #Nouvelle-Calédonie is divided in two provinces : north and south. 
  #This subdivision is irrelevant in our analysis so we keep 
  #only "Nouvelle Caledonie"
  mutate(country_fr = case_when(pays_siop %in% c("P-N N.Caléd", "P-S N.Caléd", "Nlle Caledonie") | iso3 == "NCL" ~ "Nouvelle-Caledonie",
                               iso3 == "PYF" ~ "Polynesie-Francaise",
                               iso3 == "MYT" ~ "Mayotte",
                               TRUE ~ country_fr)) %>%
    mutate(country_en = case_when(pays_siop %in% c("P-N N.Caléd", "P-S N.Caléd", "Nlle Caledonie")  | iso3 == "NCL"  ~ "New Caledonia",
                                  iso3 == "PYF" ~ "French Polynesia",
                                  iso3 == "MYT" ~ "Mayotte",
                                  TRUE ~ country_en)) %>%
  #Some entries in "pays" are French department, DROM-COM, "Ocean Indien" or   #"Multi-Pays".
  #French related : the ISO3 code 
  #Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP dataset
  mutate(iso3 = case_when(
    pays_siop == "Mayotte" ~ "MYT",
    pays_siop == "Nouvelle-Caledonie" ~ "NCL",
    pays_siop == "Polynesie Francaise" ~ "PYF",
    is.na(iso3) & pays_siop %in% c("Multi-Pays", "Multi-pays", "Ocean Indien") ~ "ZZ",
    TRUE ~ iso3)) %>%
  #Add the description of IUCN from its category
    mutate(iucn_des = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
    #Modify class of some variables
  mutate(across(.cols = -c("wdpaid", "superficie_km2",
                           "annee_doctroi_projet",
                          "mt_fin_global_af_d_prevu_devise",
                          "montant_prevu_concours_euro_octroi" ,
                          "mt_global_projet_prevu_devise",
                          "mt_part_cofinancier_prevu_euro"), 
                .fns = ~stri_enc_toutf8(.x))) %>%
  #Translate names in English, except for funding data (not made public)
  rename("region_afd" = "libelle_court_direction_regionale",
         "name_pa" = "nom_ap",
         "date_funding" = "date_doctroi_projet",
         "year_funding" = "annee_doctroi_projet",
         "area_km2" = "superficie_km2")
```

### Dataset with only SIOP variables

```{r, eval = FALSE}
#Select info corresponding to SIOP extract and AP 
list_var_siop = c("id_projet", "id_concours", "region_afd", "pays_siop", "pays2_siop", 
                  "date_funding", "year_funding", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise" ,
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit", "date_entree", "auteur_entree" )

#Definining dataset for future work with dataset other than WDPA 
data_siop_tidy = data_tidy %>%
  dplyr::select(all_of(list_var_siop))

#write_csv(data_siop_tidy, "data_tidy/BDD_siop_tidy.xlsx")
# s3write_using(x = data_siop_tidy,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_tidy_siop.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Dataset for non-confidential analysis

To perform analysis we want to keep one row per PA, characterized by WDPA ID or a name (if no ID reported). Some PAs can have several lines if they receive funds at different time or by different investors.

```{r, eval = FALSE}

#Listing relevant variables for analysis that are NOT confidential (i.e not concern funding)
list_var_fund = c("cofinanciers", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise",
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit",
                  "kfw_bin", "ffem_bin")

#Defining dataset for descriptive statistics
data_nofund = data_tidy %>%
  select(!all_of(list_var_fund))

#fwrite(data_nofund, "data_tidy/BDD_nofund.csv")

#Then to keep only one row per PA, we need to consider separately PAs having WDPA ID and PAs which do not.
## Observations with WDPAID

#OLD
# data_nofund_wdpa = data_nofund %>%
#   subset(is.na(wdpaid) == FALSE) %>%
#   group_by(wdpa_pid) %>% 
#   #Keep the earlier annee_octroi (year of the first funding)
#   arrange(year_funding) %>%
#   #Keep only one observation for rows with same WDPAID
#   slice(1) %>%
#   ungroup()

data_nofund_wdpa = data_nofund %>%
  subset(is.na(wdpaid) == FALSE) %>%
  #We keep information on fundings : one row for each wdpa_pid, funding year is kept
  #Note that WDPA_PID is a unique identifier for zones inside the corresponding WDPAID. 
  #The choice of the WDPA_PID to keep is performed below (e.g choosing the area instead   #of the buffer zone)
  group_by(wdpa_pid, year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(wdpa_pid) %>%
  #Then we create a variable with all the funding year for each WDPA ...
  mutate(year_funding_all = paste0(year_funding, collapse = ","),
         .after = "year_funding") %>%
  #... and keep only the earlier funding year for year_funding
  arrange(year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  #Finally, we need to manually remove lines with more than one WDPA_PID
  ## Remove the buffer zone of WDPAID 9035
  filter(!(wdpa_pid == "9035_B")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A"))
  
# info_filtering = filter(data_raw_corr, wdpaid %in% c(9035, 555547861, 555547863, 555705345 )) %>%
#   group_by(wdpa_pid) %>%
#   slice(1)

#Observations without WDPAID
data_nofund_na = data_nofund %>%
  subset(is.na(wdpaid) == TRUE) %>%
  #Create a unique key for a PA : project ID from AFD, country (ISO code) and PA name
  #Rows with the same key correspond to different cofunders. This info is not relevant for non-funding analysis, so we can keep only one key value.
  mutate(key = paste(id_projet, iso3, name_pa, sep = "_"),
       .before = id_projet) %>%
  #We keep information on fundings : one row for each unique key, funding year is kept
  #Note that WDPA_PID is a unique identifier for zones inside the corresponding WDPAID. 
  group_by(key, year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(key) %>%
  #Then we create a variable with all the funding years for each protected area identified by key  ...
  mutate(year_funding_all = paste0(year_funding, collapse = ","),
         .after = "year_funding") %>%
  #... and keep only the earlier funding year for year_funding
  arrange(year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  select(-key)

#Finally bind both datasets
data_nofund_nodupl = rbind(data_nofund_wdpa, data_nofund_na) 

#fwrite(data_nofund_nodupl, "data_tidy/BDD_nofund_nodupl.csv")
# s3write_using(x = data_nofund_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Datasets for confidential analysis

The first funding dataset is there to perform descriptive statistics on project funding. Thus we do not need to have one line per PA, as it is not possible to isolate the funding a given WDPAID has received. We simply save the SIOP dataset for project reported as PAs related.

```{r, eval = FALSE}

#Listing relevant variables for descriptive statistics
# list_var_fund = c("id_projet", "name_pa", "id_concours",
#                 "wdpaid", "country_en", "country_fr", "iso3",
#                 "region_afd", "region", "sub_region",
#                 "cofinanciers", "cofinanciers_siop",
#                   "mt_fin_global_af_d_prevu_devise",
#                   "montant_prevu_concours_euro_octroi",
#                   "mt_global_projet_prevu_devise",
#                   "mt_part_cofinancier_prevu_euro",
#                   "libelle_produit",
#                   "date_funding",
#                   "year_funding")


#Defining dataset for descriptive statistics on PAs funding. We keep SIOP data on projects reported by AFD employees as related to PAs. 
data_fund = data_siop_pa %>%
  mutate(region = countrycode(sourcevar = iso3_siop,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode(sourcevar = iso3_siop,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode(sourcevar = iso3_siop,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode(sourcevar = iso3_siop,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3_siop")

#fwrite(data_fund, "data_tidy/BDD_AFD_fund.csv")
# s3write_using(x = data_fund,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_AFD_fund.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))



```

Then a dataset is built with funding associated to each WDPAID. Note a project can fund several WDPAID, and that AFD funding data do not make it possible to isolate the funding of each PA defined by a WDPAID.

```{r}
data_fund_pa = data_tidy
data_fund_wdpa = data_fund_pa %>%
    subset(is.na(wdpaid) == FALSE) %>%
  #We need to manually remove some WDPA_PID not relevant
  ## Remove the buffer zone of WDPAID 9035
  filter(!(wdpa_pid == "9035_B")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A")) %>%
  #Finally, keep for each WDPAID the different funding it get
  group_by(id_projet, id_concours, wdpaid, cofinanciers) %>%
  slice(1) %>%
  ungroup()

data_fund_na = data_fund_pa %>%
  filter(is.na(wdpaid) == TRUE) %>%
  #Create a unique key for a PA : project ID from AFD, country (ISO code) and PA name
  #Rows with the same key correspond to different cofunders. This info is not relevant for non-funding analysis, so we can keep only one key value.
  mutate(key = paste(id_projet, iso3, name_pa, sep = "_"),
       .before = id_projet) %>%
  group_by(key, cofinanciers) %>%
  slice(1) %>%
  ungroup() %>%
  select(-key)

data_fund_pa_nodupl = rbind(data_fund_wdpa, data_fund_na)

#fwrite(data_fund, "data_tidy/BDD_PA_AFD_fund.csv")
# s3write_using(x = data_fund_pa_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_AFD_fund_PA.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### A polygon dataset without confidential information

Removing confidential variables from the polygon dataset. This is temporary code, as in the future we will download information from WDPA through the WDPA package, and extract the WDPA ID of interest. No confidential data will then be contained in the polygon datasets.

```{r, eval = FALSE}
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, wdpa_pid, geom)) %>%
  mutate(geom_type = sf::st_geometry_type(geom))

data_pa_nofund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

data_fund_pa = 
  #fread("data_tidy/BDD_AFD_fund_PA.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_AFD_fund_PA.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

data_fund_pa_shp = data_fund_pa %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))


# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
s3write_using(x = data_fund_pa_shp,
              FUN = sf::st_write,
              delim = ";",
              object = "data_tidy/BDD_AFD_fund_PA_shp.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

```

## Computing total areas covered by PAs in the sample

Knowing the total area covered by PAs at different level of aggregation is interesting per se. It is also necessary to compute several statistics (e.g average funding by unit of area). According to the WDPA documentation, it is likely that some reported polygons overlap. Simply summing the areas would thus lead to a biased estimate of the total area at a given level of aggregation. We follow the procedure of the WDPA (<https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage>). Our case is simpler as all of the PAs we consider are given a polygon.

1.  The layer is converted to Mollweide (an equal area projection) and the area of each polygon is calculated, in km2.

2.  Intersection of polygons and the corresponding area are computed.

3.  Then the intersection can be aggregated at country, region or world level. Then it is subtracted to the sum of areas at country, region or world level. Note that intersections between PAs whose polygon is unknown won't be taken into account.

Note that the following codes are about computing total area at country/region/world level, taking potential intersections into account. It is not about generating a new shape files for the impact analysis. Indeed the overlap should be taken into account in the impact evaluation analysis codes.

### Computations of polygons' area

```{r, eval = FALSE}

#Importing shapefiles
sf_use_s2(FALSE)
pa_shp = 
  #read_sf("data_tidy/BDD_PA_AFD_shp.gpkg") %>%
  aws.s3::s3read_using(
  FUN = sf::read_sf,
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_shp.gpkg",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  #Take polygons only
  mutate(geom_type = as.character(st_geometry_type(geom))) %>%
  filter(geom_type == "MULTIPOLYGON") %>%
  #Ensure all geometries are valid
  st_make_valid() %>%
  #From multipolygon to polygon
  sf::st_cast(to="POLYGON") %>%
  #Select relevant variables
  dplyr::select(c(wdpaid, area_km2, rep_area, geom, iso3, region_afd, region, sub_region, year_funding)) 

#Spatial definition of wdpaid 555547988 overlaps CMR and CAF. Wdpaid 1245 corresponds to the CMR part. The overlap is removed and iso3 redefined so that 555547988 is CAF only. 
geom_555547988_1245 = st_difference(pa_shp[pa_shp$wdpaid == 555547988,]$geom, pa_shp[pa_shp$wdpaid == 1245,]$geom)
pa_shp[pa_shp$wdpaid == 555547988,]$geom = geom_555547988_1245
pa_shp[pa_shp$wdpaid == 555547988,]$iso3 = "CAF"

#Define a tidy version of the former dataset, with modifications on wdpaid 555547988
pa_shp_tidy = pa_shp %>%
  #Project to Mollweide to compute relevant areas in km2
  st_transform(crs = "+proj=moll +datum=WGS84") %>%
  #Compute areas in km2 from the geometry, in km2. It must be equal to gis_a by definition 
  #Then to take into account potential refinements of the geometries (as for wdpaid 55547988), a variable for relevant area is defined. It takes rep_a value except for modified geometries where area_sf_moll is taken
  mutate(area_sf_moll = as.numeric(st_area(geom)/1e6),
         area_km2 = ifelse(wdpaid == 555547988, yes = area_sf_moll, no = rep_area))
```

### Computing the intersection at country, region, world level

```{r, eval = FALSE}

#Compute intersecting areas of polygons
pa_int = st_intersection(pa_shp_tidy, pa_shp_tidy) %>%
  #Remove intersection of polygons with themselves
  subset(wdpaid != wdpaid.1) %>%
  #If one of the two intersectin polygon have unknwon area, then it is not necessary to subtract the interesction area. Indeed there is no double-counting of the intersection in this case, when both polygon areas are summed.
  subset(is.na(area_km2) == FALSE & is.na(area_km2.1) == FALSE) %>%
  #Compute the intersecting areas (pa_shp already in Mollweide projection) in km2
  mutate(area_int = as.numeric(st_area(geom)/1e6)) %>%
  #Now duplicates need to be removed : intersection of X with Y AND intersection of Y with X are reported. We need only one.
  #An id_int to identify the intersection of a given pair
  mutate(id_int = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  mutate(id_int_temp = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  #create a mirror idX_idY --> idY_idX so that we identify the both member of a pair with the same id
  separate(id_int_temp, into = c("id_temp1", "id_temp2"), sep = "_") %>%
  mutate(id_int_rev = case_when(
    id_temp1 < id_temp2 ~ paste(id_temp1, id_temp2, sep = "_"),
    id_temp1 > id_temp2 ~ paste(id_temp2, id_temp1, sep = "_"),
    TRUE ~ paste(id_temp1, id_temp2, sep = "_")),
    .after = id_int) %>%
  #finally, get rid of the duplicates (have the same id_int_rev)
  group_by(id_int_rev) %>%
  slice(1) %>%
  ungroup() %>%
  #select relevant variables only
  select(wdpaid, iso3, region_afd, region, sub_region, year_funding, wdpaid.1, iso3.1, region_afd.1, year_funding.1, geom, area_int)

#Computing the total area of intersections
#At country level ...
pa_int_ctry = pa_int %>%
  #Only overlapping PAs in the same country are considered
  subset(iso3 ==  iso3.1) %>%
  group_by(iso3) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

#At region level
pa_int_dr = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(region_afd == region_afd.1) %>%
  group_by(region_afd) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

##At world level : all overlap are considered
pa_int_wld = sum(pa_int$area_int) 

#Compute the total intersection for each year
pa_int_yr = pa_int %>%
  #Define intersection year : the date ann_c of the later PA in the pair
  rowwise() %>%
  mutate(annee_int = max(year_funding, year_funding.1)) %>% 
  group_by(annee_int) %>%
  summarize(tot_int_km2 = sum(area_int)) %>%
  st_drop_geometry()

# fwrite(pa_int_yr,
#        "data_tidy/area/pa_int_yr.csv")
# s3write_using(x = pa_int_yr,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_int_yr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Computing total areas without intersection

```{r, eval = FALSE}

data_pa_afd = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#At country level ...
pa_area_ctry = data_pa_afd %>%
  #Compute total area at country level
  group_by(iso3) %>%
  summarize(area_tot_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  #Add information on intersection area in each country. Modify the variable so that NA value -> 0
  left_join(pa_int_ctry, by = "iso3") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~ 0, TRUE ~ tot_area_int)) %>%
  #Compute the total area at country level without intersection
  mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) 

#fwrite(pa_area_ctry, "data_tidy/area/pa_area_ctry.csv")
# s3write_using(x = pa_area_ctry,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_ctry.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At DR level ...
pa_area_dr = data_pa_afd %>%
  #Compute total area at dr level
  group_by(region_afd) %>%
  summarize(area_tot_km2 = sum(area_km2, na.rm = TRUE)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_dr, by = "region_afd") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
    mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_dr,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_dr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At world level
pa_area_wld = sum(data_pa_afd$area_km2, na.rm = TRUE) - pa_int_wld %>%
  as.data.frame() %>%
  rename("area_tot_noint_km2" = ".")
#fwrite(pa_area_wld, "data_tidy/area/pa_area_wld.csv")
# s3write_using(x = pa_area_wld,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_wld.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

## Old code

```{r, eval = FALSE}
#Listing variables public or confidential

#Public variables in the PAs dataset
list_var_PA_open = c("id_projet", "nom_du_projet", "name_pa", "id_concours", 
                "wdpaid", "wdpaid_2", "wdpaid_3", "wdpa_pid",
                "pays", "iso3", "direction_regionale", "annee_octroi",
                "cofinancier_1", "cofinancier_2", "cofinancier_3", 
                "cofinancier_4", "cofinancier_5", "cofinancier_6",
                "kfw_bin", "ffem_bin", "nb_ap_nombre_potentiel", "detail",
                "iucn_cat", "iucn_des", "marine", "superficie",
                "status", "status_yr", "gov_type","own_type", "mang_auth")
#Confidential variables in the PAs dataset
list_var_PA_conf = list_var_joint_conf = 
  c("montant_prevu_concours_euro_octroi", "mt_global_projet_prevu_devise",
    "engagements_nets_euro_octroi" , "montant_total_projet",
    "produit", "libelle_produit",
    "date_de_1er_versement_projet", "dernier_versement_en_date_projet",
    "date_signature_convention_cf", "duree_du_concours_annee",
    "duree_du_concours_annee_et_mois", "beneficiaire_primaire",
    "responsable_equipe_projet", "directeur_trice_dagence", "maitrise_ouvrage"
    )
#Confidential variables among shapefiles
list_var_shp_conf = c("mntnt", "mtglb", "e", "mnt", "prodt", "lbllp",
                      "rspns", "dr", "detal", "projt", "cmmnt")
```

```{r, eval = FALSE}
base_nodupl_lea = 
  #fread("data_tidy/base_nodupl_lea.xlsx")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_DesStat_nodupl_lea_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  select(any_of(names(data_stat_nodupl)))
  
#import a dataset with country anmes and corresponding ISO3 code
data_iso = data_stat %>%
  select(c(pays, iso3)) %>%
  group_by(iso3) %>%
  slice(1)

base_nodupl_old = 
  #fread("data_tidy/base_nodupl_old.csv") 
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_DesStat_nodupl_old_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))%>%
  select(any_of(names(data_stat_nodupl))) %>%
  select(-iso3) %>%
  left_join(data_iso, by = "pays") %>%
  mutate(iso3 = case_when(
    pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie") ~ "FRA",
    pays == "Multi-Pays" ~ "ZZ",
    !(pays %in% c("Mayotte", "P-N N.Caléd", "P-S N.Caléd", 
                "Polynesie Francaise", "Nlle Caledonie", "Multi-Pays")) ~ iso3
  ))

# projet_nodupl_old = 
#   #readxl::read_xlsx("data_tidy/projet_nodupl_old.xlsx")
#   aws.s3::s3read_using(
#   FUN = readxl::read_xlsx,
#   # Mettre les options de FUN ici
#   object = "data_tidy/projet_nodupl_old.xlsx",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))

bdd_joint = 
  #fread("data_raw/BDD_joint.xlsx")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  # Mettre les options de FUN ici
  encoding = "UTF-8",
  object = "data_tidy/BDD_joint_tidy_pub.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  select(any_of(names(data_stat_nodupl)))
```

```{r, eval = FALSE}
#Test : differences between Léa's figures and my results

#PA identified with unique WDPAID. If more than 1 WDPAID, take the earlier annee_octroi
base_id = data_stat %>% 
  filter(!is.na(wdpaid)) %>% 
  group_by(wdpaid) %>% 
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

test = base_id[duplicated(base_id$wdpaid),]

base_old_id = base_nodupl_old %>% 
  filter(grepl("NA", wdpaid) == FALSE)  %>%
  group_by(wdpaid) %>% 
  slice(1) %>%
  mutate(wdpaid = as.numeric(wdpaid)) %>%
  ungroup()

#Identify PA in common among them with WDPAID reported
test_id = base_old_id %>%
  select(c(id_projet, nom_du_projet, name_pa, id_concours, wdpaid)) %>%
  left_join(select(base_id, 
                   c(id_projet, nom_du_projet, name_pa, id_concours, wdpaid)),
            by = "wdpaid")

#PA whose WDPAID is unknown, identified by id1 uniquely
#The duplicates comes from different concours ID, so do not correspond to different PA
base_na = data_stat %>% filter(is.na(wdpaid)) %>%
  mutate(id1 = paste(id_projet, iso3, name_pa, sep = "_"),
         .before = id_projet) %>%
  group_by(id1) %>%
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

base_old_na = base_nodupl_old %>% 
  filter(grepl("NA", wdpaid) == TRUE) %>%
  mutate(id1 = paste(id_projet, iso3, name_pa, sep = "_"),
         .before = id_projet) %>%
  group_by(id1) %>%
  arrange(annee_octroi) %>%
  slice(1) %>%
  ungroup()

test_na = base_na %>%
  select(c(id1, id_projet, nom_du_projet, name_pa, id_concours)) %>%
  left_join(select(base_old_na, 
                   c(id1, id_projet, nom_du_projet, name_pa, id_concours)),
            by = "id1")

nrow(test_na %>% subset(is.na(id_projet.y) == TRUE))

#base_nodupl

base_nodupl = rbind(select(base_na, -id1), base_id)
```
