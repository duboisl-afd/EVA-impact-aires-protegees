[["index.html", "A Minimal Book Example Chapter 1 About 1.1 Usage 1.2 Render book 1.3 Preview book", " A Minimal Book Example John Doe 2023-07-21 Chapter 1 About This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports; for example, a math equation \\(a^2 + b^2 = c^2\\). 1.1 Usage Each bookdown chapter is an .Rmd file, and each .Rmd file can contain one (and only one) chapter. A chapter must start with a first-level heading: # A good chapter, and can contain one (and only one) first-level heading. Use second-level and higher headings within chapters like: ## A short section or ### An even shorter section. The index.Rmd file is required, and is also your first book chapter. It will be the homepage when you render the book. 1.2 Render book You can render the HTML version of this example book without changing anything: Find the Build pane in the RStudio IDE, and Click on Build Book, then select your output format, or select “All formats” if you’d like to use multiple formats from the same book source files. Or build the book from the R console: bookdown::render_book() To render this example to PDF as a bookdown::pdf_book, you’ll need to install XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.org/tinytex/. 1.3 Preview book As you work, you may start a local server to live preview this HTML book. This preview will update as you edit the book when you save individual .Rmd files. You can start the server in a work session by using the RStudio add-in “Preview book”, or from the R console: bookdown::serve_book() "],["building-the-datasets.html", "Chapter 2 Building the datasets 2.1 Importing relevant packages 2.2 Datasets for descriptive statistics 2.3 Computing total areas covered by PAs in the sample 2.4 Old code", " Chapter 2 Building the datasets 2.1 Importing relevant packages library(tidyverse) library(stargazer) library(dplyr) library(data.table) library(readxl) library(splitstackshape) library(janitor) library(stringi) library(sf) library(mapview) 2.2 Datasets for descriptive statistics The raw dataset has been built by Léa Poulin. It comes from the merging of SIOP extract, and PAs dataset from ARB covering 2000-2017 period. Majority of PAs had no corresponding WDPA ID, so it was found and reported manually by Léa Poulin and Ingrid Dallmann on WDPA website. Different datasets are built. First a dataset (data_PA_tidy) enriched of information on co-investors and ISO code for the country hosting the PA. From this dataset are extracted : (1) a dataset with only SIOP variables, to allow future working on PAs; (2) a dataset to perform most descriptive statistics, except confidential ones related to funding; (3) a confidential dataset with funding data. Then a dataset of PAs polygons is imported from the WDPA, and confidential data removed. Some statistics need size of PAs at country/region/world level (evolution of area covered by PAs at world level for instance). Datasets with total areas at country/region/world level are created. As many areas overlap (according to WDPA documentation), a sum of reported area would overestimate aggregated area. The computation method of WDPA is followed (https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage). 2.2.1 Cleaning the raw dataset #import a dataset with country names and corresponding ISO3 code data_iso = fread(&quot;data_raw/liste-197-etats-2020.csv&quot;) %&gt;% rename(&quot;iso3&quot; = &quot;CODE&quot;, &quot;nom_alpha&quot; = &quot;NOM_ALPHA&quot;) %&gt;% dplyr::select(c(&quot;nom_alpha&quot;, &quot;iso3&quot;)) %&gt;% #get rid of accentuations and change name by hand to correspond with BDD_joint mutate(nom_alpha2 = iconv(nom_alpha, to = &quot;ASCII//TRANSLIT&quot;), nom_alpha2 = case_when( nom_alpha2 == &quot;Cook (Iles)&quot; ~ &quot;Cook&quot;, nom_alpha2 == &quot;Cote d&#39;Ivoire&quot; ~ &quot;Cote D Ivoire&quot;, nom_alpha2 == &quot;Sao Tome-et-Principe&quot; ~ &quot;Sao Tome&quot;, nom_alpha2 == &quot;Palaos&quot; ~ &quot;Palau&quot;, nom_alpha2 == &quot;Guinee-Bissao&quot; ~ &quot;Guinee-Bissau&quot;, !(nom_alpha %in% c(&quot;Cook (Iles)&quot;, &quot;Cote d&#39;Ivoire&quot;, &quot;Sao Tome-et-Principe&quot;, &quot;Palaos&quot;, &quot;Guinée-Bissao&quot;)) ~ nom_alpha2 )) #Import the initial BDD_joint, change the encoding to keep accentuation data_PA_raw = read_excel(&quot;data_raw/BDD_joint.xlsx&quot;) %&gt;% as.data.frame() %&gt;% mutate(across(.cols = names(.), .fns = ~stri_enc_toutf8(.x))) #Modify errors in the dataset ##WDPAID 797 in Senegal data_PA_raw[data_PA_raw$wdpaid == &quot;797&quot; &amp; data_PA_raw$pays == &quot;Senegal&quot;,]$nom_ap = &quot;APAC de Kawawana&quot; data_PA_raw[data_PA_raw$wdpaid == &quot;797&quot; &amp; data_PA_raw$pays == &quot;Senegal&quot;,]$wdpaid = NA ##4223, 4224, 4226, 4228, 4229 : all in PS-N.Caledonie data_PA_raw[data_PA_raw$wdpaid %in% c(&quot;4223&quot;, &quot;4224&quot;, &quot;4226&quot;, &quot;4228&quot;, &quot;4229&quot;) &amp; data_PA_raw$pays == &quot;Fidji&quot;,]$pays = &quot;P-S N.Caléd&quot; ##305082 : Vanuatu instead of Fidji data_PA_raw[data_PA_raw$wdpaid %in% c(&quot;305082&quot;) &amp; data_PA_raw$pays == &quot;Fidji&quot;,]$pays = &quot;Vanuatu&quot; #Create a clean dataset with relevant variables data_PA_tidy = data_PA_raw %&gt;% #Get rid of the iso code in the initial dataset, to avoid confusion when merging with data_iso dplyr::select(-iso3) %&gt;% #Create dummy variables for main investors #AFD is always funder, so no need of a dummy mutate( # afd_bin = case_when((cofinancier_1 == &quot;AFD&quot; | cofinancier_2 == &quot;AFD&quot; | cofinancier_3 == &quot;AFD&quot; | # cofinancier_4 == &quot;AFD&quot; | cofinancier_5 == &quot;AFD&quot; | cofinancier_6 == &quot;AFD&quot;) ~ TRUE, # (is.na(cofinancier_1) &amp; is.na(cofinancier_2) &amp; is.na(cofinancier_3) &amp; is.na(cofinancier_4) # &amp; is.na(cofinancier_5) &amp; is.na(cofinancier_6)) ~ TRUE, # TRUE ~ FALSE), kfw_bin = ifelse(cofinancier_1 == &quot;KFW&quot; | cofinancier_2 == &quot;KFW&quot; | cofinancier_3 == &quot;KFW&quot; | cofinancier_4 == &quot;KFW&quot; | cofinancier_5 == &quot;KFW&quot; | cofinancier_6 == &quot;KFW&quot;, yes = TRUE, no = FALSE), kfw_bin = ifelse(is.na(kfw_bin), yes = FALSE, no = kfw_bin), ffem_bin = ifelse(cofinancier_1 == &quot;FFEM&quot; | cofinancier_2 == &quot;FFEM&quot; | cofinancier_3 == &quot;FFEM&quot; | cofinancier_4 == &quot;FFEM&quot; | cofinancier_5 == &quot;FFEM&quot; | cofinancier_6 == &quot;FFEM&quot;, yes = TRUE, no = FALSE), ffem_bin = ifelse(is.na(ffem_bin), yes = FALSE, no = ffem_bin), .after = &quot;cofinancier_6&quot;) %&gt;% #Create a dummy for other co-investors # mutate(cofin_unkwn = ifelse(is.na(cofinancier_1) &amp; is.na(cofinancier_1) &amp; is.na(cofinancier_1) &amp; is.na(cofinancier_1) &amp; is.na(cofinancier_1) &amp; is.na(cofinancier_1), # yes = TRUE, # no = FALSE), # cofin_unkwn = ifelse(is.na(cofin_unkwn), yes = FALSE, no = cofin_unkwn), # .after = &quot;ffem_bin&quot;) %&gt;% #Create a dummy for investors not AFD, KFW or FFEM # mutate(cofin_other = afd_bin == FALSE &amp; # kfw_bin == FALSE &amp; ffem_bin == FALSE &amp; cofin_unkwn == FALSE, # .after = &quot;cofin_unkwn&quot;) %&gt;% #Add the ISO3 code corresponding to the country hosting the PA. Facilitate future mergings left_join(data_iso, by = c(&quot;pays&quot; = &quot;nom_alpha2&quot;)) %&gt;% #Some entries in &quot;pays&quot; are French department, DROM-COM, &quot;Ocean Indien&quot; or &quot;Multi-Pays&quot;. #French related : assigned to France. Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP mutate(iso3 = case_when( pays %in% c(&quot;Mayotte&quot;, &quot;P-N N.Caléd&quot;, &quot;P-S N.Caléd&quot;, &quot;Polynesie Francaise&quot;, &quot;Nlle Caledonie&quot;) ~ &quot;FRA&quot;, pays %in% c(&quot;Multi-Pays&quot;, &quot;Ocean Indien&quot;) ~ &quot;ZZ&quot;, !(pays %in% c(&quot;Mayotte&quot;, &quot;P-N N.Caléd&quot;, &quot;P-S N.Caléd&quot;, &quot;Polynesie Francaise&quot;, &quot;Nlle Caledonie&quot;, &quot;Multi-Pays&quot;)) ~ iso3 )) %&gt;% #Add the description of IUCN from its category mutate(iucn_des = case_when( !is.na(wdpaid) &amp; iucn_cat == &quot;Ia&quot; ~ &quot;Réserve naturelle intégrale&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;Ib&quot; ~ &quot;Zone de nature sauvage&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;II&quot; ~ &quot;Parc national&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;III&quot; ~ &quot;Monument naturel&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;IV&quot; ~ &quot;Gest. des habitats/espèces&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;V&quot; ~ &quot;Paysage protégé&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;VI&quot; ~ &quot;Gest. de ress. protégées&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;Not Applicable&quot; ~ &quot;Non catégorisée&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;Not Reported&quot; ~ &quot;Non catégorisée&quot;, !is.na(wdpaid) &amp; iucn_cat == &quot;Not Assigned&quot; ~ &quot;Non catégorisée&quot;, TRUE ~ &quot;Non référencée&quot;), .after = iucn_cat) %&gt;% #Modify class of some variables mutate(across(.cols = c(&quot;wdpaid&quot;, &quot;superficie&quot;, &quot;montant_prevu_concours_euro_octroi&quot;, &quot;mt_global_projet_prevu_devise&quot; , &quot;engagements_nets_euro_octroi&quot;, &quot;montant_total_projet&quot;), .fns = ~as.numeric(.x))) %&gt;% mutate(across(.cols = -c(&quot;wdpaid&quot;, &quot;superficie&quot;, &quot;montant_prevu_concours_euro_octroi&quot;, &quot;mt_global_projet_prevu_devise&quot; , &quot;engagements_nets_euro_octroi&quot;, &quot;montant_total_projet&quot;), .fns = ~stri_enc_toutf8(.x))) #fwrite(data_PA_tidy, &quot;data_tidy/BDD_joint_tidy.csv&quot;) 2.2.2 Dataset with only SIOP variables #Select info corresponding to SIOP extract and AP list_var_siop_AP = c( &quot;id_projet&quot;, &quot;nom_du_projet&quot;, &quot;nom_de_projet_pour_les_instances&quot;, &quot;id_concours&quot;, &quot;libelle_du_concours&quot;, &quot;description_du_projet&quot;, &quot;wdpaid&quot;, &quot;wdpaid_2&quot;, &quot;wdpaid_3&quot;, &quot;montant_prevu_concours_euro_octroi&quot;, &quot;mt_global_projet_prevu_devise&quot;, &quot;engagements_nets_euro_octroi&quot;, &quot;montant_total_projet&quot;, &quot;produit&quot;, &quot;libelle_produit&quot;, &quot;division_technique&quot;, &quot;libelle_division_technique&quot;, &quot;agence&quot;, &quot;libelle_agence&quot;, &quot;annee_octroi&quot;, &quot;date_octroi&quot;, &quot;date_de_1er_versement_projet&quot;, &quot;dernier_versement_en_date_projet&quot;, &quot;date_signature_convention_cf&quot;, &quot;duree_du_concours_annee&quot;, &quot;duree_du_concours_annee_et_mois&quot;, &quot;id_pays_de_realisation&quot;, &quot;pays&quot;, &quot;iso3&quot;, &quot;direction_regionale&quot;, &quot;autres_pays_de_realisation&quot;, &quot;etat_du_projet&quot;, &quot;libelle_etat_du_projet&quot;, &quot;beneficiaire_primaire&quot;, &quot;responsable_equipe_projet&quot;, &quot;directeur_trice_dagence&quot;, &quot;date_de_remise_du_rapport_final&quot;, &quot;cofinancier_1&quot;, &quot;cofinancier_2&quot;, &quot;cofinancier_3&quot;,&quot;cofinancier_4&quot;, &quot;cofinancier_5&quot;, &quot;cofinancier_6&quot;, &quot;kfw_bin&quot;, &quot;ffem_bin&quot;, &quot;maitrise_ouvrage&quot;, &quot;superf_interne&quot;, &quot;nb_ap_nombre_potentiel&quot;, &quot;detail&quot;, &quot;projet&quot;, &quot;commentaires&quot;) #Definining dataset for future analysis : siop and AP but not WDPA data_siop_AP = data_PA_tidy %&gt;% dplyr::select(all_of(list_var_siop_AP), iso3) #write_csv(data_siop_AP, &quot;data_tidy/BDD_AP_SIOP_joint.xlsx&quot;) 2.2.3 Dataset for non-confidential statistics To perform descriptive statistics we want to keep one row per PA, characterized by WDPA ID or a name (if no ID reported). Some PAs can have several lines if they receive funds at different time or by different investors. #Listing relevant variables for descriptive statistics that are NOT confidential (i.e not concern funding) list_var_PA_nofund = c(&quot;id_projet&quot;, &quot;nom_du_projet&quot;, &quot;nom_ap&quot;, &quot;id_concours&quot;, &quot;wdpaid&quot;, &quot;pays&quot;, &quot;iso3&quot;, &quot;direction_regionale&quot;, &quot;annee_octroi&quot;, &quot;nb_ap_nombre_potentiel&quot;, &quot;detail&quot;, &quot;iucn_cat&quot;, &quot;iucn_des&quot;, &quot;marine&quot;, &quot;superficie&quot;, &quot;status&quot;, &quot;status_yr&quot;, &quot;gov_type&quot;,&quot;own_type&quot;, &quot;mang_auth&quot;) #Defining dataset for descriptive statistics data_stat_nofund = data_PA_tidy %&gt;% select(all_of(list_var_PA_nofund), iso3) #fwrite(data_stat_nofund, &quot;data_tidy/BDD_DesStat_nofund.csv&quot;) #Then to keep only one row per PA, we need to consider separately PAs having WDPA ID and PAs which do not. data_stat_nofund_wdpa = data_stat_nofund %&gt;% subset(is.na(wdpaid) == FALSE) %&gt;% group_by(wdpaid) %&gt;% arrange(annee_octroi) %&gt;% slice(1) %&gt;% ungroup() data_stat_nofund_na = data_stat_nofund %&gt;% subset(is.na(wdpaid) == TRUE) %&gt;% mutate(id1 = paste(id_projet, iso3, nom_ap, sep = &quot;_&quot;), .before = id_projet) %&gt;% group_by(id1) %&gt;% arrange(annee_octroi) %&gt;% slice(1) %&gt;% ungroup() %&gt;% #remove id1 variable, to bind data_stat_na and data_stat_wdpa by row select(-id1) data_stat_nofund_nodupl = rbind(data_stat_nofund_wdpa, data_stat_nofund_na) #fwrite(data_stat_nofund_nodupl, &quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot;) 2.2.4 Dataset for confidential descriptive statistics #Listing relevant variables for descriptive statistics list_var_PA_fund = c(&quot;id_projet&quot;, &quot;nom_du_projet&quot;, &quot;nom_ap&quot;, &quot;id_concours&quot;, &quot;wdpaid&quot;, &quot;pays&quot;, &quot;iso3&quot;, &quot;direction_regionale&quot;, &quot;montant_prevu_concours_euro_octroi&quot;, &quot;mt_global_projet_prevu_devise&quot;, &quot;engagements_nets_euro_octroi&quot;, &quot;montant_total_projet&quot;, &quot;libelle_produit&quot;, &quot;annee_octroi&quot;, &quot;cofinancier_1&quot;, &quot;cofinancier_2&quot;, &quot;cofinancier_3&quot;, &quot;cofinancier_4&quot;, &quot;cofinancier_5&quot;, &quot;cofinancier_6&quot;, &quot;kfw_bin&quot;, &quot;ffem_bin&quot;) #Defining dataset for descriptive statistics #Duplicates are not revmoved here, as we want the information on the different concours for instance. Peculiar datasets data_stat_fund = data_PA_tidy %&gt;% select(all_of(list_var_PA_fund), iso3) #fwrite(data_stat_fund, &quot;data_tidy/BDD_DesStat_fund.csv&quot;) 2.2.5 A polygon dataset without confidential information #The confidential information removed concern funding or nominative variables pa_shp = read_sf(&quot;data_raw/WDPA_SHP/BDD_SHP_nodupl.shp&quot;) %&gt;% clean_names() %&gt;% select(-c(mntnt, mtglb, e, mnt, prodt, lbllp, dt_ct, d_1, d, d_c, durdcncrs_a, drdcncrs_an, atrsp, ett, lbllt, rspns, dr, mtrs, detal, projt, cmmnt, cmmnt_1)) # st_write(pa_shp, # dsn = &quot;data_tidy/BDD_shp_pub.gpkg&quot;, # delete_dsn = TRUE) rm(pa_shp) 2.3 Computing total areas covered by PAs in the sample Knowing the total area covered by PAs at different level of aggregation is interesting per se. It is also necessary to compute several statistics (e.g average funding by unit of area). According to the WDPA documentation, it is likely that some reported polygons overlap. Simply summing the areas would thus lead to a biased estimate of the total area at a given level of aggregation. We follow the procedure of the WDPA (https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage). Our case is simpler as all of the PAs we consider are given a polygon. The layer is converted to Mollweide (an equal area projection) and the area of each polygon is calculated, in km2. Intersection of polygons and the corresponding area are computed. Then the intersection can be aggregated at country, region or world level. Then it is subtracted to the sum of areas at country, region or world level. Note that intersections between PAs whose polygon is unknown won’t be taken into account. Note that the following codes are about computing total area at country/region/world level, taking potential intersections into account. It is not about generating a new shape files for the impact analysis. Indeed the overlap should be taken into account in the impact evaluation analysis codes. 2.3.1 Computations of polygons’ area #Importing shapefiles sf_use_s2(FALSE) pa_shp = read_sf(&quot;data_tidy/BDD_shp_raw.gpkg&quot;) %&gt;% # aws.s3::s3read_using( # FUN = sf::read_sf, # # Mettre les options de FUN ici # object = &quot;data_tidy/BDD_SHP_nodupl_pub.gpkg&quot;, # bucket = &quot;projet-afd-eva-ap&quot;, # opts = list(&quot;region&quot; = &quot;&quot;)) %&gt;% #Ensure all geometries are valid st_make_valid() %&gt;% #From multipolygon to polygon sf::st_cast(to=&quot;POLYGON&quot;) %&gt;% clean_names() %&gt;% #Select relevant variables #Note ann_c = annee_octroi in the initial database data_PA_raw dplyr::select(c(wdpaid, sprfc, rep_a, gis_a, geom, iso3, drct, ann_c)) %&gt;% #Variable sprfc corresponds to AFD internal reported size rename(&quot;sprfc_int&quot; = &quot;sprfc&quot;) %&gt;% mutate(wdpaid = as.numeric(wdpaid), sprfc_int = as.numeric(sprfc_int)) #Spatial definition of wdpaid 555547988 overlaps CMR and CAF. Wdpaid 1245 corresponds to the CMR part. The overlap is removed and iso3 redefined so that 555547988 is CAF only. geom_555547988_1245 = st_difference(pa_shp[pa_shp$wdpaid == 555547988,]$geom, pa_shp[pa_shp$wdpaid == 1245,]$geom) pa_shp[pa_shp$wdpaid == 555547988,]$geom = geom_555547988_1245 pa_shp[pa_shp$wdpaid == 555547988,]$iso3 = &quot;CAF&quot; #Define a tidy version of the former dataset, with modifications on wdpaid 555547988 pa_shp_tidy = pa_shp %&gt;% #Project to Mollweide to compute relevant areas in km2 st_transform(crs = &quot;+proj=moll +datum=WGS84&quot;) %&gt;% #Compute areas in km2 from the geometry, in km2. It must be equal to gis_a by definition #Then to take into account potential refinements of the geometries (as for wdpaid 55547988), a variable for relevant area is defined. It takes rep_a value except for modified geometries where area_sf_moll is taken mutate(area_sf_moll = as.numeric(st_area(geom)/1e6), sprfc_km2 = ifelse(wdpaid == 555547988, yes = area_sf_moll, no = rep_a)) 2.3.2 Computing the intersection at country, region, world level #Compute intersecting areas of polygons pa_int = st_intersection(pa_shp_tidy, pa_shp_tidy) %&gt;% #Remove intersection of polygons with themselves subset(wdpaid != wdpaid.1) %&gt;% #If one of the two intersectin polygon have unknwon area, then it is not necessary to subtract the interesction area. Indeed there is no double-counting of the intersection in this case, when both polygon areas are summed. subset(is.na(sprfc_km2) == FALSE &amp; is.na(sprfc_km2.1) == FALSE) %&gt;% #Compute the intersecting areas (pa_shp already in Mollweide projection) in km2 mutate(area_int = as.numeric(st_area(geom)/1e6)) %&gt;% #Now duplicates need to be removed : intersection of X with Y AND intersection of Y with X are reported. We need only one. #An id_int to identify the intersection of a given pair mutate(id_int = paste0(wdpaid, &quot;_&quot;, wdpaid.1), .before = wdpaid) %&gt;% mutate(id_int_temp = paste0(wdpaid, &quot;_&quot;, wdpaid.1), .before = wdpaid) %&gt;% #create a mirror idX_idY --&gt; idY_idX so that we identify the both member of a pair with the same id separate(id_int_temp, into = c(&quot;id_temp1&quot;, &quot;id_temp2&quot;), sep = &quot;_&quot;) %&gt;% mutate(id_int_rev = case_when( id_temp1 &lt; id_temp2 ~ paste(id_temp1, id_temp2, sep = &quot;_&quot;), id_temp1 &gt; id_temp2 ~ paste(id_temp2, id_temp1, sep = &quot;_&quot;), TRUE ~ paste(id_temp1, id_temp2, sep = &quot;_&quot;)), .after = id_int) %&gt;% #finally, get rid of the duplicates (have the same id_int_rev) group_by(id_int_rev) %&gt;% slice(1) %&gt;% ungroup() %&gt;% #select relevant variables only select(wdpaid, iso3, drct, ann_c, wdpaid.1, iso3.1, drct.1, ann_c.1, geom, area_int) #Computing the total area of intersections #At country level ... pa_int_ctry = pa_int %&gt;% #Only overlapping PAs in the same country are considered subset(iso3 == iso3.1) %&gt;% group_by(iso3) %&gt;% summarize(tot_area_int = sum(area_int)) %&gt;% st_drop_geometry() #At region level pa_int_dr = pa_int %&gt;% #Only overlapping PAs in the same DR are considered subset(drct == drct.1) %&gt;% group_by(drct) %&gt;% summarize(tot_area_int = sum(area_int)) %&gt;% st_drop_geometry() ##At world level : all overlap are considered pa_int_wld = sum(pa_int$area_int) #Compute the total intersection for each year pa_int_yr = pa_int %&gt;% #Define intersection year : the date ann_c of the later PA in the pair rowwise() %&gt;% mutate(annee_int = max(ann_c, ann_c.1)) %&gt;% group_by(annee_int) %&gt;% summarize(tot_int_km2 = sum(area_int)) %&gt;% st_drop_geometry() # fwrite(pa_int_yr, # &quot;data_tidy/area/pa_int_yr.csv&quot;) 2.3.3 Computing total areas without intersection #At country level ... pa_area_ctry = data_stat_nofund_nodupl %&gt;% #Compute total area at country level group_by(iso3) %&gt;% summarize(sprfc_tot_km2 = sum(superficie)) %&gt;% ungroup() %&gt;% #Add information on intersection area in each country. Modify the variable so that NA value -&gt; 0 left_join(pa_int_ctry, by = &quot;iso3&quot;) %&gt;% mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~ 0, TRUE ~ tot_area_int)) %&gt;% #Compute the total area at country level without intersection mutate(sprfc_tot_noint_km2 = sprfc_tot_km2 - tot_area_int) #fwrite(pa_area_ctry, &quot;data_tidy/area/pa_area_ctry.csv&quot;) #At DR level ... pa_area_dr = data_stat_nofund_nodupl %&gt;% #Compute total area at dr level group_by(direction_regionale) %&gt;% summarize(sprfc_tot_km2 = sum(superficie)) %&gt;% ungroup() %&gt;% #Add information on intersection area in each DR. Modify the variable so that NA value -&gt; 0 left_join(pa_int_dr, by = c(&quot;direction_regionale&quot; = &quot;drct&quot;)) %&gt;% mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %&gt;% #Compute the total area at country level without intersection mutate(sprfc_tot_noint_km2 = sprfc_tot_km2 - tot_area_int) %&gt;% st_drop_geometry() #fwrite(pa_area_dr, &quot;data_tidy/area/pa_area_dr.csv&quot;) #At world level pa_area_wld = sum(data_stat_nofund_nodupl$superficie) - pa_int_wld %&gt;% as.data.frame() %&gt;% rename(&quot;sprfc_tot_noint_km2&quot; = &quot;.&quot;) #fwrite(pa_area_wld, &quot;data_tidy/area/pa_area_wld.csv&quot;) 2.4 Old code #Listing variables public or confidential #Public variables in the PAs dataset list_var_PA_open = c(&quot;id_projet&quot;, &quot;nom_du_projet&quot;, &quot;nom_ap&quot;, &quot;id_concours&quot;, &quot;wdpaid&quot;, &quot;wdpaid_2&quot;, &quot;wdpaid_3&quot;, &quot;wdpa_pid&quot;, &quot;pays&quot;, &quot;iso3&quot;, &quot;direction_regionale&quot;, &quot;annee_octroi&quot;, &quot;cofinancier_1&quot;, &quot;cofinancier_2&quot;, &quot;cofinancier_3&quot;, &quot;cofinancier_4&quot;, &quot;cofinancier_5&quot;, &quot;cofinancier_6&quot;, &quot;kfw_bin&quot;, &quot;ffem_bin&quot;, &quot;nb_ap_nombre_potentiel&quot;, &quot;detail&quot;, &quot;iucn_cat&quot;, &quot;iucn_des&quot;, &quot;marine&quot;, &quot;superficie&quot;, &quot;status&quot;, &quot;status_yr&quot;, &quot;gov_type&quot;,&quot;own_type&quot;, &quot;mang_auth&quot;) #Confidential variables in the PAs dataset list_var_PA_conf = list_var_joint_conf = c(&quot;montant_prevu_concours_euro_octroi&quot;, &quot;mt_global_projet_prevu_devise&quot;, &quot;engagements_nets_euro_octroi&quot; , &quot;montant_total_projet&quot;, &quot;produit&quot;, &quot;libelle_produit&quot;, &quot;date_de_1er_versement_projet&quot;, &quot;dernier_versement_en_date_projet&quot;, &quot;date_signature_convention_cf&quot;, &quot;duree_du_concours_annee&quot;, &quot;duree_du_concours_annee_et_mois&quot;, &quot;beneficiaire_primaire&quot;, &quot;responsable_equipe_projet&quot;, &quot;directeur_trice_dagence&quot;, &quot;maitrise_ouvrage&quot; ) #Confidential variables among shapefiles list_var_shp_conf = c(&quot;mntnt&quot;, &quot;mtglb&quot;, &quot;e&quot;, &quot;mnt&quot;, &quot;prodt&quot;, &quot;lbllp&quot;, &quot;rspns&quot;, &quot;dr&quot;, &quot;detal&quot;, &quot;projt&quot;, &quot;cmmnt&quot;) base_nodupl_lea = #fread(&quot;data_tidy/base_nodupl_lea.xlsx&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_DesStat_nodupl_lea_pub.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) %&gt;% select(any_of(names(data_stat_nodupl))) #import a dataset with country anmes and corresponding ISO3 code data_iso = data_stat %&gt;% select(c(pays, iso3)) %&gt;% group_by(iso3) %&gt;% slice(1) base_nodupl_old = #fread(&quot;data_tidy/base_nodupl_old.csv&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_DesStat_nodupl_old_pub.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;))%&gt;% select(any_of(names(data_stat_nodupl))) %&gt;% select(-iso3) %&gt;% left_join(data_iso, by = &quot;pays&quot;) %&gt;% mutate(iso3 = case_when( pays %in% c(&quot;Mayotte&quot;, &quot;P-N N.Caléd&quot;, &quot;P-S N.Caléd&quot;, &quot;Polynesie Francaise&quot;, &quot;Nlle Caledonie&quot;) ~ &quot;FRA&quot;, pays == &quot;Multi-Pays&quot; ~ &quot;ZZ&quot;, !(pays %in% c(&quot;Mayotte&quot;, &quot;P-N N.Caléd&quot;, &quot;P-S N.Caléd&quot;, &quot;Polynesie Francaise&quot;, &quot;Nlle Caledonie&quot;, &quot;Multi-Pays&quot;)) ~ iso3 )) # projet_nodupl_old = # #readxl::read_xlsx(&quot;data_tidy/projet_nodupl_old.xlsx&quot;) # aws.s3::s3read_using( # FUN = readxl::read_xlsx, # # Mettre les options de FUN ici # object = &quot;data_tidy/projet_nodupl_old.xlsx&quot;, # bucket = &quot;projet-afd-eva-ap&quot;, # opts = list(&quot;region&quot; = &quot;&quot;)) bdd_joint = #fread(&quot;data_raw/BDD_joint.xlsx&quot;) aws.s3::s3read_using( FUN = data.table::fread, # Mettre les options de FUN ici encoding = &quot;UTF-8&quot;, object = &quot;data_tidy/BDD_joint_tidy_pub.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) %&gt;% select(any_of(names(data_stat_nodupl))) #Test : differences between Léa&#39;s figures and my results #PA identified with unique WDPAID. If more than 1 WDPAID, take the earlier annee_octroi base_id = data_stat %&gt;% filter(!is.na(wdpaid)) %&gt;% group_by(wdpaid) %&gt;% arrange(annee_octroi) %&gt;% slice(1) %&gt;% ungroup() test = base_id[duplicated(base_id$wdpaid),] base_old_id = base_nodupl_old %&gt;% filter(grepl(&quot;NA&quot;, wdpaid) == FALSE) %&gt;% group_by(wdpaid) %&gt;% slice(1) %&gt;% mutate(wdpaid = as.numeric(wdpaid)) %&gt;% ungroup() #Identify PA in common among them with WDPAID reported test_id = base_old_id %&gt;% select(c(id_projet, nom_du_projet, nom_ap, id_concours, wdpaid)) %&gt;% left_join(select(base_id, c(id_projet, nom_du_projet, nom_ap, id_concours, wdpaid)), by = &quot;wdpaid&quot;) #PA whose WDPAID is unknown, identified by id1 uniquely #The duplicates comes from different concours ID, so do not correspond to different PA base_na = data_stat %&gt;% filter(is.na(wdpaid)) %&gt;% mutate(id1 = paste(id_projet, iso3, nom_ap, sep = &quot;_&quot;), .before = id_projet) %&gt;% group_by(id1) %&gt;% arrange(annee_octroi) %&gt;% slice(1) %&gt;% ungroup() base_old_na = base_nodupl_old %&gt;% filter(grepl(&quot;NA&quot;, wdpaid) == TRUE) %&gt;% mutate(id1 = paste(id_projet, iso3, nom_ap, sep = &quot;_&quot;), .before = id_projet) %&gt;% group_by(id1) %&gt;% arrange(annee_octroi) %&gt;% slice(1) %&gt;% ungroup() test_na = base_na %&gt;% select(c(id1, id_projet, nom_du_projet, nom_ap, id_concours)) %&gt;% left_join(select(base_old_na, c(id1, id_projet, nom_du_projet, nom_ap, id_concours)), by = &quot;id1&quot;) nrow(test_na %&gt;% subset(is.na(id_projet.y) == TRUE)) #base_nodupl base_nodupl = rbind(select(base_na, -id1), base_id) "],["descriptive-statistics-on-biodiversity-in-the-protected-areas.html", "Chapter 3 Descriptive statistics on biodiversity in the protected areas 3.1 Importing packages and functions 3.2 Setting the environment 3.3 Importing PAs datasets 3.4 Downloading data of interests and compute relevant indicators 3.5 Computing statistics", " Chapter 3 Descriptive statistics on biodiversity in the protected areas In this document are computed and plotted descriptive statistics for the protected areas (PAs) using the mapme biodiversity package. This package provides an easy access to biodiversity-related data and allow to compute different indicators. 3.1 Importing packages and functions #{r setup, include=FALSE, eval = FALSE} #knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # source(&quot;scripts/Statistics/fns_DesStat_biodiv.R&quot;, encoding = &quot;utf-8&quot;) #The last version of mapme.biodiversity package is downloaded directly from github remotes::install_github(&quot;mapme-initiative/mapme.biodiversity&quot;, upgrade=&quot;always&quot;) library(mapme.biodiversity) library(sf) library(tidyverse) library(mapview) library(magrittr) library(stargazer) library(dplyr) library(openxlsx) library(writexl) library(ggplot2) library(questionr) library(readxl) library(data.table) library(sp) library(raster) library(terra) library(janitor) library(ARTofR) library(aws.s3) #A first look at mapme biodiversity indicators resources &lt;- names(available_resources()) indicators &lt;- names(available_indicators()) cat(paste(&quot;Supported resources:\\n-&quot;, paste(resources, collapse = &quot;\\n- &quot;), &quot;\\n\\nSupported indicators:\\n-&quot;, paste(indicators, collapse = &quot;\\n- &quot;))) 3.2 Setting the environment This might be necessary to access SSPCloud storage from mapme.biodiversity functions. # Sys.setenv(&quot;AWS_ACCESS_KEY_ID&quot; = &quot;GD8CI0UQQPTETOZS65J2&quot;, # &quot;AWS_SECRET_ACCESS_KEY&quot; = &quot;e0bsXE55qz+xmNeVdwhTb39wKoQuIJFC0Y6eqPoG&quot;, # &quot;AWS_DEFAULT_REGION&quot; = &quot;us-east-1&quot;, # &quot;AWS_SESSION_TOKEN&quot; = &quot;eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJHRDhDSTBVUVFQVEVUT1pTNjVKMiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNjg4NjUxNjk5LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6InZ1aWxsb3RhQGFmZC5mciIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJleHAiOjE2ODg3Mzg4NzgsImZhbWlseV9uYW1lIjoiVnVpbGxvdCIsImdpdmVuX25hbWUiOiJBbnRvaW5lIiwiZ3JvdXBzIjpbImFmZC1ldmEtYXAiXSwiaWF0IjoxNjg4NjUxNzAwLCJpc3MiOiJodHRwczovL2F1dGgubGFiLnNzcGNsb3VkLmZyL2F1dGgvcmVhbG1zL3NzcGNsb3VkIiwianRpIjoiN2ZmMjJhNmEtM2IyYS00NWFiLWJmYTItNmVhZDZkNzY5YzBhIiwibmFtZSI6IkFudG9pbmUgVnVpbGxvdCIsIm5vbmNlIjoiYjQzM2E1N2MtMjZiNS00NmE0LTkzOGItOGMyM2FmOTVlYTI5IiwicG9saWN5Ijoic3Rzb25seSIsInByZWZlcnJlZF91c2VybmFtZSI6InZ1aWxsb3RhIiwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iLCJkZWZhdWx0LXJvbGVzLXNzcGNsb3VkIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBncm91cHMgZW1haWwiLCJzZXNzaW9uUG9saWN5IjoiZXlKV1pYSnphVzl1SWpvaU1qQXhNaTB4TUMweE55SXNJbE4wWVhSbGJXVnVkQ0k2VzNzaVJXWm1aV04wSWpvaVFXeHNiM2NpTENKQlkzUnBiMjRpT2xzaWN6TTZLaUpkTENKU1pYTnZkWEpqWlNJNld5SmhjbTQ2WVhkek9uTXpPam82Y0hKdmFtVjBMV0ZtWkMxbGRtRXRZWEFpTENKaGNtNDZZWGR6T25Nek9qbzZjSEp2YW1WMExXRm1aQzFsZG1FdFlYQXZLaUpkZlN4N0lrVm1abVZqZENJNklrRnNiRzkzSWl3aVFXTjBhVzl1SWpwYkluTXpPa3hwYzNSQ2RXTnJaWFFpWFN3aVVtVnpiM1Z5WTJVaU9sc2lZWEp1T21GM2N6cHpNem82T2lvaVhTd2lRMjl1WkdsMGFXOXVJanA3SWxOMGNtbHVaMHhwYTJVaU9uc2ljek02Y0hKbFptbDRJam9pWkdsbVpuVnphVzl1THlvaWZYMTlMSHNpUldabVpXTjBJam9pUVd4c2IzY2lMQ0pCWTNScGIyNGlPbHNpY3pNNlIyVjBUMkpxWldOMElsMHNJbEpsYzI5MWNtTmxJanBiSW1GeWJqcGhkM002Y3pNNk9qb3FMMlJwWm1aMWMybHZiaThxSWwxOVhYMD0iLCJzZXNzaW9uX3N0YXRlIjoiYWYyMDdlY2UtOWEzNi00OTQyLTllODYtNjA1NTJmNGYxZTg1Iiwic2lkIjoiYWYyMDdlY2UtOWEzNi00OTQyLTllODYtNjA1NTJmNGYxZTg1Iiwic3ViIjoiOTI3N2Y3MzMtNTBmMy00MjM4LWI1YzctNjRjMmU4YTZiNDI0IiwidHlwIjoiQmVhcmVyIn0.40_wwJeo7HhTJjvPyob96nNEvbCmvohcN7Wnd02ETirLobdTmE7QZZbd9q5P1ZGANkkIkAf8who86ELp1crWfw&quot;, # &quot;AWS_S3_ENDPOINT&quot;= &quot;minio.lab.sspcloud.fr&quot;, # &quot;AWS_HTTPS&quot; = &quot;FALSE&quot;, # &quot;AWS_VIRTUAL_HOSTING&quot;=&quot;FALSE&quot;) 3.3 Importing PAs datasets #Load spatial data and transform into polygons (requirement of the mapme package) #If the function get_resources used later returns an error &quot;...Loop 0 is not valid: Edge 94 crosses edge 96&gt;...&quot;, then the following function might solve it. It works if sf was updated v1.0 and more, and brings back to old way of working. sf uses mostly a flat Earth model instead of s2 spherical geometry in the new versions. sf_use_s2(FALSE) #/!\\ : in pa_shp, variable sprfc is the area reported by AFD members, and is not equal to rep_a (area reported by WDPA) nor superficie in the BDD_joint. The latter is a combination of rep_a and sprfc, where superficie = rep_a except if rep_a = 0 or not reported. pa_shp = #read_sf(&quot;data_tidy/BDD_SHP_nodupl_pub.gpkg&quot;) %&gt;% aws.s3::s3read_using( FUN = sf::read_sf, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_shp_pub.gpkg&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) %&gt;% st_make_valid() %&gt;% sf::st_cast(to = &quot;POLYGON&quot;) #From BDD_joint, that is the combination of the SIOP dataset and the AP dataset from ARB team in AFD. Imported to have the information on the PA area (combination of areas reported by WDPA and ARB) pa_nodupl = #fread(&quot;data_tidy/BDD_DesStat_nodupl.csv&quot;) %&gt;% aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, object = &quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) %&gt;% dplyr::select(c(wdpaid, superficie)) #mapview(pa_shp) 3.4 Downloading data of interests and compute relevant indicators For the moment, mapme.biodiversity functions do not support reading/writing in a S3 server like SSPCloud. Waiting for the new release of the package, the following process is followed : Create a sub-folder in the temporary folder (RAM of the R session) to download and store the raw data Associate the portfolio to this sub-folder Download the raw data and compute the indicators of interest, unnest the data obtained Then, a dataframe can be saved. Note that this solution is not time-optimal : raw data must be downloaded each time. 3.4.1 Creating the portfolio #The raw data from mapme package are stored in a temporary folder tmp = paste(tempdir(), &quot;mapme&quot;, sep = &quot;/&quot;) #save_folder = get_bucket(&quot;projet-afd-eva-ap&quot;, region = &quot;&quot;) #Creating the portfolio pa_pfolio = pa_shp %&gt;% init_portfolio(2000:2020, outdir = tmp, #cores = 4, add_resources = TRUE, verbose = TRUE) 3.4.2 TEST : importing data from SSPCloud data are downloaded from an other script and stored in the SSPCloud. Here : copy these data to the temporary storage of the R session, and use them to compute indicators. df_files = aws.s3::get_bucket(&quot;projet-afd-eva-ap&quot;, prefix = &quot;data_raw/mapme_bio_data/gfw_treecover/&quot;, region = &quot;&quot;) %&gt;% as.data.frame() list_files = df_files$Key i = list_files[1] for (i in list_files) { temp_file = s3read_using(FUN = terra::rast, object = i, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot;=&quot;&quot;)) terra::writeRaster(temp_file, file.path(tempdir(), &quot;test.tif&quot;), overwrite = TRUE) } plot(temp_file) 3.4.3 Compute indicators from geospatial data ##~~~~~~~~~~~~~~~~ ## ~ Forests ---- ##~~~~~~~~~~~~~~~~ ##Downloading data and computing indicators pa_pfolio_tcover = get_resources(pa_pfolio, resources = c(&quot;gfw_lossyear&quot;,&quot;gfw_treecover&quot;,&quot;gfw_emissions&quot;), vers_treecover = &quot;GFC-2020-v1.8&quot;, vers_lossyear = &quot;GFC-2020-v1.8&quot;) %&gt;% # FAO forest definition here: Minimum treecover = 10%, minimum size =1 hectare calc_indicators(indicators = &quot;treecover_area&quot;, min_cover = 10, min_size = 1, overwrite=T) #Unest the sf file into a classic data frame without geometry data_pfolio_tcover = unnest(pa_pfolio_tcover, cols=&quot;treecover_area&quot;) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(wdpaid, assetid, years,treecover) %&gt;% mutate(treecover = case_when(treecover == 0 ~ NA, TRUE ~ treecover)) %&gt;% filter(!is.na(treecover)) #Write the dataframe into the bucket s3write_using(data_pfolio_tcover, data.table::fwrite, object = &quot;data_tidy/mapme_bio_data/data_pfolio_tcover.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;) ) #Copying files to SSPCloud ##emissions files_emi &lt;- list.files(paste(tmp, &quot;gfw_emissions&quot;, sep = &quot;/&quot;), full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files_emi) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_emissions&quot;, region = &quot;&quot;, show_progress = TRUE) } ##loss years files_lossyear &lt;- list.files(paste(tmp, &quot;gfw_lossyear&quot;, sep = &quot;/&quot;), full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files_emi) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_lossyear&quot;, region = &quot;&quot;, show_progress = TRUE) } ##Treecover loss files_treecover &lt;- list.files(paste(tmp, &quot;gfw_treecover&quot;, sep = &quot;/&quot;), full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files_emi) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_treecover&quot;, region = &quot;&quot;, show_progress = TRUE) } #Removing files from temp do.call(file.remove, list(list.files(paste(tmp, &quot;gfw_emissions&quot;, sep = &quot;/&quot;), full.names = TRUE))) do.call(file.remove, list(list.files(paste(tmp, &quot;gfw_lossyear&quot;, sep = &quot;/&quot;), full.names = TRUE))) do.call(file.remove, list(list.files(paste(tmp, &quot;gfw_treecover&quot;, sep = &quot;/&quot;), full.names = TRUE))) ##~~~~~~~~~~~~~~~~~~ ## ~ Mangroves ---- ##~~~~~~~~~~~~~~~~~~ ##Downloading data and computing indicators pa_pfolio_mang = get_resources(pa_pfolio, resources = c(&quot;gmw&quot;)) %&gt;% # FAO forest definition here: Minimum treecover = 10%, minimum size =1 #hectare calc_indicators(indicators = &quot;mangroves_area&quot;, overwrite=T) ##Unest the sf file into a classic data frame without geometry data_pfolio_mang = unnest(pa_pfolio_mang, cols=&quot;mangroves_area&quot;) %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(wdpaid, assetid, year,mangrove_extent) # s3write_using(data_pfolio_mang, # data.table::fwrite, # object = &quot;data_tidy/mapme_bio_data/data_pfolio_mang.csv&quot;, # bucket = &quot;projet-afd-eva-ap&quot;, # opts = list(&quot;region&quot; = &quot;&quot;) # ) # data_pfolio_mang = s3read_using(data.table::fread, # object = &quot;data_tidy/mapme_bio_data/data_pfolio_mang.csv&quot;, # bucket = &quot;projet-afd-eva-ap&quot;, # opts = list(&quot;region&quot; = &quot;&quot;) # ) #Removing files from temp ##emissions files_mang &lt;- list.files(paste(tmp, &quot;gmw&quot;, sep = &quot;/&quot;), full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files_mang) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/data_raw/mapme_bio_data/gmw&quot;, region = &quot;&quot;, show_progress = TRUE) } do.call(file.remove, list(list.files(paste(tmp, &quot;gmw&quot;, sep = &quot;/&quot;), full.names = TRUE))) ##~~~~~~~~~~~~~~~~~~~~ ## ~ Land cover -- ##~~~~~~~~~~~~~~~~~~~~ ##Downloading data and computing indicators pa_pfolio_land = get_resources(pa_pfolio, resources = c(&quot;esalandcover&quot;)) %&gt;% calc_indicators(indicators = &quot;landcover&quot;, overwrite=T) ##Unnest data data_pfolio_land = unnest(pa_pfolio_land, cols = &quot;landcover&quot;) %&gt;% st_drop_geometry() %&gt;% dplyr::select(wdpaid, assetid, year, area, classes) s3write_using(data_pfolio_land, data.table::fwrite, object = &quot;data_tidy/mapme_bio_data/data_pfolio_land.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;) ) # data_pfolio_land = s3read_using(data.table::fread, # object = &quot;data_tidy/mapme_bio_data/data_pfolio_land.csv&quot;, # bucket = &quot;projet-afd-eva-ap&quot;, # opts = list(&quot;region&quot; = &quot;&quot;) # ) ##~~~~~~~~~~~~~~~~~~~ ## ~ Emissions ---- ##~~~~~~~~~~~~~~~~~~~ # pa_pfolio_emi = # get_resources(pa_pfolio, # resources = c(&quot;gfw_lossyear&quot;,&quot;gfw_treecover&quot;,&quot;gfw_emissions&quot;), # vers_treecover = &quot;GFC-2020-v1.8&quot;, # vers_lossyear = &quot;GFC-2020-v1.8&quot;) %&gt;% # calc_indicators(indicators = &quot;treecoverloss_emissions&quot;, # min_cover = 30, # min_size = 1, overwrite=T) # write_portfolio(pa_pfolio_emi, # dsn = &quot;data_tidy/mapme_bio_data/pa_pfolio_emi.gpkg&quot;, # overwrite = FALSE) pa_pfolio_emi = read_portfolio(&quot;data_tidy/mapme_bio_data/pa_pfolio_emi.gpkg&quot;) # data_pfolio_emi = unnest(pa_pfolio_emi, # cols=&quot;treecoverloss_emissions&quot;) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::select(id_pr,wdpaid,years,emissions) # fwrite(data_pfolio_emi, # &quot;data_tidy/mapme_bio_data/data_pfolio_emi.csv&quot;) data_pfolio_emi = fread(&quot;data_tidy/mapme_bio_data/data_pfolio_emi.csv&quot;) ##~~~~~~~~~~~~~~~~~~~~ ## ~ Biome ---- ##~~~~~~~~~~~~~~~~~~~~ ##Downloading data and computing indicators pa_pfolio_biome = get_resources(pa_pfolio, resources = c(&quot;teow&quot;)) %&gt;% calc_indicators(indicators = &quot;biome&quot;, overwrite=T) # write_portfolio(pa_pfolio_biome, # dsn = &quot;01_data_tidy/mapme_bio_data/pa_pfolio_biome.gpkg&quot;, # overwrite = FALSE) ##Unest the sf file into a classic data frame without geometry # data_biome = unnest(pa_pfolio_biome, cols=&quot;biome&quot;) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::select(id_pr,wdpaid,year,mangrove_extent) ##~~~~~~~~~~~~~~~~~~~~ ## ~ Soil features -- ##~~~~~~~~~~~~~~~~~~~~ #/!\\ voir quels indicateurs/mesures prendre !! ##Downloading data and computing indicators pa_pfolio_soil = get_resources(pa_pfolio, resources = c(&quot;soilgrids&quot;)) %&gt;% # FAO forest definition here: Minimum treecover = 10%, minimum size =1 #hectare calc_indicators(indicators = &quot;soilproperties&quot;, overwrite=T) # write_portfolio(pa_pfolio_mang, # dsn = &quot;01_data_tidy/mapme_bio_data/pa_pfolio_mang.gpkg&quot;, # overwrite = FALSE) ##Unest the sf file into a classic data frame without geometry # data_biome = unnest(pa_pfolio_biome, cols=&quot;biome&quot;) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::select(id_pr,wdpaid,year,mangrove_extent) ##~~~~~~~~~~~~~~~~~~~~ ## ~ Accessibility -- ##~~~~~~~~~~~~~~~~~~~~ ##Downloading data and computing indicators pa_pfolio_acc = get_resources(&quot;nelson_et_al&quot;, range_traveltime = c(&quot;5k_10k&quot;, &quot;100k_200k&quot;, &quot;500k_1mio&quot;, &quot;1mio_5mio&quot;)) %&gt;% calc_indicators(&quot;traveltime&quot;, stats_accessibility = c(&quot;min&quot;, &quot;max&quot;), engine = &quot;extract&quot;) # write_portfolio(pa_pfolio_mang, # dsn = &quot;01_data_tidy/mapme_bio_data/pa_pfolio_mang.gpkg&quot;, # overwrite = FALSE) ##Unest the sf file into a classic data frame without geometry # data_biome = unnest(pa_pfolio_biome, cols=&quot;biome&quot;) %&gt;% # sf::st_drop_geometry() %&gt;% # dplyr::select(id_pr,wdpaid,year,mangrove_extent) Faire une fonction pour l’extraction de tout jeu de données ? Répétitif en soit de faire forêts, mangroves, etc. Warning and errors face and their meaning. although coordinates are longitude/latitude, st_intersects assumes that they are planar. See https://r-spatial.org/r/2020/06/17/s2.html and https://r-spatial.github.io/sf/articles/sf7.html#. Basically I used sf_use_s2(FALSE) at the creation of the portfolio. Thus sf uses flat Earth model instead of s2 spherical geometry. The operation st_intersects assumes the data lie in a flat plane where one degree longitude equals one degree latitude, irrespective where the PA is on the world (equirectangular projection). Thus if the polygons are drawn from coordinates in a spherical geometry, the operation is performed on the wrong projection. Is it a problem in itself ? Well as a projection is a bijection between two coordinate systems, plygons that intersect (or not) in a projection will intersect in the second. However the polygons will be distorded (the more so as they are located closer to the poles), and the areas computed could be wrong. Anyway according to the documentation the WDPA polygons are provided in WGS84 geographic coordinate system, i.e a planar projection (Plate Carree) . No problem should arise from the warning then. So according to Florent Bedecarrats, this warning is related to an other issue. The sphere representing the Earth is transformed into a plane through a cut on a given line. If a polygon is located on this line, the flattened polygon is considered to go around the Earth. To test for this possibility, compare the area of the polygon to the true area of the PA. Avis : TIFFFillStrip:Read error at scanline 4294967295; got 0 bytes, expected 1387 (GDAL error 1)Avis : TIFFReadEncodedStrip() failed. (GDAL error 1). This advice occurs during the computation of indicators (a few tenths for emissions). Fail to read some parts of the raster file ? Is it problematic for the whole process ? Best solution : remove the corresponding TIFF and download data again. Avis : D:/projet_AiresProtegees/00_data_raw/mapme_bio_data/gfw_lossyear/Hansen_GFC-2020-v1.8_lossyear_10N_010E.tif, band 1: IReadBlock failed at X offset 0, Y offset 29995: TIFFReadEncodedStrip() failed. (GDAL error 1) Same as before. Best solution : remove the corresponding TIFF and download data again. Avis : Error : [crop] incorrect number of values (too many) for writing Check the error in more details. 3.5 Computing statistics From the datasets obtained, statistics of interest can be computed and plotted. 3.5.1 Forests Variation of forest loss over time : Building the figure dataset #Building the dataset data_stat_treeloss = data_pfolio_forest %&gt;% group_by(nm_ap) %&gt;% #Comoute variation over time in each PA mutate(lag_treecov = lag(treecover), loss = ((treecover - lag_treecov)/lag_treecov)*100) %&gt;% ungroup() %&gt;% #Regroup years for analysis in five years intervals mutate(years_regroup = case_when( years &lt;= 2005 ~ &quot;2000-2005&quot;, years &lt;= 2010 ~ &quot;2005-2010&quot;, years &lt;= 2015 ~ &quot;2010-2015&quot;, years &lt;=2020 ~ &quot;2015-2020&quot;, TRUE ~ NA), .after = years) %&gt;% #Remove NA values for loss filter(!is.na(loss)) %&gt;% #Compute mean loss for five years intervals in each PA group_by(nm_ap, years_regroup) %&gt;% mutate(moy_5 = mean(loss)) %&gt;% ungroup() Statistics at PA level #Evolution for a given PA ##Buba stat_forest_buba = stat_treeloss_id(df = data_stat_treeloss, id = &quot;317051&quot;, name_pa = &quot;AP Buba&quot;, treatment_yr = 2007) fig_evo_buba = stat_forest_buba[[1]] ggsave(plot = fig_evo_buba, filename = &quot;fig_forest_loss_evo_ap_buba.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) fig_evo5_buba = stat_forest_buba[[2]] ggsave(plot = fig_evo5_buba, filename = &quot;fig_forest_loss_evo5_ap_buba.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) #Niumi stat_forest_niumi = stat_treeloss_id(df = data_stat_treeloss, id = &quot;109037&quot;, name_pa = &quot;AP Niumi&quot;, treatment_yr = 2008) fig_evo_niumi = stat_forest_niumi[[1]] ggsave(plot = fig_evo_niumi, filename = &quot;fig_forest_loss_evo_ap_niumi.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) fig_evo5_niumi = stat_forest_niumi[[2]] ggsave(plot = fig_evo5_niumi, filename = &quot;fig_forest_loss_evo5_ap_niumi.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) #Bamboung stat_forest_bamboung = stat_treeloss_id(df = data_stat_treeloss, id = &quot;555651496&quot;, name_pa = &quot;AP Bamboung&quot;, treatment_yr = 2008) fig_evo_bamboung = stat_forest_bamboung[[1]] ggsave(plot = fig_evo_bamboung, filename = &quot;fig_forest_loss_evo_ap_bamboung.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) fig_evo5_bamboung = stat_forest_bamboung[[2]] ggsave(plot = fig_evo5_bamboung, filename = &quot;fig_forest_loss_evo5_ap_bamboung.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) /! Modifier le code précédent pour inclure plusieurs aires ??? Statistics at region level #Evolution at region level : dataset data_stat_treeloss_reg = data_stat_treeloss %&gt;% group_by(drct, years) %&gt;% #For each region and each period, compute average evolution mutate(evo_avg_reg = mean(treecover)) %&gt;% ungroup() %&gt;% group_by(drct) %&gt;% #Variation of the average evolution over time in each region mutate(lag_region = lag(evo_avg_reg), loss_region = ((evo_avg_reg - lag_region)/lag_region)*100) %&gt;% #remove 2001 : either NA, or take value above when two regions are consecutive in the data frame (lag by region not applied) ??? mutate(loss_region = case_when( !is.na(loss_region) &amp; years == 2001 ~ NA, TRUE ~loss_region)) #Sahel fig_evo_sahel = stat_treeloss_reg(df = data_stat_treeloss_reg, reg = &quot;Dr Grand Sahel&quot;, name_reg = &quot;Sahel&quot;) ggsave(plot = fig_evo_sahel, filename = &quot;fig_forest_loss_evo_reg_sahel.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) #Guinea gulf fig_evo_guinee = stat_treeloss_reg(df = data_stat_treeloss_reg, reg = &quot;Dr Golfe De Guinee&quot;, name_reg = &quot;Golfe de Guinée&quot;) ggsave(plot = fig_evo_guinee, filename = &quot;fig_forest_loss_evo_reg_guinee.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) #Eastern Africa fig_evo_eastAf = stat_treeloss_reg(df = data_stat_treeloss_reg, reg = &quot;Dr Afrique De L&#39;Est&quot;, name_reg = &quot;Afrique de l&#39;Est&quot;) ggsave(plot = fig_evo_eastAf, filename = &quot;fig_forest_loss_evo_reg_eastAf.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) #Eastern Africa fig_evo_austAf = stat_treeloss_reg(df = data_stat_treeloss_reg, reg = &quot;Dr Afrique Australe&quot;, name_reg = &quot;Afrique australe&quot;) ggsave(plot = fig_evo_austAf, filename = &quot;fig_forest_loss_evo_reg_austAf.png&quot;, path = &quot;05_StatDes/biodiversity/forest/loss&quot;, width = 7, height = 5) 3.5.2 Mangrove Summary table of mangrove area in each PA : tbl_mang_summary = data_mang %&gt;% dplyr::group_by(wdpaid) %&gt;% summarize(area_sqkm = sum(value)) 3.5.3 Emissions /! pas clair Summary table of emissions in each PA : # create summary table tbl_emi_summary = data_emi %&gt;% group_by(name) %&gt;% summarize(area_sqkm = sum(value)) 3.5.4 Biome/TEOW "],["descriptive-statistics-on-projects-funded-by-the-afd.html", "Chapter 4 Descriptive statistics on projects funded by the AFD 4.1 Importing packages 4.2 Importing datasets 4.3 Performing descriptive statistics", " Chapter 4 Descriptive statistics on projects funded by the AFD In this document are performed and plotted descriptive statistics from the datasets built in buildingDB_PA_WDPA. The following statistics are derived : Distribution of parcels among IUCN categories, at country, region and world level. Distribution in terms of ecosystems Distribution of PAs across countries and regions 4.1 Importing packages #{r setup, include=FALSE, eval = FALSE} #knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # library(tidyverse) library(stargazer) library(dplyr) library(ggplot2) library(ggrepel) library(RColorBrewer) library(data.table) #library(readxl) #library(splitstackshape) library(janitor) library(xtable) library(questionr) library(tidyterra) library(terra) library(sf) library(mapview) library(aws.s3) 4.2 Importing datasets #Both datasets are imported also in UTF8 encoding, for some variables ##A first dataset with some PA on more than one row (one line per funding for instance) data_stat = #fread(&quot;data_tidy/BDD_DesStat_nofund.csv&quot;, encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_DesStat_nofund.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) ##A second dataset with one line per PA, more suited for some statistics data_stat_nodupl = #fread(&quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot; , encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) pa_area_ctry = #fread(&quot;data_tidy/area/pa_area_ctry.csv&quot;, encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/area/pa_area_ctry.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) pa_area_dr = #fread(&quot;data_tidy/area/pa_area_dr.csv&quot;, encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/area/pa_area_dr.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) pa_area_wld = #fread(&quot;data_tidy/area/pa_area_wld.csv&quot;, encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/area/pa_area_wld.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) pa_int_yr = #fread(&quot;data_tidy/area/pa_area_dr.csv&quot;, encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/area/pa_int_yr.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) 4.3 Performing descriptive statistics 4.3.1 IUCN categories 4.3.1.1 Share of PAs by IUCN categories #Building the relevant dataset ##For all PAs .. data_cat_iucn = data_stat_nodupl %&gt;% group_by(iucn_des) %&gt;% #number of PAs per IUCN category summarize(n_iucn = n()) %&gt;% ungroup() %&gt;% #Frequency of IUCN categories mutate(n_pa = sum(n_iucn), freq_iucn = round(n_iucn/n_pa*100, 1)) %&gt;% arrange(desc(iucn_des)) %&gt;% mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) ##... and for referenced PAs only data_cat_iucn_ref = data_stat_nodupl %&gt;% #Remove not referenced PAs subset(!(iucn_des %in% c(&quot;Non catégorisée&quot;, &quot;Non référencée&quot;))) %&gt;% group_by(iucn_des) %&gt;% #number of PAs per IUCN category summarize(n_iucn = n()) %&gt;% ungroup() %&gt;% #Frequency of IUCN categories mutate(n_pa = sum(n_iucn), freq_iucn = round(n_iucn/n_pa*100, 1)) %&gt;% arrange(freq_iucn) %&gt;% mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) #Latex table tbl_cat_iucn = data_cat_iucn %&gt;% select(c(iucn_des, n_iucn, freq_iucn)) names(tbl_cat_iucn) &lt;- c(&quot;Catégories IUCN&quot;,&quot;Nombre d&#39;AP&quot;, &quot;Proportion d&#39;AP (%)&quot;) tbl_cat_iucn_ref = data_cat_iucn_ref %&gt;% select(c(iucn_des, n_iucn, freq_iucn)) names(tbl_cat_iucn_ref) &lt;- c(&quot;Catégories IUCN&quot;,&quot;Nombre d&#39;AP&quot;, &quot;Proportion d&#39;AP (%)&quot;) #Histogram including non-referenced PAs hist_cat_iucn = ggplot(data_cat_iucn, aes(x = reorder(iucn_des, -freq_iucn), y = freq_iucn, fill = iucn_des)) %&gt;% + geom_bar(stat = &quot;identity&quot;, width = 0.50, fill=&quot;#3182BD&quot;) %&gt;% + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par catégorie IUCN&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_cat_iucn$n_iucn), &quot;aires protégées. Nombre d&#39;aires indiqué sur les barres.&quot;), x = &quot;Catégories IUCN&quot;, y = &quot;Nombre (%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_cat_iucn #Histogram excluding non-referenced PAs hist_cat_iucn_ref = ggplot(data_cat_iucn_ref, aes(x = reorder(iucn_des, -freq_iucn), y = freq_iucn, fill = iucn_des)) %&gt;% + geom_bar(stat = &quot;identity&quot;, width = 0.50, fill=&quot;#3182BD&quot;) %&gt;% + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par catégorie IUCN (hors AP non-répertoriées)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_cat_iucn_ref$n_iucn), &quot;aires protégées. Nombre d&#39;aires indiqué sur les barres.&quot;), x = &quot;Catégories IUCN&quot;, y = &quot;Nombre (%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_cat_iucn_ref #Pie chart INcluding non-referenced PAs pie_cat_iucn = ggplot(data_cat_iucn, aes(x=&quot;&quot;, y= freq_iucn, fill = iucn_des)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;, color=&quot;white&quot;) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% # + geom_label(aes(x=1.4, label = paste0(freq_iucn, &quot;%&quot;)), # color = &quot;white&quot;, # position = position_stack(vjust = 0.7), size=2.5, # show.legend = FALSE) %&gt;% + labs(x = &quot;&quot;, y = &quot;&quot;, title = &quot;Proportion d&#39;aires protégées par catégorie IUCN (%)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_cat_iucn$n_iucn), &quot;aires protégées&quot;)) %&gt;% + scale_fill_brewer(name = &quot;Catégories&quot;, palette = &quot;Dark2&quot;) %&gt;% + theme_void() pie_cat_iucn #Pie chart EXcluding non-referenced PAs pie_cat_iucn_ref = ggplot(data_cat_iucn_ref, aes(x=&quot;&quot;, y= freq_iucn, fill = iucn_des)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;, color=&quot;white&quot;) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), &quot;%&quot;)), color = &quot;white&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% # + geom_label(aes(x=1.4, label = paste0(freq_iucn, &quot;%&quot;)), # color = &quot;white&quot;, # position = position_stack(vjust = 0.7), size=2.5, # show.legend = FALSE) %&gt;% + labs(x = &quot;&quot;, y = &quot;&quot;, title = &quot;Proportion d&#39;aires protégées par catégorie IUCN \\nhors aires non répertoriées (%)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_cat_iucn_ref$n_iucn), &quot;aires protégées&quot;)) %&gt;% + scale_fill_brewer(name = &quot;Catégories&quot;, palette = &quot;Dark2&quot;) %&gt;% + theme_void() pie_cat_iucn_ref #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;hist_cat_iucn.png&quot;, sep = &quot;/&quot;), plot = hist_cat_iucn, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_cat_iucn_ref.png&quot;, sep = &quot;/&quot;), plot = hist_cat_iucn_ref, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;pie_cat_iucn.png&quot;, sep = &quot;/&quot;), plot = pie_cat_iucn, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;pie_cat_iucn_ref.png&quot;, sep = &quot;/&quot;), plot = pie_cat_iucn_ref, device = &quot;png&quot;, height = 6, width = 9) print(xtable(tbl_cat_iucn, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_cat_iucn.tex&quot;, sep = &quot;/&quot;)) print(xtable(tbl_cat_iucn_ref, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_cat_iucn_ref.tex&quot;, sep = &quot;/&quot;)) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/IUCN&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.1.2 IUCN categories by countries and regions #Build the distribution of IUCN categories at country level ... data_iucn_ctry = table(data_stat_nodupl$iucn_des, data_stat_nodupl$iso3) %&gt;% #Create a table with all iucn categories for each country, and compute the frequencies in percent prop.table(2) %&gt;% as.data.frame() %&gt;% mutate(Freq = round(Freq, 3)*100) %&gt;% pivot_wider(names_from = Var2, values_from = Freq) %&gt;% rename(&quot;iucn_des&quot; = &quot;Var1&quot;) #... and regional level data_iucn_reg = table(data_stat_nodupl$iucn_des, data_stat_nodupl$direction_regionale) %&gt;% #Create a table with all iucn categories for each country, and compute the frequencies in percent prop.table(2) %&gt;% as.data.frame() %&gt;% mutate(Freq = round(Freq, 3)*100) %&gt;% pivot_wider(names_from = Var2, values_from = Freq) %&gt;% rename(&quot;iucn_des&quot; = &quot;Var1&quot;) #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) print(xtable(data_iucn_ctry, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_iucn_ctry.tex&quot;, sep = &quot;/&quot;)) print(xtable(data_iucn_reg, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_iucn_reg.tex&quot;, sep = &quot;/&quot;)) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) for(f in files) { cat(&quot;Uploading file&quot;, paste0(&quot;&#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/IUCN&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.2 Ecosystems (excluding non-referenced PAs) 4.3.2.1 Proportion of PAs by marine or terrestrial areas #Build datasets data_eco = data_stat_nodupl %&gt;% #subset non-referencded PAs (have NA ecosysteme) subset(is.na(marine) == FALSE) %&gt;% mutate(marine = as.factor(marine)) data_eco$ecosyst_en = fct_recode(data_eco$marine, &quot;Terrestrial&quot;=&quot;0&quot;, &quot;Coastal&quot;=&quot;1&quot;, &quot;Marine&quot;=&quot;2&quot;) data_eco$ecosyst_fr = fct_recode(data_eco$marine, &quot;Terrestre&quot;=&quot;0&quot;, &quot;Côtier&quot;=&quot;1&quot;, &quot;Marin&quot;=&quot;2&quot;) data_eco_hist = data_eco %&gt;% group_by(ecosyst_en, ecosyst_fr) %&gt;% summarize(n = n(), freq = round(n/nrow(data_eco), 1)*100) %&gt;% ungroup() tbl_eco_world_fr = data_eco_hist %&gt;% select(c(ecosyst_fr, n, freq)) %&gt;% rename(&quot;Ecosystème&quot; = &quot;ecosyst_fr&quot;, &quot;Nombre d&#39;AP&quot; = &quot;n&quot;, &quot;Proportion d&#39;AP(%)&quot; = &quot;freq&quot;) tbl_eco_world_en = data_eco_hist %&gt;% select(c(ecosyst_en, n, freq)) %&gt;% rename(&quot;Ecosystem&quot; = &quot;ecosyst_en&quot;, &quot;Number of PAs&quot; = &quot;n&quot;, &quot;Share of PAs(%)&quot; = &quot;freq&quot;) #Histogram in share (in French) hist_eco_shr_fr = ggplot(data_eco_hist, aes(x = ecosyst_fr, y = freq, fill = ecosyst_fr)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = freq), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par type d&#39;écosystème \\n(hors AP non-référencées)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_eco_hist$n), &quot;aires protégées. Nombre d&#39;aires indiqué sur les barres.&quot;), x = &quot;Type d&#39;écosystème&quot;, y = &quot;Proportion d&#39;aires protégées(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_eco_shr_fr # #Histogram in share (in English) hist_eco_shr_en = ggplot(data_eco_hist, aes(x = ecosyst_en, y = freq, fill = ecosyst_en)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = freq), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion of protected areas by ecosystem type \\n(excluding non-references PAs)&quot;, subtitle = paste(&quot;Sample :&quot;, sum(data_eco_hist$n), &quot;protected areas. Number of areas indicated above.&quot;), x = &quot;Ecosystem type&quot;, y = &quot;Proportion of protected areas(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) #hist_eco_shr_en #Histogram in number (in French) hist_eco_n_fr = ggplot(data_eco_hist, aes(x = ecosyst_fr, y = n, fill = ecosyst_fr)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par type d&#39;écosystème \\n(hors AP non-référencées)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_eco_hist$n), &quot;aires protégées&quot;), x = &quot;Type d&#39;écosystème&quot;, y = &quot;Proportion d&#39;aires protégées&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_eco_n_fr #Histogram in number (in English) hist_eco_n_en = ggplot(data_eco_hist, aes(x = ecosyst_en, y = n, fill = ecosyst_en)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + labs(title = &quot;Proportion of protected areas by ecosystem type \\n(excluding non-referenced PAs)&quot;, subtitle = paste(&quot;Sample :&quot;, sum(data_eco_hist$n), &quot;protected areas&quot;), x = &quot;Ecosystem type&quot;, y = &quot;Proportion of protected areas&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) #hist_eco_n_en #Pie chart (in French) pie_eco_fr = ggplot(data_eco_hist, aes(x = &quot;&quot;, y = freq, fill = ecosyst_fr)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;,color=&quot;white&quot;) %&gt;% + geom_label(aes(x=1.3, label = paste0(freq, &quot;%&quot;)), color = &quot;black&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par type d&#39;écosystème \\n(hors AP non-référencées)&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_eco_hist$n), &quot;aires protégées&quot;), x = &quot;Type d&#39;écosystème&quot;, y = &quot;Proportion d&#39;aires protégées&quot;) %&gt;% + scale_fill_brewer(name = &quot;Ecosystème&quot;, palette=&quot;Paired&quot;) %&gt;% + theme_void() #pie_eco_fr #Histogram in number (in English) pie_eco_en = ggplot(data_eco_hist, aes(x = &quot;&quot;, y = n, fill = ecosyst_en)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;,color=&quot;white&quot;) %&gt;% + geom_label(aes(x=1.3, label = paste0(freq, &quot;%&quot;)), color = &quot;black&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + labs(title = &quot;Proportion of protected areas by ecosystem type \\n(exluding non-referenced PAs)&quot;, subtitle = paste(&quot;Sample :&quot;, sum(data_eco_hist$n), &quot;protected areas&quot;), x = &quot;Ecosystem type&quot;, y = &quot;Proportion of protected areas&quot;) %&gt;% + scale_fill_brewer(name = &quot;Ecosystem&quot;, palette=&quot;Paired&quot;) %&gt;% + theme_void() pie_eco_en #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;hist_eco_shr_fr.png&quot;, sep = &quot;/&quot;), plot = hist_eco_shr_fr, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_eco_shr_en.png&quot;, sep = &quot;/&quot;), plot = hist_eco_shr_en, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_eco_n_fr.png&quot;, sep = &quot;/&quot;), plot = hist_eco_n_fr, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_eco_n_en.png&quot;, sep = &quot;/&quot;), plot = hist_eco_n_en, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;pie_eco_fr.png&quot;, sep = &quot;/&quot;), plot = pie_eco_fr, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;pie_eco_en.png&quot;, sep = &quot;/&quot;), plot = pie_eco_en, device = &quot;png&quot;, height = 6, width = 9) print(xtable(tbl_eco_world_fr, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_ecosyst_fr.tex&quot;, sep = &quot;/&quot;)) print(xtable(tbl_eco_world_en, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_ecosyst_en.tex&quot;, sep = &quot;/&quot;)) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/ecosysteme&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.3 Distribution of PAs across countries and regions 4.3.3.1 Statistics at country level data_distrib_ctry = data_stat_nodupl %&gt;% group_by(pays, iso3) %&gt;% summarize(n = n(), freq = round(n/nrow(data_stat_nodupl), 1)*100) %&gt;% ungroup() data_distrib_ctry_top = data_distrib_ctry %&gt;% subset(freq &gt;= 5) #Histogram in share (in French) for top countries hist_distrib_ctry_top_shr_fr = ggplot(data_distrib_ctry_top, aes(x = reorder(pays, -freq), y = freq, fill = pays)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = freq), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Les pays abritant le plus d&#39;aires protégées&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_distrib_ctry$n), &quot;aires protégées. Nombre d&#39;aires indiqué à la base du graphique&quot;), x = &quot;Pays&quot;, y = &quot;Proportion d&#39;aires protégées(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_distrib_ctry_top_shr_fr # #Histogram in number (in French) hist_distrib_ctry_n_fr = ggplot(data_distrib_ctry, aes(x = reorder(pays, -n), y = n, fill = pays)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = n), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par pays&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_distrib_ctry$n), &quot;aires protégées. Nombre d&#39;aires indiqué sur chaque barre&quot;), x = &quot;Pays&quot;, y = &quot;Proportion d&#39;aires protégées(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_distrib_ctry_n_fr # #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;hist_distrib_ctry_top_shr_fr.png&quot;, sep = &quot;/&quot;), plot = hist_distrib_ctry_top_shr_fr, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_distrib_ctry_n_fr.png&quot;, sep = &quot;/&quot;), plot = hist_distrib_ctry_n_fr, device = &quot;png&quot;, height = 6, width = 9) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/distribution&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.3.2 Statistics at region level data_distrib_reg = data_stat_nodupl %&gt;% group_by(direction_regionale) %&gt;% summarize(n = n(), freq = round(n/nrow(data_stat_nodupl), 3)*100) %&gt;% ungroup() %&gt;% mutate(region = gsub(&quot;Dr &quot;, &quot;&quot;, direction_regionale), .after = &quot;direction_regionale&quot;) data_distrib_reg_top = data_distrib_reg %&gt;% subset(freq &gt;= 5) #Histogram in share (in French) for top countries hist_distrib_reg_top_shr_fr = ggplot(data_distrib_reg_top, aes(x = reorder(region, -freq), y = freq, fill = region)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = freq), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Les directions régionales finançant le plus d&#39;aires protégées&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_distrib_reg$n), &quot;aires protégées. Nombre d&#39;aires indiqué sur chaque barre.&quot;), x = &quot;Direction régionale&quot;, y = &quot;Proportion d&#39;aires protégées(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_distrib_reg_top_shr_fr # #Histogram in number (in French) hist_distrib_reg_n_fr = ggplot(data_distrib_reg, aes(x = reorder(direction_regionale, -n), y = n, fill = direction_regionale)) %&gt;% + geom_bar(width = 0.50, fill= &quot;#3182BD&quot;, stat=&quot;identity&quot;) %&gt;% + geom_text(aes(label = round(n, 1), y = n), vjust = -0.1, color=&quot;black&quot;, size=3.5) %&gt;% + labs(title = &quot;Proportion d&#39;aires protégées par région&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_distrib_ctry$n), &quot;aires protégées. Nombre d&#39;aires indiqué sur chaque barre.&quot;), x = &quot;Direction régionale&quot;, y = &quot;Proportion d&#39;aires protégées(%)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) hist_distrib_reg_n_fr #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;hist_distrib_reg_top_shr_fr.png&quot;, sep = &quot;/&quot;), plot = hist_distrib_reg_top_shr_fr, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;hist_distrib_reg_n_fr.png&quot;, sep = &quot;/&quot;), plot = hist_distrib_reg_n_fr, device = &quot;png&quot;, height = 6, width = 9) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/distribution&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.4 Surface of PAs 4.3.4.1 Distribution of surfaces tbl_distrib_area_no0 = summary( filter(data_stat_nodupl, superficie != 0)$superficie) %&gt;% format(scientific = FALSE, big.mark = &quot; &quot;) %&gt;% as.array() %&gt;% t() %&gt;% as.data.frame() %&gt;% select(-c(&quot;1st Qu.&quot;,&quot;3rd Qu.&quot;)) 4.3.4.2 Average surface in countries and regions #Distribution of PA WITH SURFACE &gt;0 across countries and regions ##Country data_distrib_no0_ctry = data_stat_nodupl %&gt;% filter(superficie != 0) %&gt;% group_by(iso3, pays) %&gt;% summarize(n = n(), freq = round(n/nrow(data_stat_nodupl), 1)*100) %&gt;% ungroup() ##Region data_distrib_no0_dr = data_stat_nodupl %&gt;% filter(superficie != 0) %&gt;% group_by(direction_regionale) %&gt;% summarize(n = n(), freq = round(n/nrow(data_stat_nodupl), 1)*100) %&gt;% ungroup() %&gt;% mutate(region = gsub(&quot;Dr &quot;, &quot;&quot;, direction_regionale), .after = &quot;direction_regionale&quot;) #By country.. tbl_area_avg_ctry = data_distrib_no0_ctry %&gt;% select(-freq) %&gt;% left_join(pa_area_ctry, by = &quot;iso3&quot;) %&gt;% select(-c(iso3, sprfc_tot_km2, tot_area_int)) %&gt;% mutate(sprfc_avg_noint_km2 = format(sprfc_tot_noint_km2/n, big.mark = &quot; &quot;, scientific = FALSE, digits = 1), sprfc_tot_noint_km2 = format(sprfc_tot_noint_km2, big.mark = &quot; &quot;, scientific = FALSE, digits = 1), ) names(tbl_area_avg_ctry) = c(&quot;Pays&quot;, &quot;Nombre d&#39;AP&quot;, &quot;Superficie totale (km2)&quot;, &quot;Superficie moyenne (km2)&quot;) #By region tbl_area_avg_dr = data_distrib_no0_dr %&gt;% select(-freq) %&gt;% left_join(pa_area_dr, by = &quot;direction_regionale&quot;) %&gt;% select(-c(sprfc_tot_km2, tot_area_int, direction_regionale)) %&gt;% mutate(sprfc_avg_noint_km2 = format(sprfc_tot_noint_km2/n, big.mark = &quot; &quot;, scientific = FALSE, digits = 1), sprfc_tot_noint_km2 = format(sprfc_tot_noint_km2, big.mark = &quot; &quot;, scientific = FALSE, digits = 1), ) names(tbl_area_avg_dr) = c(&quot;Direction régionale&quot;, &quot;Nombre d&#39;AP&quot;, &quot;Superficie totale (km2)&quot;, &quot;Superficie moyenne (km2)&quot;) #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) print(xtable(tbl_distrib_area_no0, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_distrib_area_no0.tex&quot;, sep = &quot;/&quot;)) print(xtable(tbl_area_avg_ctry, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_area_avg_ctry.tex&quot;, sep = &quot;/&quot;)) print(xtable(tbl_area_avg_dr, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_area_avg_dr.tex&quot;, sep = &quot;/&quot;)) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/surface&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.5 Temporal evolution In this section is plotted the evolution in the number and surafe of PAs over time (cumulated number/surface and number/surface of PAs funded by year). 4.3.5.1 Number of PAs data_time_range = data.frame(annee = c(min(data_stat_nodupl$annee_octroi):max(data_stat_nodupl$annee_octroi)) ) data_time_n = data_stat_nodupl %&gt;% group_by(annee_octroi) %&gt;% summarize(n = n()) %&gt;% full_join(data_time_range, by = c(&quot;annee_octroi&quot; = &quot;annee&quot;)) %&gt;% mutate(n = case_when(is.na(n)~0, TRUE~n)) %&gt;% arrange(annee_octroi) %&gt;% mutate(n_cum = cumsum(n)) #Number of PAs funded by year fig_n_pa = ggplot(data_time_n, aes(x = factor(annee_octroi), y = n)) %&gt;% + geom_bar(stat = &#39;identity&#39;, fill = &quot;#3182BD&quot;) %&gt;% + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), color = &quot;black&quot;, size=4, vjust = -0.3) %&gt;% + labs(title = &quot;Nombre d&#39;aires protégées appuyées par année&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_time_n$n), &quot;aires protégées&quot;), x = &quot;Année&quot;, y = &quot;Nombre d&#39;aires protégées&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) fig_n_pa #Cumulative number over time fig_ncum_pa = ggplot(data_time_n, aes(x = factor(annee_octroi), y = n_cum)) %&gt;% # + geom_point(color = &quot;#3182BD&quot;, size = 1.5) %&gt;% # + geom_line(color = &quot;#3182BD&quot;, size = 1) %&gt;% + geom_bar(stat = &#39;identity&#39;, fill = &quot;#3182BD&quot;) %&gt;% + geom_text(aes(y = n_cum, label = n_cum), color = &quot;black&quot;, size=4, vjust = -0.3) %&gt;% + labs(title = &quot;Evolution cumulée du nombre d&#39;aires protégées appuyées par l&#39;AFD&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_time_n$n), &quot;aires protégées&quot;), x = &quot;Année&quot;, y = &quot;Nombre d&#39;aires protégées&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) fig_ncum_pa #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;fig_n_pa.png&quot;, sep = &quot;/&quot;), fig_n_pa, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;fig_ncum_pa.png&quot;, sep = &quot;/&quot;), fig_ncum_pa, device = &quot;png&quot;, height = 6, width = 9) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/time_evolution&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.5.2 Surface of PAs data_time_range = data.frame(annee = c(min(data_stat_nodupl$annee_octroi):max(data_stat_nodupl$annee_octroi)) ) data_time_area = data_stat_nodupl %&gt;% group_by(annee_octroi) %&gt;% summarize(tot_area_km2 = sum(superficie)) %&gt;% left_join(pa_int_yr, by = c(&quot;annee_octroi&quot; = &quot;annee_int&quot;)) %&gt;% full_join(data_time_range, by = c(&quot;annee_octroi&quot; = &quot;annee&quot;)) %&gt;% mutate(tot_area_km2 = case_when(is.na(tot_area_km2)~0, TRUE~tot_area_km2), tot_int_km2 = case_when(is.na(tot_int_km2)~0, TRUE~tot_int_km2), tot_area_noint_km2 = tot_area_km2 - tot_int_km2) %&gt;% arrange(annee_octroi) #Evolution of area over time fig_area_pa = ggplot(data_time_area, aes(x = factor(annee_octroi), y = tot_area_noint_km2)) %&gt;% + geom_bar(stat = &#39;identity&#39;, fill = &quot;#3182BD&quot;) %&gt;% + geom_text(aes(y = tot_area_noint_km2, label = ifelse(tot_area_noint_km2 != 0, format(tot_area_noint_km2, digits = 2, scientific = TRUE), NA)), color = &quot;black&quot;, size=3, vjust = -0.3) %&gt;% + labs(title = &quot;Evolution de la superficie des aires protégées&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_time_n$n), &quot;aires protégées couvrant&quot;, format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = &quot; &quot;), &quot;km2&quot;), x = &quot;Année&quot;, y = &quot;Superficie (km2)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) fig_area_pa #Cumulative area over time fig_area_cum_pa = ggplot(data_time_area, aes(x = factor(annee_octroi), y = cumsum(tot_area_noint_km2))) %&gt;% # + geom_point(color = &quot;#3182BD&quot;, size = 1.5) %&gt;% # + geom_line(color = &quot;#3182BD&quot;, size = 1) %&gt;% + geom_bar(stat = &#39;identity&#39;, fill = &quot;#3182BD&quot;) %&gt;% + geom_text(aes(y = cumsum(tot_area_noint_km2), label = format(cumsum(tot_area_noint_km2), digits = 2, scientific = TRUE)), color = &quot;black&quot;, size=3, vjust = -0.3) %&gt;% + labs(title = &quot;Evolution cumulée de la superficie des aires protégées&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_time_n$n), &quot;aires protégées couvrant&quot;, format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = &quot; &quot;), &quot;km2&quot;), x = &quot;Année&quot;, y = &quot;Superficie (km2)&quot;) %&gt;% + theme(legend.position = &quot;bottom&quot;, legend.key = element_rect(fill = &quot;white&quot;), plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6), axis.title.x = element_text(margin = margin(t = 10)), panel.background = element_rect(fill = &#39;white&#39;, colour = &#39;white&#39;, linewidth = 0.5, linetype = &#39;solid&#39;), panel.grid.major = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), panel.grid.minor = element_line(colour = &#39;grey90&#39;, linetype = &#39;solid&#39;), plot.caption = element_text(color = &#39;grey50&#39;, size = 8.5, face = &#39;plain&#39;)) fig_area_cum_pa #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) ggsave(paste(tmp, &quot;fig_area_pa.png&quot;, sep = &quot;/&quot;), fig_area_pa, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;fig_area_cum_pa.png&quot;, sep = &quot;/&quot;), fig_area_cum_pa, device = &quot;png&quot;, height = 6, width = 9) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/time_evolution&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) 4.3.6 Governance Here is plotted the distribution of PAs across governance type. #Table of the governance type distribution ##English version data_gov_en = data_stat_nodupl %&gt;% mutate(gov_type = case_when(gov_type == &quot;&quot; ~ &quot;Not referenced&quot;, TRUE ~ gov_type)) %&gt;% group_by(gov_type) %&gt;% summarize(n = n()) %&gt;% mutate(n_tot = sum(n), freq = round(n/n_tot*100,1)) %&gt;% select(-n_tot) %&gt;% arrange(-freq) tbl_gov_en = data_gov_en names(tbl_gov_en) = c(&quot;Governance&quot;,&quot;Number of PAs&quot;,&quot;Share of PAs (%)&quot;) ##French Version data_gov_fr = data_stat_nodupl %&gt;% mutate(gov_type = case_when(gov_type == &quot;&quot; ~ &quot;Non référencée&quot;, gov_type == &quot;Collaborative governance&quot; ~ &quot;Gouvernance collaborative&quot;, gov_type == &quot;Federal or national ministry or agency&quot; ~ &quot;Ministère ou agence, fédérale ou nationale&quot;, gov_type == &quot;Federal or national ministry or agency&quot; ~ &quot;Ministère ou agence, fédérale ou nationale&quot;, gov_type == &quot;Government-delegated management&quot; ~ &quot;Gestion déléguée par le gouvernement&quot;, gov_type == &quot;Indigenous peoples&quot; ~ &quot;Peuples indigènes&quot;, gov_type == &quot;Joint governance&quot; ~ &quot;Gouvernance conjointe&quot;, gov_type == &quot;Local communities&quot; ~ &quot;Communautés locales&quot;, gov_type == &quot;Non-profit organisations&quot; ~ &quot;Organisations non-lucratives&quot;, gov_type == &quot;Not Reported&quot; ~ &quot;Non rapportée&quot;, gov_type == &quot;Sub-national ministry or agency&quot; ~ &quot;Ministère ou agence sous-nationale&quot;, TRUE ~ gov_type)) %&gt;% group_by(gov_type) %&gt;% summarize(n = n()) %&gt;% mutate(n_tot = sum(n), freq = round(n/n_tot*100,1)) %&gt;% select(-n_tot) %&gt;% arrange(-freq) tbl_gov_fr = data_gov_fr names(tbl_gov_fr) = c(&quot;Gouvernance&quot;,&quot;Nombre d&#39;AP&quot;,&quot;Proportion (%)&quot;) #PAs with nureported or unreferenced governance types are removed ##Tables ###English data_gov_knwn_en = data_stat_nodupl %&gt;% mutate(gov_type = case_when(gov_type == &quot;&quot; ~ &quot;Not referenced&quot;, TRUE ~ gov_type)) %&gt;% filter(gov_type != &quot;Not Reported&quot; &amp; gov_type != &quot;Not referenced&quot;) %&gt;% group_by(gov_type) %&gt;% summarize(n = n()) %&gt;% mutate(n_tot = sum(n), freq = round(n/n_tot*100,1)) %&gt;% select(-n_tot) %&gt;% arrange(-freq) tbl_gov_knwn_en = data_gov_knwn_en names(tbl_gov_knwn_en) = c(&quot;Governance&quot;,&quot;Number of PAs&quot;,&quot;Share of PAs (%)&quot;) ###French data_gov_knwn_fr = data_stat_nodupl %&gt;% mutate(gov_type = case_when(gov_type == &quot;&quot; ~ &quot;Non référencée&quot;, gov_type == &quot;Collaborative governance&quot; ~ &quot;Gouvernance collaborative&quot;, gov_type == &quot;Federal or national ministry or agency&quot; ~ &quot;Ministère ou agence, fédérale ou nationale&quot;, gov_type == &quot;Federal or national ministry or agency&quot; ~ &quot;Ministère ou agence, fédérale ou nationale&quot;, gov_type == &quot;Government-delegated management&quot; ~ &quot;Gestion déléguée par le gouvernement&quot;, gov_type == &quot;Indigenous peoples&quot; ~ &quot;Peuples indigènes&quot;, gov_type == &quot;Joint governance&quot; ~ &quot;Gouvernance conjointe&quot;, gov_type == &quot;Local communities&quot; ~ &quot;Communautés locales&quot;, gov_type == &quot;Non-profit organisations&quot; ~ &quot;Organisations non-lucratives&quot;, gov_type == &quot;Not Reported&quot; ~ &quot;Non rapportée&quot;, gov_type == &quot;Sub-national ministry or agency&quot; ~ &quot;Ministère ou agence sous-nationale&quot;, TRUE ~ gov_type)) %&gt;% filter(gov_type != &quot;Non référencée&quot; &amp; gov_type != &quot;Non rapportée&quot;) %&gt;% group_by(gov_type) %&gt;% summarize(n = n()) %&gt;% mutate(n_tot = sum(n), freq = round(n/n_tot*100,1)) %&gt;% select(-n_tot) %&gt;% arrange(-freq) tbl_gov_knwn_fr = data_gov_knwn_fr names(tbl_gov_knwn_fr) = c(&quot;Gouvernance&quot;,&quot;Nombre d&#39;AP&quot;,&quot;Proportion (%)&quot;) ##Pie charts ###English pie_gov_knwn_en = ggplot(data_gov_knwn_en, aes(x=&quot;&quot;, y= freq, fill= gov_type)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;, color=&quot;white&quot;) %&gt;% + geom_label(aes(x=1.3, label = paste0(format(freq, digits = 2), &quot;%&quot;)), color = &quot;black&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + labs(title = &quot;Governance type of PAs, except not referenced/reported PAs&quot;, subtitle = paste(&quot;Sample :&quot;, sum(data_gov_knwn_en$n), &quot;PAs&quot;)) %&gt;% + scale_fill_brewer(name = &quot;Governance&quot;, palette=&quot;Paired&quot;) %&gt;% + theme_void() ###French pie_gov_knwn_fr = ggplot(data_gov_knwn_fr, aes(x=&quot;&quot;, y= freq, fill= gov_type)) %&gt;% + geom_bar(width = 1, stat = &quot;identity&quot;, color=&quot;white&quot;) %&gt;% + geom_label(aes(x=1.3, label = paste0(format(freq, digits = 2), &quot;%&quot;)), color = &quot;black&quot;, position = position_stack(vjust = 0.55), size=2.5, show.legend = FALSE) %&gt;% + coord_polar(&quot;y&quot;, start=0) %&gt;% + labs(title = &quot;Gouvernance, hors aires protégées avec une gouvernance \\nnon-rapportée/référencée&quot;, subtitle = paste(&quot;Echantillon :&quot;, sum(data_gov_knwn_fr$n), &quot;aires protégées&quot;)) %&gt;% + scale_fill_brewer(name = &quot;Gouvernance&quot;, palette=&quot;Paired&quot;) %&gt;% + theme_void() pie_gov_knwn_fr #Saving figures tmp = paste(tempdir(), &quot;fig&quot;, sep = &quot;/&quot;) print(xtable(tbl_gov_en, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_gov_en.tex&quot;, sep =&quot;/&quot;)) print(xtable(tbl_gov_fr, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_gov_fr.tex&quot;, sep =&quot;/&quot;)) print(xtable(tbl_gov_knwn_en, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_gov_knwn_en.tex&quot;, sep =&quot;/&quot;)) print(xtable(tbl_gov_knwn_fr, type = &quot;latex&quot;), file = paste(tmp, &quot;tbl_gov_knwn_fr.tex&quot;, sep =&quot;/&quot;)) ggsave(paste(tmp, &quot; pie_gov_knwn_en.png&quot;, sep = &quot;/&quot;), plot = pie_gov_knwn_en, device = &quot;png&quot;, height = 6, width = 9) ggsave(paste(tmp, &quot;pie_gov_knwn_fr.png&quot;, sep = &quot;/&quot;), plot = pie_gov_knwn_fr, device = &quot;png&quot;, height = 6, width = 9) #Export to S3 storage ##List of files to save in the temp folder files &lt;- list.files(tmp, full.names = TRUE) ##Add each file in the bucket (same foler for every file in the temp) count = 0 for(f in files) { count = count+1 cat(&quot;Uploading file&quot;, paste0(count, &quot;/&quot;, length(files), &quot; &#39;&quot;, f, &quot;&#39;&quot;), &quot;\\n&quot;) aws.s3::put_object(file = f, bucket = &quot;projet-afd-eva-ap/DesStat/gouvernance&quot;, region = &quot;&quot;, show_progress = TRUE) } #Erase the files in the temp directory do.call(file.remove, list(list.files(tmp, full.names = TRUE))) "],["hello-bookdown.html", "Chapter 5 Hello bookdown 5.1 A section", " Chapter 5 Hello bookdown All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (#) per .Rmd file. 5.1 A section All chapter sections start with a second-level (##) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. "],["matching.html", "Chapter 6 Matching 6.1 Initial settings 6.2 Matching process", " Chapter 6 Matching In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to compute the Average Treatment on the Treated (ATT). The treatment here is to be under protected area status, and we look at the impact on deforestation. The steps are the following Pre-processing : in a loop for each country Create a grid of a given country Import geospatial data on PAs from the WDPA dataset, and assign each observation unit/pixel to a group : PA funded by the AFD (treated), PA non-funded by the AFD, buffer (closed to but not a PA), other (so potential control). Compute the covariates and outcome of interest for all pixels thanks to the mapme.biodiversity package Build the matching data frame Post-processing Load the matching dataframe of the given country Perform the matching Plot covariate balance and density plots to ensure relevant matching Panelize the dataframe Perform regressions 6.1 Initial settings #{r setup, include=FALSE, eval = FALSE} #knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # #Install some libraries install.packages(c(&quot;tictoc&quot;, &quot;geodata&quot;, &quot;wdpar&quot;, &quot;exactextractr&quot;, &quot;MatchIt&quot;, &quot;fixest&quot;, &quot;cobalt&quot;)) remotes::install_github(&quot;mapme-initiative/mapme.biodiversity&quot;, upgrade=&quot;always&quot;) #Install the river to download wdpa data directly webdriver::install_phantomjs() # Load Libraries library(dplyr) library(tictoc) library(xtable) library(tidyr) library(stringr) library(ggplot2) # For plotting library(sf) # For handling vector data library(terra) # For handling raster data library(raster) # For handling raster data library(rgeos) library(geodata) # For getting country files library(wdpar) # For getting protected areas library(exactextractr) # For zonal statistics library(mapme.biodiversity) library(aws.s3) library(MatchIt) #For matching library(fixest) #For estimating the models library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes #Import functions source(&quot;scripts/ImpactAnalysis/fns_matching.R&quot;) # Define the path to a working directory #wdir_s3 = file.path(&quot;data_tidy/mapme_bio_data/matching&quot;) tmp_pre = paste(tempdir(), &quot;matching_pre&quot;, sep = &quot;/&quot;) tmp_post = paste(tempdir(), &quot;matching_post&quot;, sep = &quot;/&quot;) # Define the file name of the matching frame name_output = name_input = &quot;matching_frame_10km&quot; ext_output = ext_input = &quot;.gpkg&quot; ##### ###Pre-processing ##### ##Buffer and gridsize : make it depends on the country ? For instance, a typical size of grid such that the smaller PA is sampled with at least N pixels ? # Specify buffer width in meter buffer_m = 10000 # Specify the grid cell size in meter gridSize = 10000 #Load data data_pa_full = #fread(&quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot; , encoding = &quot;UTF-8&quot;) aws.s3::s3read_using( FUN = data.table::fread, encoding = &quot;UTF-8&quot;, # Mettre les options de FUN ici object = &quot;data_tidy/BDD_DesStat_nofund_nodupl.csv&quot;, bucket = &quot;projet-afd-eva-ap&quot;, opts = list(&quot;region&quot; = &quot;&quot;)) #List of countries in the sample #list_iso = unique(data_pa_full$iso3) list_iso = c(&quot;COM&quot;, &quot;MMR&quot;) # Specify a list of WDPA IDs of funded protected areas (treated areas) # paid = data_stat_nodupl[data_stat_nodupl$iso3 == country,]$wdpaid # Start year y_first = 2000 # End year y_last = 2021 ##### ###Post-processing ##### # Define Column Names of Covariates colname.travelTime = &quot;minutes_median_5k_110mio&quot; colname.clayContent = &quot;clay_0.5cm_mean&quot; # colname.elevation = &quot;elevation_mean&quot; # colname.tri = &quot;tri_mean&quot; colname.fcIni = &quot;treecover_2000&quot; # Prefix of columns for forest cover colfc.prefix = &quot;treecover&quot; # Separation between prefix and year colfc.bind = &quot;_&quot; # Prefix of columns for forest loss colfl.prefix = &quot;treeloss&quot; #Prefix of columns for average forest loss pre-funding colname.flAvg = &quot;avgLoss_pre_fund&quot; # Year of Funding Start funding.start = 2014 6.2 Matching process 6.2.1 Pre-processing #For each country in the list, the different steps of the pre-processing are performed count = 0 max_i = length(list_iso) tic_pre = tic() for (i in list_iso) { count = count+1 print(paste0(i, &quot; : country &quot;, count, &quot;/&quot;, max_i)) #Generate observation units print(&quot;--Generating observation units&quot;) output_pre_grid = fn_pre_grid(iso = i, path_tmp = tmp_pre, gridSize = gridSize) #Load the outputs utm_code = output_pre_grid$utm_code gadm_prj = output_pre_grid$ctry_shp_prj grid = output_pre_grid$grid #Determining Group IDs and WDPA IDs for all observation units print(&quot;--Determining Group IDs and WDPA IDs&quot;) grid_param = fn_pre_group(iso = i, path_tmp = tmp_pre, utm_code = utm_code, buffer_m = buffer_m, data = data_pa_full, gadm_prj = gadm_prj, grid = grid, gridSize = gridSize) #Calculating outcome and other covariates for all observation units print(&quot;--#Calculating outcome and other covariates&quot;) fn_pre_mf(grid.param = grid_param, path_tmp = tmp_pre, iso = i, name_output = name_output, ext_output = ext_output) } toc_pre = toc() 6.2.2 Post-processing #For each country in the list, the different steps of the post-processing are performed count = 0 max_i = length(list_iso) tic_post = tic() for (i in list_iso) { count = count+1 print(paste0(i, &quot; : country &quot;, count, &quot;/&quot;, max_i)) #Load the matching frame print(&quot;--Loading the matching frame&quot;) mf_ini = fn_post_load_mf(iso = i) #Add average pre-loss print(&quot;--Add covariate : average tree loss pre-funding&quot;) mf = fn_post_avgLoss_prefund(mf = mf_ini, yr_start = funding.start - 5, yr_end = funding.start - 1, colfl.prefix = colfl.prefix) #Define cut-offs print(&quot;--Define cutoffs&quot;) ##CAREFUL : ADD elevation and TRI when available lst_cutoffs = fn_post_cutoff(mf = mf, colname.travelTime = colname.travelTime, colname.clayContent = colname.clayContent, colname.fcIni = colname.fcIni, colname.flAvg = colname.flAvg ) #Run Coarsened Exact Matching print(&quot;--Run CEM&quot;) out.cem = fn_post_cem(mf = mf, iso = i, path_tmp = tmp_post, lst_cutoffs = lst_cutoffs, colname.travelTime = colname.travelTime, colname.clayContent = colname.clayContent, colname.fcIni = colname.fcIni, colname.flAvg = colname.flAvg) #Plots : covariates print(&quot;--Some plots : covariates&quot;) print(&quot;----Covariate balance&quot;) fn_post_plot_covbal(out.cem = out.cem, colname.travelTime = colname.travelTime, colname.clayContent = colname.clayContent, colname.fcIni = colname.fcIni, colname.flAvg = colname.flAvg, iso = i, path_tmp = tmp_post) print(&quot;----Density plots&quot;) fn_post_plot_density(out.cem = out.cem, colname.travelTime = colname.travelTime, colname.clayContent = colname.clayContent, colname.fcIni = colname.fcIni, colname.flAvg = colname.flAvg, iso = i, path_tmp = tmp_post) #Panelize dataframes print(&quot;----Panelize (Un-)Matched Dataframe&quot;) output_post_panel = fn_post_panel(out.cem = out.cem, mf = mf, colfc.prefix = colfc.prefix, colfc.bind = colfc.bind) matched.wide = output_post_panel$matched.wide unmatched.wide = output_post_panel$unmatched.wide matched.long = output_post_panel$matched.long unmatched.long = output_post_panel$unmatched.long #Plots : trend print(&quot;----Plots again : trend&quot;) fn_post_plot_trend(matched.long = matched.long, unmatched.long = unmatched.long, iso = i) } toc_post = toc() #Notes ## Automate the definition of cutoffs for CEM ### Coder 5.5.3 de Iacus et al. 2012 ? Permet de savoir le gain de matched units pour une modification des seuils d&#39;une variable ## Loop for different treatment years : need to adapt fn_post_avgLoss_prefund function ## Allow to enter a list of any covariates to perform the matching ## Function to plot Fig. 3 in Iacus et al. 2012 ## Il faut contrôler le nombre de paired units à la fin ! Typiquement on veut que tous les pixels traités soient retenus, idéalement. ## On veut ATE ou ATT ?? Je dirai ATT car on ne veut pas estimer l&#39;effet de mettre une AP, mais l&#39;effet des AP financés par l&#39;AFD "],["cross.html", "Chapter 7 Cross-references 7.1 Chapters and sub-chapters 7.2 Captioned figures and tables", " Chapter 7 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 7.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter 7. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 7.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 7.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 7.1: Here is a nice figure! Don’t miss Table 7.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 7.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 "],["parts.html", "Chapter 8 Parts", " Chapter 8 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. "],["footnotes-and-citations.html", "Chapter 9 Footnotes and citations 9.1 Footnotes 9.2 Citations", " Chapter 9 Footnotes and citations 9.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 1. 9.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2023) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations References "],["blocks.html", "Chapter 10 Blocks 10.1 Equations 10.2 Theorems and proofs 10.3 Callout blocks", " Chapter 10 Blocks 10.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{10.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (10.1). 10.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 10.1. Theorem 10.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 10.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Chapter 11 Sharing your book 11.1 Publishing 11.2 404 pages 11.3 Metadata for sharing", " Chapter 11 Sharing your book 11.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 11.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 11.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
