---
title: "Exercise_1"
output: html_document
date: "2024-07-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The following exercises will help you to master the steps of the analysis carried out in the chapter "Geospatial Impact Assessment of Conservation on Forest Cover Loss" and to understand the methodology used. The evaluation is conducted here for a single protected area to make it easier to understand the code, but the scripts for analysing the portfolio can be found on the 'github link'.

## Exercise 1 : Build a matching sample

```{r}
# load/install packages if necessary
lop <- c("ggplot2", "tidyr", "dplyr", "stringr", "sf", "terra", "raster", "geodata", "exactextractr", "mapme.biodiversity", "future","progressr","wdpar")
newp <- lop[!(lop %in% installed.packages()[,"Package"])]
if(length(newp)) install.packages(newp)
lapply(lop, require, character.only = TRUE)
```

```{r cars}
# Load Libraries
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
#remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")
library(mapme.biodiversity)
library(future)
library(progressr)
```

## Settings ⚙️

Q1 : Please fill up the following chunk with :

-   a working directory
-   the country code of Bolivia
-   the size of the buffer
-   the size of the grid
-   the WDPA ID of Tariquia

```{r}

# Define the path to a working directory
wdir = file.path(tempdir())
# Define the file name of the output matching frame
name_output = "mf_BOL_500ha.gpkg"
# Specify a country; to find the right country code, please refer to this page https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3
country = "BOL"
# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
gridSize = 2236.068 # --> 500ha
# Specify a WDPA IDs; to find the WDPA ID, please refer to this page 
# https://www.protectedplanet.net/en
paid = c( 20041)
```

## Gridding of the country

Q2: Run the following code and explain what the question ... is doing

```{r}
## 2. Generating observation units for matching frame
# Download country polygon to working directory and load it into workspace
gadm <- gadm(country = country, resolution = 1, level = 0, path = wdir) %>%
  st_as_sf()
# If the country polygon file already exists in working directory, it can be loaded into work space by
#gadm = readRDS(file.path(wdir, paste0('gadm41_',country,'_0_pk.rds'))) %>% st_as_sf()
# Find UTM zone of the country centroid
centroid = st_coordinates(st_centroid(gadm))
lonlat2UTM = function(lonlat) {
  utm = (floor((lonlat[1] + 180) / 6) %% 60) + 1
  if (lonlat[2] > 0) {
    utm + 32600
  } else{
    utm + 32700
  }
}
utm_code = lonlat2UTM(centroid)
# Reproject GADM
gadm_prj = gadm %>% st_transform(crs = utm_code)
# Make bounding box of projected country polygon
bbox = st_bbox(gadm_prj) %>% st_as_sfc() %>% st_as_sf()
# Make a Grid to the extent of the bounding box
grid.ini = st_make_grid(bbox, cellsize = c(gridSize,gridSize))
# Crop Grid to the extent of country boundary by
# subsetting to the grid cells that intersect with the country
grid.sub = grid.ini %>%
  st_intersects(gadm_prj, .) %>%
  unlist()
# Filter the grid to the subset
grid = grid.ini[sort(grid.sub)] %>%
  st_as_sf() %>%
  mutate(gridID = seq(1:nrow(.))) # Add id for grid cells
# Visualize
ggplot() +
 geom_sf(data = st_geometry(bbox)) +
 geom_sf(data = st_geometry(gadm_prj)) +
 geom_sf(data = st_geometry(grid), alpha = 0)

## 3. Determining Group IDs and WDPA IDs for all observation units
# Get the PA polygons/points of the specified country;
# They're downloaded to the working directory.
#wdpa = wdpa_fetch(country, wait = TRUE, download_dir = wdir)
# If the PA file already exists, it can be loaded in this way
#wdpa = wdpa_read(paste0(wdir, '/WDPA_Jul2023_BOL-shapefile.zip'))
wdpa=wdpa_wld_raw %>% filter(ISO3=="BOL")
# PAs are projected, and column "geometry_type" is added
wdpa_prj = wdpa_clean(wdpa, geometry_precision = 1000,
                      # Don't erase overlapped polygons
                      erase_overlaps = FALSE) %>%
  # Remove the PAs that are only proposed, or have geometry type "point"
  filter(STATUS != "Proposed") %>%
  filter(GEOMETRY_TYPE != "POINT") %>%
  # Project PA polygons to the previously determined UTM zone
  st_transform(crs = utm_code)

# Separate funded and non-funded protected areas
wdpaID_funded = paid
wdpa_funded = wdpa_prj %>% filter(WDPAID %in% wdpaID_funded) %>%
  mutate(group=1) # Assign an ID "1" to the funded PA group

wdpa_nofund = wdpa_prj %>%
  filter(!WDPAID %in% wdpaID_funded) %>%
  st_buffer(., dist=0) # a hack to solve 'bad' polygons in R, e.g. problem of self-intersection
# Determine the non-funded PAs that intersect with funded PAs,
# and delete the intersection part from non-funded PAs to reduce noise when rasterizing WDPAIDs later.
intersection = st_intersection(wdpa_nofund, wdpa_funded)
wdpa_nofund <- wdpa_nofund %>%
  { if (nrow(intersection) == 0) . else st_difference(., st_union(st_geometry(intersection))) } %>%
  mutate(group = 2)

# Make Buffers of 10km around all protected areas
wdpa_buffer <- st_buffer(wdpa_funded, dist = buffer_m) %>%
  rbind(st_buffer(wdpa_nofund, dist = buffer_m)) %>%
  # Assign an ID "3" to the buffer group
  mutate(group=3)
# Merge the dataframes of funded PAs, non-funded PAs and buffers
wdpa_groups = rbind(wdpa_funded, wdpa_nofund, wdpa_buffer)
# Subset to polygons that intersect with country boundary
wdpa.sub = wdpa_groups %>%
  st_intersects(gadm_prj, .) %>%
  unlist()
# Filter the PA+buffer to the subset
wdpa_groups = wdpa_groups[sort(wdpa.sub),] %>%
  st_as_sf()

ggplot(wdpa_groups) +
  geom_sf(aes(fill = factor(WDPAID)), lwd=0, alpha=0.4) +
  theme_bw()


# Initialize an empty raster to the spatial extent of the country
r.ini = raster()
extent(r.ini) = extent(gadm_prj)
# Specify the raster resolution as same as the pre-defined 'gridSize'
res(r.ini) = gridSize
# Assign the raster pixels with "Group" values,
# Take the minimal value if a pixel is covered by overlapped polygons, so that PA Group ID has higher priority than Buffer ID.
# Assign value "0" to the background pixels (control candidates group)
r.group = rasterize(wdpa_groups, r.ini, field="group", fun="min", background=0) %>%
  mask(., gadm_prj)
# Rename Layer
names(r.group) = "group"
# Rasterize wdpaid
r.wdpaid = rasterize(wdpa_prj, r.ini, field="WDPAID", fun="first", background=0) %>%
  mask(., gadm_prj)
names(r.wdpaid) = "wdpaid"

# Aggregate pixel values by taking the majority
grid.group = exact_extract(x=r.group, y=grid, fun='mode', append_cols="gridID") %>%
  rename(group = mode)
grid.wdpaid = exact_extract(x=r.wdpaid, y=grid, fun="mode", append_cols="gridID") %>%
  rename(wdpaid = mode)
# Merge data frames
grid.param = grid.group %>%
  merge(., grid.wdpaid, by="gridID") %>%
  merge(., grid, by="gridID") %>%
  # drop rows having "NA" in column "group"
  drop_na(group) %>%
  # drop the column of "gridID"
  subset(., select=-c(gridID)) %>%
  st_as_sf() %>%
  # Grid is projected to WGS84 because mapme.biodiverty package merely works with this CRS
  st_transform(crs=4326)
```

Q3: Fill in the following code to visualize different group of the PA

```{r}
# Visualize grouped grid cells
grid.param %>%

  #mutate(group = replace(group, wdpaid%in%c(1084, 478028, 555625665, 555697863, 10906), 2)) %>%
  # Plot Groups for Phase I

  ggplot() +
  geom_sf(aes(fill = factor(group)), lwd=0) +
  scale_fill_manual(name="Group", # legend title
                    values = c("grey", "darkgreen", "darkblue", "orange"),
                    labels = c("control candidate", "treatment candidate", "non-funded PA", "buffer zone")) +
  theme_bw()
```

## Download the data

Q4 : Please refer to this page (<https://github.com/mapme-initiative/mapme.biodiversity>) to find the function to complete the following code

```{r}
## 4. Calculating deforestation area and other covariates for all observation units
# Get input data ready for indicator calculation

#years=2000:2021
mapme_options(outdir =wdir)
# aoi = init_portfolio(grid.param,
#                      years = 2000:2021,
#                      outdir = wdir,
#                      tmpdir = file.path(wdir, "tmp"),
#                      add_resources = FALSE)

aoi=grid.param
```

### Covariate: Soil

Insert the function to download soil data :

```{r}
get.soil = aoi %>% get_resources(get_soilgrids(
        layers = "clay", # resource specific argument
        depths = "0-5cm", # resource specific argument
        stats = "mean"))
                         
# set up parallel plan with 6 concurrent threads
plan(multisession, workers = 20)
# Calculate Indicator
with_progress({
  zonal.soil = get.soil %>% calc_indicators(
          calc_soilproperties(
            stats = "mean",
            engine = "zonal"
          )
        )
})
plan(sequential) # close child processes
# Transform the output dataframe into a pivot dataframe
pivot.soil = zonal.soil %>%
  unnest(soilproperties) %>%
  mutate(across(value, round, 3)) %>% # Round numeric columns
  pivot_wider(names_from = c("variable"), values_from = "value")%>%
  dplyr::select(-c(datetime,unit))
      

```

### Covariate: Elevation

Insert the function to calculate elevation mean

```{r}
get.elevation = aoi %>% get_resources(get_nasa_srtm())
# set up parallel plan with 6 concurrent threads
plan(multisession, workers = 20)

# Calculate Indicator
with_progress({
  zonal.elevation = calc_indicators(calc_elevation(
          stats= "mean",
          engine = "exactextract"))
  
  
})
plan(sequential) # close child processes
# Transform the output dataframe into a pivot dataframe
pivot.elevation = zonal.elevation %>% unnest(elevation)%>%
  pivot_wider(names_from = c("variable"), values_from = "value")%>%
  dplyr::select(-c(datetime,unit))
      


```

### Covariate: TRI

```{r}
# set up parallel plan with 6 concurrent threads
plan(multisession, workers = 20)
# Calculate Indicator
with_progress({
  zonal.tri = get.elevation %>% calc_indicators(calc_tri(
          stats = "mean",
          engine = "exactextract"))
})
plan(sequential) # close child processes
# Transform the output dataframe into a pivot dataframe
pivot.tri = zonal.tri %>% unnest(tri)%>%
  pivot_wider(names_from = c("variable"), values_from = "value")%>%
  dplyr::select(-c(datetime,unit))


```

### Covariate: Travel Time

Download data related to travel time and calculate the median travel time

```{r}
get.travelT = aoi%>% get_resources(get_nelson_et_al(ranges = c("5k_110mio")))

# set up parallel plan with 6 concurrent threads
plan(multisession, workers = 20)
# Calculate Indicator
with_progress({
  zonal.travelT  <-get.travelT %>% calc_indicators(calc_traveltime(
          stats = "median",
          engine = "exactextract"))
  })
plan(sequential) # close child processes
# Transform the output dataframe into a pivot dataframe
pivot.travelT = zonal.travelT %>%
  unnest(traveltime) %>%
  pivot_wider(names_from = "variable", values_from = "value", 
              names_prefix = "minutes_median_")%>%
  dplyr::select(-c(datetime,unit))

```

### Time Series of Tree Cover Area

```{r}
get.tree = aoi %>%get_resources(get_gfw_treecover(version =  version_gfc),
                                     get_gfw_lossyear(version = version_gfc))
# set up parallel plan with 6 concurrent threads
plan(multisession, workers = 20)
# Calculate time series
with_progress({
  zonal.tree = get.tree %>% calc_indicators(calc_treecover_area(years=years, min_size=0.5, 
                                                                    min_cover=10))
  
})
plan(sequential) # close child processes

# Transform the output dataframe into a pivot dataframe
pivot.tree = zonal.tree %>%
  unnest(treecover_area) %>%
  # Transfer treecover unit to percentage
  mutate(treecover = round((treecover*1e4)/(gridSize^2)*100, 2)) %>%
  pivot_wider(names_from = "datetime", values_from = "value", names_prefix = "treecover_")%>%
  dplyr::select(-c(datetime,unit))

```

Q5 : Why is a multisession used ? Explain

```{r}


# The calculation of tree loss area is performed at dataframe base
# Get the column names of tree cover time series
colnames_tree = names(pivot.tree)[startsWith(names(pivot.tree), "treecover")]
# Drop the first year
dropFirst = tail(colnames_tree, -1)
# Drop the last year
dropLast = head(colnames_tree, -1)
# Set list of new column names for tree loss time series
colnames_loss = dropFirst %>% str_split(., "_")
# Add new columns: treeloss_tn = treecover_tn - treecover_t(n-1)
for (i in 1:length(dropFirst)) {
  new_colname <- paste0("treeloss_", colnames_loss[[i]][2])
  pivot.tree[[new_colname]] <- pivot.tree[[dropFirst[i]]] - pivot.tree[[dropLast[i]]]
}


# Export Matching Frame
# Remove "geometry" column from pivot dataframes
df.tree = pivot.tree %>% mutate(x = NULL) %>% as.data.frame()
df.travelT = pivot.travelT %>% mutate(x = NULL) %>% as.data.frame()
df.soil = pivot.soil %>% mutate(x = NULL) %>% as.data.frame()
df.elevation = pivot.elevation %>% mutate(x = NULL) %>% as.data.frame()
df.tri = pivot.tri %>% mutate(x=NULL) %>% as.data.frame()
# Make a dataframe containing only "assetid" and geometry
df.geom = pivot.tree[, c("assetid", "x")] %>% as.data.frame()
# Merge all output dataframes
pivot.all = Reduce(dplyr::full_join, list(df.travelT, df.soil, df.tree, df.elevation, df.tri, df.geom)) %>%
  st_as_sf()
# Make column Group ID and WDPA ID have data type "integer"
pivot.all$group = as.integer(pivot.all$group)
pivot.all$wdpaid = as.integer(pivot.all$wdpaid)

# Export the matching frame
st_write(pivot.all, dsn = file.path(wdir, name_output), delete_dsn = TRUE)

```

# Create an interactive map

To visualise

```{r}
worldMaps <- function(df, world_data, data_type, period, indicator){
  
  # Function for setting the aesthetics of the plot
  my_theme <- function () { 
    theme_bw() + theme(axis.text = element_text(size = 14),
                       axis.title = element_text(size = 14),
                       strip.text = element_text(size = 14),
                       panel.grid.major = element_blank(), 
                       panel.grid.minor = element_blank(),
                       panel.background = element_blank(), 
                       legend.position = "bottom",
                       panel.border = element_blank(), 
                       strip.background = element_rect(fill = 'white', colour = 'white'))
  }
  
  # Select only the data that the user has selected to view
  plotdf <- df[df$Indicator == indicator & df$DataType == data_type & df$Period == period,]
  plotdf <- plotdf[!is.na(plotdf$ISO3), ]
  
  # Add the data the user wants to see to the geographical world data
  world_data['DataType'] <- rep(data_type, nrow(world_data))
  world_data['Period'] <- rep(period, nrow(world_data))
  world_data['Indicator'] <- rep(indicator, nrow(world_data))
  world_data['Value'] <- plotdf$Value[match(world_data$ISO3, plotdf$ISO3)]
  
  # Create caption with the data source to show underneath the map
  capt <- paste0("Source: ", ifelse(data_type == "Childlessness", "United Nations" , "World Bank"))
  
  # Specify the plot for the world map
  library(RColorBrewer)
  library(ggiraph)
  g <- ggplot() + 
    geom_polygon_interactive(data = world_data, color = 'gray70', size = 0.1,
                                    aes(x = long, y = lat, fill = Value, group = group, 
                                        tooltip = sprintf("%s<br/>%s", ISO3, Value))) + 
    scale_fill_gradientn(colours = brewer.pal(5, "RdBu"), na.value = 'white') + 
    scale_y_continuous(limits = c(-60, 90), breaks = c()) + 
    scale_x_continuous(breaks = c()) + 
    labs(fill = data_type, color = data_type, title = NULL, x = NULL, y = NULL, caption = capt) + 
    my_theme()
  
  return(g)
}
```
