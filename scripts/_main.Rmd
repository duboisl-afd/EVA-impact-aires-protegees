--- 
documentclass: book
title: "Impact analysis of protected areas funded by the AFD : an open-guide for reproductibility"
author: 
- Antoine Vuillot
- Ingrid Dallmann
- Léa Poulin
- Pierre-Yves Durand
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
bibliography: 
- biblio.bib
- packages.bib
biblio-style: apalike
url: https://vuillota.github.io/EVA-impact-aires-protegees
description: This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.
github-repo: vuillota/EVA-impact-aires-protegees.git
link-citations: yes
css: assets/style.css
---

description: This is a minimal example of using the bookdown package to write a book.
  The output format for this example is bookdown::gitbook.

# About this website {-}

This site presents in an open and transparent way the analysis performed by IRS/EVA team on protected areas. More precisely, an impact analysis is performed using geospatial data to assess to what extent do PAs funded by the AFD preserve biodiversity.

<!--chapter:end:index.Rmd-->

# Building the datasets

This script builds the different datasets for the analysis. The lists of protected areas (PAs) reported by the Agence Française de Développement (AFD) departments are combined, merged with AFD project database ("SIOP") and the World Database on Protected Areas (WDPA). The latter is the most comprehensive database on marine and terrestrial protected areas, published by the International Union for the Conservation of Nature (IUCN). The following datasets are created :

-   A confidential dataset to perform descriptive statistics on fundings

-   A dataset to perform non-confidential statistics

-   Datasets specific to impact analysis (for PA supported by the AFD or a specific funder, a all PA in a given country, etc.)

-   Datasets with geospatial information, for specific uses (e.g maps)

-   Datasets with total area at country, region or world level, taking into account potential intersection between PA reported by the WDPA (see WDPA documentation)

These datasets are available upon requests, with potential restriction for datasets containing confidential data. Note that this script loads geospatial datasets that are memory demanding. Ensure that the R session has accessed to enough temporary memory (RAM) before running the script (typically 10 GB), or clean the RAM regularly.

The datasets used are stored and saved into the SSPCloud platform that uses minIO storage. Thus specific functions from the aws.S3 package are used to write and read files (aws.S3::s3read_using() and aws.S3::s3write_using()). These can be replaced by other R functions to read/write locally (data.table::fread() typically).

## Initial settings

Configuring the Rmarkdown

# ```{r setup, include = FALSE, eval = FALSE}
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
# ```

Downloading and importing the relevant packages

```{r message=TRUE, warning=TRUE, eval = FALSE}
install.packages(c("janitor", "geodata", "wdpar", "countrycode"))
library(tidyverse)
library(dplyr)
library(data.table)
library(readxl)
library(janitor)
library(stringi)
library(sf)
library(terra)
library(mapview)
library(wdpar)
library(aws.s3)
library(countrycode)
library(geodata)

#Install webdriver to download WDPA data
#webdriver::install_phantomjs()

```

## Datasets for analysis

### Merge PAs reporting by AFD technical departments

A first step has been to collect information on the PAs funded by the AFD. A first bunch was collected by Léa Poulin, Ingrid Dallmann and Pierre-Yves Durand (from evaluation and learning service of the innovation, research and knowledge department). Others were reported to us by the agriculture, rural development and biodiversity department. These datasets are combined with only relevant variables for future merging with WDPA and SIOP databases.

```{r, eval = FALSE}
#PAs gathered by the evaluation department
##BDD_joint created by Léa Poulin. 
##Create a dataset with a merged column for cofunders, instead of a variable for each. Only relevant variables are kept, and the date/author of the report are added.
data_pa_eva = 
  #read_excel("data_raw/BDD_joint.xlsx") %>%
  s3read_using(readxl::read_excel,
               object = "data_raw/BDD_joint.xlsx",
               bucket = "projet-afd-eva-ap",
               opts = list("region" = "")) %>%
  as.data.frame() %>%
  unite(cofinanciers, starts_with("cofinancier"),
        sep=",", remove = TRUE, na.rm = TRUE) %>%
  select(c(id_projet, id_concours, cofinanciers, 
           nom_ap, wdpaid, superficie)) %>%
  rename("superficie_km2" = "superficie") %>%
  mutate(superficie_km2 = as.numeric(superficie_km2),
         wdpaid = as.numeric(wdpaid),
         date_entree = "2022-12-06",
         auteur_entree = "Léa Poulin,Pierre-Yves Durand,Ingrid Dallmann") %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x)))

##WDPAID 797 with ID project CZZ3056 corresponds to APAC de Kawawana in Senegal, with no WDPAID (https://kawawana.iccaconsortium.org/) 
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$nom_ap = "APAC de Kawawana"
#Change reported area (https://kawawana.iccaconsortium.org/?p=150) : 10 000 ha or 100 km2
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$superficie_km2 = 100
data_pa_eva[data_pa_eva$wdpaid == "797" & data_pa_eva$id_projet == "CZZ3056",]$wdpaid = NA

#PAs gathered by agriculture, rural development and biodiversity department (10-08-2023)
data_pa_arb = 
  #read_excel("data_raw/BDD_ARB_10082023.xlsx") %>%
  s3read_using(readxl::read_excel,
             object = "data_raw/BDD_ARB_10082023.xlsx",
             bucket = "projet-afd-eva-ap",
             opts = list("region" = "")) %>%
  as.data.frame() %>%
  clean_names() %>%
  select(c(id_projet, id_concours, nom_cofinanciers,
           nom_de_laire_protegee, id_wdpa, superficie_km2)) %>%
  rename("cofinanciers" = "nom_cofinanciers",
         "nom_ap" = "nom_de_laire_protegee",
         "wdpaid" = "id_wdpa",
         "superficie_raw" = "superficie_km2") %>%
  #Create variables:
  ## Replace "NA" by NA values in wdpaid
  ## Check unit of area given reported by ARB
  ## Convert the area reported in km2, controlling for NA values, unreported values ("Non requis (information délivrée par la WDPA)"), values in hectares or km2. Note in some rows, unit must be removed and "," replaced by "." for the numeric conversion
  mutate(wdpaid = as.numeric(case_when(wdpaid == "NA" ~ NA,
                            TRUE ~ wdpaid)),
         date_entree = "2023-08-10",
         auteur_entree = "ARB",
         superficie_unit = case_when(grepl("km2", superficie_raw) ~ "km2",
                                     grepl("ha|Ha", superficie_raw) ~ "ha",
                                     TRUE ~ "km2"),
         superficie_km2 = case_when(grepl("Non", superficie_raw) ~ NA,
                                is.na(superficie_raw) ~ NA,
                                superficie_unit == "ha" ~ as.numeric(gsub(",", ".", gsub("ha|Ha", "", superficie_raw)))/1e2,
                                superficie_unit == "km2" ~ as.numeric(gsub(",", ".", gsub("km2", "", superficie_raw))),
                                TRUE ~ as.numeric(superficie_raw))) %>%
  # Change encoding of characters
  mutate(across(.cols = !c(wdpaid, superficie_km2),
                .fns = ~stri_enc_toutf8(.x))) %>%
  select(c("id_projet", "id_concours", "cofinanciers", "nom_ap",
           "wdpaid", "superficie_km2", "date_entree", "auteur_entree"))
  
#Create a dataset gathering the previous datasets
data_pa_afd = rbind(data_pa_eva, data_pa_arb)

#Finally, writing the dataset in csv file. Careful to the delimiter : ";" used as "," present in some variables values.
# write_delim(data_pa_afd, "data_raw/BDD_PA_AFD.csv",
#             delim = ";",
#             na = "NA")
# s3write_using(x = data_pa_afd,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_AFD.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Merge the list of PAs to AFD project information and WDPA

The list of PAs reported by AFD departments are then merged with AFD internal project information database (so-called "SIOP") and the World Database on Protected areas.

```{r, eval = FALSE}

#Import the list of PAs
data_pa_afd = 
  #read_delim("data_raw/BDD_PA_AFD.csv", delim = ";")
  s3read_using(readr::read_delim,
                delim = ";", #Careful to the delimiter choice
               show_col_types = FALSE,
                object = "data_raw/BDD_PA_AFD.csv",
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))

list_wdpa_afd = unique(data_pa_afd$wdpaid)

#Import SIOP extract
##A function to transform country names from upper case (SIOP database) to lower cases : FRANCE -> France
fn_ucfirst <- function (str) {
  paste(toupper(substring(str, 1, 1)), tolower(substring(str, 2)), sep = "")
}

data_siop_pa = 
  #read_excel("data_raw/BO_AP_16082023.xlsx") %>%
  s3read_using(readxl::read_excel,
              object = "data_raw/BO_AP_16082023.xlsx",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  #Keep only project IDs corresponding to PAs reported
  filter(id_projet %in% data_pa_afd$id_projet) %>%
  select(c(id_projet, id_concours,
           libelle_court_direction_regionale,
           pays_de_realisation, autres_pays_de_realisation,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           cofinancier,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_doctroi_projet, annee_doctroi_projet)) %>%
  rename("cofinanciers_siop" = "cofinancier",
         "pays" = "pays_de_realisation",
         "pays2" = "autres_pays_de_realisation") %>%
  #Change country ("pays") name from upper case to lower case : e.g FRANCE -> France 
  mutate(pays = case_when(is.na(pays) == TRUE ~ NA,
                         is.na(pays) == FALSE ~ fn_ucfirst(pays)),
         pays2 = case_when(is.na(pays2) == TRUE ~ NA,
                          is.na(pays2) == FALSE ~ fn_ucfirst(pays2))) %>%
  #Add ISO code from countrycode package, reading "pays" variable
  mutate(iso3_siop = countrycode(sourcevar = pays, 
                                 origin = "country.name.fr",
                                 destination = "iso3c",
                                 custom_match = c("Multi-pays" = "ZZ",
                                                  "Multi-Pays" = "ZZ",
                                                  "Inde" = "IND")),
         .after = "pays")
  
#Import WDPA data
##Download the latest version of the WDPA and write to the storage, if necessary
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)

##Load the WDPA from the storage
data_wdpa = 
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  st_drop_geometry() %>%
  clean_names() %>%
  filter(wdpaid %in% list_wdpa_afd) %>%
  rename("iso3_wdpa" = "iso3")

#Merge the datasets
##A first raw dataset that will be edited to complete ISO3 code of countries.
data_raw1 = data_pa_afd %>%
  #Add information from WDPA to PAs funded and with WDPAID
  left_join(data_wdpa, by = "wdpaid") %>%
  #Add information from SIOP
  left_join(data_siop_pa, by = c("id_projet", "id_concours")) %>%
  #Keep only one ISO information : priority WDPA, then SIOP if NA value
  mutate(iso3 = iso3_wdpa,
         iso3 = case_when(is.na(iso3) == TRUE ~ iso3_siop,
                          TRUE ~ iso3),
         .after = "iso3_wdpa")

#Manually add iso3 for some PAs where names are known but assigned "ZZ". 
#The nom_ap is searched on google ("nom_ap protected area") and iso3 completed if
#information found
data_raw2 = data_raw1 %>%
  mutate(iso3 = case_when(grepl("Yambé-Diahoué", nom_ap) ~ "NCL",
                          nom_ap == "Aitutaki (3 Ra'ui)" ~ "COK",
                          nom_ap == "Dohimen (Hienghène)" ~ "NCL",
                          nom_ap == "Kerehira" ~ "SLB",
                          nom_ap == "Kiribati" ~ "KIR",
                          nom_ap == "Marou" ~ "VUT",
                          nom_ap == "Mistery Island (Aneityum)" ~ "VUT",
                          nom_ap == "Ngula Pele" ~ "VUT",
                          nom_ap == "Paonangisu" ~ "VUT",
                          nom_ap == "Parc provincial Yeega-Hienga (Hienghène)" ~ "NCL",
                          grepl("Rarotonga", nom_ap) ~ "COK",
                          nom_ap == "Saama" ~ "VUT",
                          nom_ap == "Siviri" ~ "VUT",
                          nom_ap == "Dohimen" ~ "NCL",
                          nom_ap == "Hienghène" ~ "NCL",
                          nom_ap == "Hyabe Lé Jao" ~ "NCL",
                          grepl("Pouébo", nom_ap) ~ "NCL",
                          nom_ap == "Tasi Vanua" ~ "VUT",
                          nom_ap == "Yeega" ~ "NCL",
                          nom_ap == "Mangareva" ~ "PYF",
                          nom_ap == "Rakiraiki" ~ "FJI",
                          nom_ap == "Tasi Vanua" ~ "VUT",
                          nom_ap == "Parc National Pongara" ~ "GAB",
                          TRUE ~ iso3))

#Save this raw dataset
# s3write_using(x = data_raw2,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Correct errors

Here errors in the reported information are corrected manually. Note the SIOP can be updated and the error not present anymore. The errors that do not need to be corrected anymore are kept in comment.

```{r, eval = FALSE}
#Loading the raw dataset
data_raw = 
  #fread("data_raw/BDD_PA_raw.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
data_raw_corr = data_raw

#Modify errors in the dataset
##4223, 4224, 4226, 4228, 4229 : all in PS-N.Caledonie
## -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("4223", "4224", "4226", "4228", "4229") & data_raw_corr$pays == "Fidji",]$pays = "P-S N.Caléd"
##305082 : Vanuatu instead of Fidji
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("305082") & data_raw_corr$pays == "Fidji",]$pays = "Vanuatu"
##31459 : Central African Republic instead of Cameroon. 
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("31459") & data_raw_corr$pays == "Cameroun",]$pays = "Centrafrique"
##Rio Grande de Buba : Guinee Bissau instead of Gambia
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("317051") & data_raw_corr$pays == "Gambie",]$pays = "Guinee-Bissau"
##WDPAID 20267 : in GNQ instead of GIN
# -> not relevant with new SIOP extract
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$pays = "Guinee-Equatoriale"
# data_raw_corr[data_raw_corr$wdpaid %in% c("20267") ,]$iso3 = "GNQ"

# s3write_using(x = data_raw_corr,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_raw/BDD_PA_raw_corr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

### Tidy the datasets

After manual correction, a tidy dataset is built. Relevant variables are selected, region/sub-region/country names are added from ISO3 codes and countrycode package, description of IUCN categories added. Some variables are renamed in English.

```{r, eval = FALSE}
#Import raw dataset corrected from report errors
data_raw_corr = 
  #fread("data_raw/BDD_PA_raw_corr.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_raw/BDD_PA_raw_corr.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Build the tidy dataset
data_tidy = data_raw_corr %>%
  #Select relevant variables
  select(c(libelle_court_direction_regionale, pays, pays2, parent_iso3, iso3,
           id_projet, id_concours, nom_ap, wdpaid, wdpa_pid, 
           date_doctroi_projet, annee_doctroi_projet, status, status_yr,
           iucn_cat, marine, superficie_km2, rep_m_area, rep_area,
           gov_type, own_type,
           cofinanciers, cofinanciers_siop,
           mt_fin_global_af_d_prevu_devise,
           montant_prevu_concours_euro_octroi,
           mt_global_projet_prevu_devise,
           mt_part_cofinancier_prevu_euro,
           libelle_produit,
           date_entree, auteur_entree)) %>%
    #Create dummy variables for main investors
  #AFD is always funder, so no need of a dummy. 
  mutate(kfw_bin = grepl("KFW|kfw|KfW", cofinanciers),
         ffem_bin = grepl("ffem|FFEM", cofinanciers),
         cof_bin = is.na(cofinanciers) == FALSE & !(cofinanciers %in% c("AFD", "afd")),
         .after = "cofinanciers") %>%
  #Create an area variable combining AFD and WDPA information. Priority given to WDPA, then AFD if unknown
  rename("area_afd_km2" = "superficie_km2") %>%
  #If both are not NA and different, take rep_area
  #If both are equal, take rep_area
  #if one is NA, take the other
  #If both NA, set NA
  #If rep_area = 0 and area_afd_km2 != 0 then set area_afd_km2
  mutate(area_km2 = case_when(is.na(area_afd_km2) == FALSE & is.na(rep_area) == FALSE & area_afd_km2 == rep_area ~ rep_area,
                              is.na(area_afd_km2) == FALSE & is.na(rep_area) == FALSE & area_afd_km2 != rep_area ~ rep_area,
                              is.na(area_afd_km2) == TRUE & is.na(rep_area) == FALSE ~ rep_area,
                              is.na(area_afd_km2) == FALSE & is.na(rep_area) == TRUE ~ area_afd_km2,
                              is.na(area_afd_km2) == TRUE & is.na(rep_area) == TRUE ~ NA,
                              rep_area == 0 & is.na(area_afd_km2) == FALSE & area_afd_km2 >0 ~ area_afd_km2
                              ),
         .after = "rep_area") %>%
    #Some entries in "pays" are French department, DROM-COM, "Ocean Indien" or   
  #"Multi-Pays".
  #French related : the ISO3 code 
  #Ocen Indien let NA value, Muti-pays set to ZZ as in the SIOP dataset
  #Nouvelle-Calédonie is divided in two provinces : north and south. This subdivision is irrelevant in our analysis so we keep only "Nouvelle Caledonie"
  mutate(iso3 = case_when(
    pays == "Mayotte" ~ "MYT",
    pays == "Nouvelle-Caledonie" ~ "NCL",
    pays == "Polynesie Francaise" ~ "PYF",
    is.na(iso3) & pays %in% c("Multi-Pays", "Multi-pays", "Ocean Indien") ~ "ZZ",
    TRUE ~ iso3)) %>%
  #Add region, sub-region and country names from the ISO3 country code
  mutate(region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name",
                              custom_match = c("COG;CMR;CAF" = "Africa",
                                               "ZZ" = "")),
         sub_region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name",
                              custom_match = c("COG;CMR;CAF" = "Sub-Saharan Africa",
                                               "ZZ" = "")),
         country_en = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en",
                              custom_match = c("PYF" = "French Polynesia",
                                               "NCL" = "New Caledonia",
                                               "MYT" = "Mayotte",
                                               "COK" = "Cook Islands",
                                               "ZZ" = "Multi-countries",
                                               "COG;CMR;CAF" = "Multi-countries")),
         country_fr = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr",
                              custom_match = c("PYF" = "Polynésie Française",
                                               "NCL" = "Nouvelle-Calédonie",
                                               "MYT" = "Mayotte",
                                               "COK" = "Iles Cook",
                                               "ZZ" = "Multi-pays",
                                               "COG;CMR;CAF" = "Multi-pays")),
         .after = "iso3") %>%
#Change transboundary iso3 to ZZ (multi-countries)
  mutate(iso3 = case_when(iso3 == "COG;CMR;CAF" ~"ZZ",
                          TRUE ~iso3)) %>%
    #Some PAs have iso "ZZ" (multi-countries) by funded by Dr Ocean Pacifique. The region is assigned to Oceania
    mutate(region = case_when(region == "" & libelle_court_direction_regionale == "DR OCEAN PACIFIQUE" ~ "Oceania",
                              region == "" & grepl("sahel|guinee|africa", libelle_court_direction_regionale, ignore.case = TRUE) ~ "Africa",
                              region == "" & grepl("chine|asie", libelle_court_direction_regionale, ignore.case = TRUE) ~ "Asia",
                              region == "" & grepl("amerique", libelle_court_direction_regionale, ignore.case = TRUE) ~ "America",
                              region == "" ~ NA,
                            TRUE ~ region)) %>%
  #Add the description of IUCN from its category 'in French and English)
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
    #Modify class of some variables
  mutate(across(.cols = -c("wdpaid", "area_afd_km2", 
                           "area_km2", "rep_area", "rep_m_area",
                           "annee_doctroi_projet",
                          "mt_fin_global_af_d_prevu_devise",
                          "montant_prevu_concours_euro_octroi" ,
                          "mt_global_projet_prevu_devise",
                          "mt_part_cofinancier_prevu_euro"), 
                .fns = ~stri_enc_toutf8(.x))) %>%
  #Translate names in English
  rename("region_afd" = "libelle_court_direction_regionale",
         "name_pa" = "nom_ap",
         "date_funding" = "date_doctroi_projet",
         "year_funding" = "annee_doctroi_projet")


```

### Dataset with only AFD project variables

Build a dataset from the tidy dataset that keeps only SIOP variables. Potentially useful for analysis on SIOP information.

```{r, eval = FALSE}
#Select info corresponding to SIOP extract and AP 
list_var_siop = c("id_projet", "id_concours", "region_afd", "pays", "pays2", 
                  "date_funding", "year_funding", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise" ,
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit", "date_entree", "auteur_entree" )

#Definining dataset for future work with dataset other than WDPA 
data_siop_tidy = data_tidy %>%
  dplyr::select(all_of(list_var_siop))

#write_csv(data_siop_tidy, "data_tidy/BDD_siop_tidy.xlsx")
# s3write_using(x = data_siop_tidy,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_tidy_siop.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Dataset for non-confidential analysis

Build a dataset with one row per PA. In the list of PAs reported by AFD department, some PAs are also reported in the WDPA and are identified by a unique WDPA ID, some have no WDPAID but have a unique name, and other have neither name nor WDPAID. For the latter case, a PA is supposed to be identified by project ID and country. Thus we need to remove duplicates for each case. Also, all the funding years of each PA is kept. Note that a few PAs have an entry with WDPA ID, and an other with no WDPAID though they have the same name (e.g Parc National de Pongara). The duplicate without WDPA ID is removed.

For the impact analysis, we also need to take into account transboundary PAs (i.e PAs on more than one country). Indeed the analysis is performed country by country. Thus we need to divide the PAs across the countries it is located in, and re-compute the area of the PA in each country.

#### For descriptive statistics

```{r, eval = FALSE}
#Listing relevant variables for analysis that are NOT confidential (i.e not concern funding)
list_var_fund = c("cofinanciers", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise",
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit",
                  "kfw_bin", "ffem_bin", "cof_bin")

#Defining dataset for descriptive statistics
data_nofund = data_tidy %>%
  select(!all_of(list_var_fund))

#fwrite(data_nofund, "data_tidy/BDD_PA_AFD_nofund.csv")
# s3write_using(x = data_nofund,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#Then to keep only one row per PA, we need to consider separately PAs having WDPA ID and PAs which do not.

## Observations with WDPAID
###We keep information on fundings : one row for each wdpa_pid, funding year is kept
###Note that WDPA_PID is a unique identifier for zones inside the corresponding WDPAID. The choice of the WDPA_PID to keep is performed below (e.g choosing the area instead of the buffer zone)
data_nofund_wdpa = data_nofund %>%
  subset(is.na(wdpaid) == FALSE) %>%
  group_by(wdpa_pid, year_funding) %>%
  slice(1) %>%
  ungroup() %>%
  group_by(wdpa_pid) %>%
  #Then we create a variable with all the funding year for each WDPA ...
  mutate(year_funding_all = paste0(year_funding, collapse = ","),
         .after = "year_funding") %>%
  #... and keep only the earlier funding year for year_funding
  arrange(year_funding) %>%
  slice(1) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() %>%
  #Finally, we need to manually remove lines with more than one WDPA_PID
  ## Remove the marine area of WDPAID 9035 with null area
  filter(!(wdpa_pid == "9035_A")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A"))
  
# info_filtering = filter(data_raw_corr, wdpaid %in% c(9035, 555547861, 555547863, 555705345 )) %>%
#   group_by(wdpa_pid) %>%
#   slice(1)

#Observations without WDPAID but with name of the PA
data_nofund_name = data_nofund %>%
  subset(is.na(wdpaid) == TRUE & is.na(name_pa) == FALSE) %>%
  #Remove completely similar rows (due to merging with SIOP and WDPA)
  unique() %>%
  #Some PAs might have been funded at different times. Create a variable with all the funding year for each PA name
  group_by(name_pa) %>%
  mutate(year_funding_all = paste0(unique(year_funding), collapse = ","),
         .after = "year_funding") %>%
  mutate(year_funding_all = case_when(year_funding_all == "NA" ~NA,
                                      TRUE ~ year_funding_all)) %>%
  #keep observation with largest area reported
  arrange(-area_km2) %>%
  slice(1) %>%
  #Change year_funding to min of year_fund_all
  mutate(year_funding = min(as.numeric(unlist(strsplit(year_funding_all, split = ","))), na.rm = TRUE),
         year_funding = case_when(year_funding == Inf ~ NA,
                                  TRUE ~ year_funding)) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() %>%
  #Some PAs have multiple entries, with DR Siege de Paris and DR Ocean Pacifique. Their region is assigned to Oceania
  mutate(region = case_when(name_pa %in% c("Ailite", "Aitutaki (3 Ra'ui)",
                                               "Kerehira", 
                          "Kibelofolu", "Kiribati", "Ma'au", "Mereka", 
                          "Mistery Island (Aneityum)", "Ngula Pele", "Niu Houa",
                          "Niumarere", "Paonangisu", 
                          "Parc provincial Yeega-Hienga (Hienghène)", 
                          "Rarotonga : Avana-Muri lagoon ra'ui", 
                          "Rarotonga : Mitiaro ra'ui", "Saama", "Siviri", 
                          "Takara", "Takola", "Tavuilo", "Waimamaru") 
           & id_projet == "CZZ1282" ~ "Oceania",
         TRUE ~ region)) 
#Careful : the following filtering are outdated
  # filter(!(grepl("Aire de gestion durable des ressources Yambé", name_pa) & id_projet == "CZZ1282")) %>%
  # ##Remove duplicate with zero area while the other is non-zerp
  # filter(!(id_projet == "CZZ1667" & name_pa == "Dohimen")) %>%
  # filter(!(name_pa == "Hienghène" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Hyabe Lé Jao" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Naroko" & id_projet == "CZZ1667")) %>%
  # filter(!(name_pa == "Tasi Vanua" & id_projet == "CZZ166701")) %>%
  # filter(!(name_pa == "Yeega" & id_projet == "CZZ1667")) %>%
  # ##Remove duplicate of Pouébo with area 0
  # filter(!(name_pa == "Pweevo (Pouébo)"))

#Finally, observations with no WDPAID and no name_pa
data_nofund_na = data_nofund %>%
  subset(is.na(wdpaid) == TRUE & is.na(name_pa) == TRUE) %>%
  #Remove identical observations
  unique() %>%
    #Some PAs might have been funded at different times. Create a variable with all the funding year for each PA name
  group_by(id_projet, iso3) %>%
  mutate(year_funding_all = paste0(unique(year_funding), collapse = ","),
         .after = "year_funding") %>%
  mutate(year_funding_all = case_when(year_funding_all == "NA" ~NA,
                                      TRUE ~ year_funding_all)) %>%
  #keep observation with largest area reported
  arrange(-area_km2) %>%
  slice(1) %>%
  #Change year_funding to min of year_fund_all
  mutate(year_funding = min(as.numeric(unlist(strsplit(year_funding_all, split = ","))), na.rm = TRUE),
         year_funding = case_when(year_funding == Inf ~ NA,
                                  TRUE ~ year_funding)) %>%
  #Rename year_funding variable to precise it is the year of first funding by the AFD
  rename("year_funding_first" = "year_funding") %>%
  ungroup() 
  
#Finally bind the datasets
data_nofund_nodupl = rbind(data_nofund_wdpa, data_nofund_name, data_nofund_na) 

#fwrite(data_nofund_nodupl, "data_tidy/BDD_nofund_nodupl.csv")
# s3write_using(x = data_nofund_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

#### For impact analysis

Different datasets are built, depending on the portfolio to analyse (e.g PAs supported by AFD or a specific funder).

##### AFD portfolio

One PA in the AFD portfolio is located in Congo Republic, Cameroon and Republican Central Africa (WDPA ID 555547988). As by desing the impact analysis is performed country by country, this PA must be artificially divided in three and each part assigned to the country it is located in.

```{r, eval = FALSE}

#Import the non-confidential dataset with no duplicates
data_pa_nofund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Import WDPA data
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, geom)) %>%
  filter(wdpaid %in% data_pa_nofund_nodupl$wdpaid)

#The PA WDPAID 555547988 is located in COG, CMR and CAF
##Create a frame with one line by country
df_555547988 = data_pa_nofund_nodupl %>%
  filter(wdpaid == 555547988) %>%
  left_join(data_wdpa, by = "wdpaid") %>%
  #Create one line by country
  separate_longer_delim(cols = c("parent_iso3"), delim = ";") %>%
  mutate(iso3 = parent_iso3,
         country_en = countrycode(sourcevar = iso3,
                                  origin = "iso3c",
                                  destination = "un.name.en"),
        country_fr = countrycode(sourcevar = iso3,
                        origin = "iso3c",
                        destination = "un.name.fr"), 
        name_pa = paste(name_pa, iso3, sep = "-"))

##Get countries boundaries from geodata package
ctry_bnd = gadm(country = unique(df_555547988$iso3), 
                path = tempfile(),
                version = "latest", level = 0) %>%
  st_as_sf() %>%
  rename("geom_ctry" = "geometry",
         "iso3" = "GID_0")

##Take the intersection of each country with the transboundary polygon, then compute its area in km2
df_int = st_intersection(ctry_bnd, df_555547988$geom) %>%
  st_as_sf() %>%
  #Compute the area in km2
  mutate(area_int_km2 = as.numeric(st_area(geom_ctry))/1e6) %>%
  group_by(area_int_km2) %>%
  slice(1) %>%
  select(c("iso3", "area_int_km2")) %>%
  st_drop_geometry()

##Define the cropped dataset
df_cropd = df_555547988 %>% 
  left_join(df_int, by = "iso3") %>%
  mutate(area_km2 = area_int_km2) %>%
  select(c(names(data_pa_nofund_nodupl))) %>%
  st_drop_geometry()

##Replace the original transboundary line by multiple lines
data_pa_ie = data_pa_nofund_nodupl %>%
  #Select all lines excepted the one to replace
  filter(is.na(wdpaid) | wdpaid != 555547988) %>%
  #Add the multiple lines 
  rbind(df_cropd)

#Finally this dataset is saved
# s3write_using(x = data_pa_ie,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_ie.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

##### FAPBM portfolio

The Fund for Protected Areas and Biodiversity in Madagascar (FAPBM in French) is the main funder of PAs in Madagascar. A dataset specific to the PAs it supports is built, knowing the name of these PAs (FAPBM website).

```{r, eval = FALSE}
#The name of PAs funded by the FAPBM, as stated on their website (https://www.fapbm.org/aires-protegees-soutenues/, consulted the 2023-09-18).
# I have removed any "-" and replace it by "".
pa_fapbm_names = data.frame(name_pa = c("Ambohitantely", "Ibity", "Corridor Marojejy-Anjanaharibe Sud-Tsaratanana","Nosy Hara","Galoko Kalobinono","Analamerana"
                   ,"Anjanaharibe Sud","Lokobe","Manongarivo", "Ambodivahibe"
                   , "Andrafiamena Andavakoera", "Ankivonjy", "Ankarana", 
                   "Montagne d’Ambre","Montagne des Français", "Loky Manambato"
                   , "Tsaratanana", "Oronjia", "Masoala", "Marojejy", "Makira"
                   , "Ivohibe", "Befotaka Midongy", "Andringitra", "Massif d’Itremo"
                   , "Agnalazaha", "Ranomafana", "Manombo", "Zombitse Voabasia"
                   , "Nosy Ve Androka", "Kalambatritra", "Cap Sainte Marie", 
                   "Beza Mahafaly", "Andranomena", "Menabe Antimena", "Mikea"
                   , "Isalo", "Tsimanampetsotse", "Complexe Mangoky Ihotry"
                   , "Kirindy Mitea", "Andohahela", "Bombetoka", "Namoroka"
                   , "Sahamalaza Îles Radama", "Complexe Tsimembo Manambolomaty"
                   , "Mandrozo", "Complexe Mahavavy Kinkony", "Bemaraha"
                   , "Beanka", "Baie de Baly", "Site bioculturel d’Antrema"
                   , "Ankarafantsika", "Corridor Ankeniheny Zahamena", "Mangerivola"
                   , "Betampona", "Andasibe Mantadia", "Analamazaotra", "Nosy Mangabe"
                   , "Mananara Nord", "Zahamena", "Marotandrano", "Maromizaha"
                   , "Analalava", "Ambatovaky")) %>%
  #Change name for some PAs that are in WDPA but with slightly different name
  #after cross-checking with polygon of WDPA on https://www.protectedplanet.net/
  #and https://www.fapbm.org/aires-protegees-soutenues/
  #Not found :
  ## Corridor Marojejy-Anjanaharibe Sud-Tsaratanana
  mutate(name_pa = case_when(name_pa == "Andasibe Mantadia" ~ "Mantadia",
                             name_pa == "Bombetoka" ~ "Bombetoka Belemboka",
                             name_pa == "Complexe Mahavavy Kinkony" ~ "Complexe Zones Humides Mahavavy Kinkony",
                             name_pa == "Complexe Mangoky Ihotry" ~ "Complexe Zones Humides Mangoky Ihotry",
                             name_pa == "Kalambatritra" ~ "Kalambatrika",
                             name_pa == "Ibity" ~ "Massif d'Ibity",
                             name_pa == "Kirindy Mitea" ~ "Kirindy Mite",
                             name_pa == "Mandrozo" ~"Zone Humide de Mandrozo",
                             name_pa == "Montagne des Français" ~"Ambohitr'Antsingy Montagne des Français",
                             name_pa == "Tsimanampetsotse" ~ "Tsimanampesotse",
                             name_pa == "Zombitse Voabasia" ~ "Zombitse Vohibasia",
                             TRUE ~ name_pa)) %>%
  mutate(name_pa_clean = janitor::make_clean_names(name_pa))

#Filter the WDPA with PA funded by FAPBM
data_pa_fapbm = data_wdpa %>%
  janitor::clean_names() %>%
  filter(iso3 == "MDG") %>%
  mutate(name_clean = make_clean_names(name), .after = "name") %>%
  filter(name_clean %in% pa_fapbm_names$name_pa_clean) %>%
  mutate(area_km2 = rep_area, .after = "rep_area") %>%
  mutate(region_afd = "DR OCEAN INDIEN", 
         name_pa = name,
         region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") %>%
  #Add the description of IUCN from its category (French and English)
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  mutate(year_funding_first = NA, year_funding_all = NA)


#The PA funded by FAPBM but not in the WDPA
pa_fapbm_not_found = pa_fapbm_names %>%
  filter(!(name_pa_clean %in% data_pa_fapbm$name_clean))

#Save the dataset
# s3write_using(x = data_pa_fapbm,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_FAPBM.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

##### For Madagascar

A dataset is built from the WDPA. The only modification consists in adding region and country names, plus IUCN category description.

```{r, eval = FALSE}
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names()

data_pa_mdg = data_wdpa %>%
  filter(iso3 == "MDG") %>%
  mutate(name_clean = make_clean_names(name), .after = "name") %>%
  mutate(area_km2 = rep_area, .after = "rep_area") %>%
  mutate(region_afd = "DR OCEAN INDIEN", 
         name_pa = name,
         region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode::countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") %>%
  #Add the description of IUCN from its category
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ " Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  mutate(year_funding_first = NA, year_funding_all = NA) %>%
  #Finally compute centroid coordindates (to create maps) and dummy for FAPBM funded
  mutate(coord = st_centroid(geom),
        lon = unlist(map(coord,1)),
        lat = unlist(map(coord,2)),
         fapbm = wdpaid %in% data_pa_fapbm$wdpaid) 


#Save the dataset
# s3write_using(x = data_pa_mdg,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_MDG.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### Datasets for confidential analysis

The first funding dataset is there to perform descriptive statistics on project funding. Thus we do not need to have one line per PA, as it is not possible to isolate the funding a given WDPAID has received. We simply save the SIOP dataset for project reported as PAs related.

```{r, eval = FALSE}
#Listing relevant variables for descriptive statistics
list_var_fund = c("id_projet", "name_pa", "id_concours",
                "wdpaid", "country_en", "country_fr", "iso3",
                "region_afd", "region", "sub_region",
                "area_km2", "rep_area", "area_afd_km2",
                "cofinanciers", "cofinanciers_siop",
                  "mt_fin_global_af_d_prevu_devise",
                  "montant_prevu_concours_euro_octroi",
                  "mt_global_projet_prevu_devise",
                  "mt_part_cofinancier_prevu_euro",
                  "libelle_produit",
                  "date_funding",
                  "year_funding")


#Defining dataset for descriptive statistics on PAs funding. Keep one row for each id_projet/id_concours/cofinanciers of SIOP
data_fund = data_tidy %>%
  select(all_of(list_var_fund)) %>%
  group_by(id_projet, id_concours, cofinanciers_siop) %>%
  slice(1)


#fwrite(data_fund, "data_tidy/BDD_AFD_fund.csv")
# s3write_using(x = data_fund,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_fund.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

Then a dataset is built with funding associated to each WDPAID. Note a project can fund several WDPAID, and that AFD funding data do not make it possible to isolate the funding of each PA defined by a WDPAID.

```{r, eval = FALSE}
data_fund_pa = data_tidy

#For PAs with WDPAIDs
data_fund_wdpa = data_fund_pa %>%
    subset(is.na(wdpaid) == FALSE) %>%
  #We need to manually remove some WDPA_PID not relevant
  ## Remove the marine area with null area of WDPAID 9035
  filter(!(wdpa_pid == "9035_A")) %>%
  ## 555547861 has 3 marine PAs. The C one is chosen as the size reported by AFD (superficie_km2) matches the area reported by WDPA (https://www.protectedplanet.net/555547861)
  filter(!(wdpa_pid %in% c("555547861_A", "555547861_B"))) %>%
  # 555705345 : buffer area is also reported. Remove the buffer
  filter(!(wdpa_pid == "555705345_B")) %>%
  #555547863 : keep the WDPA_PID whose area matches the one reported by AFD employees and WDPA website (https://www.protectedplanet.net/555547863)
  filter(!(wdpa_pid == "555547863_A")) %>%
  #Finally, keep for each WDPAID the different funding it get
  group_by(id_projet, id_concours, wdpaid, cofinanciers) %>%
  slice(1) %>%
  ungroup()

#For PAs without WDPAIDs but a name_pa : for the PA identified by name_pa, keep id_projet/id_concours/confinanciers
data_fund_name = data_fund_pa %>%
  filter(is.na(wdpaid) == TRUE & is.na(name_pa) == FALSE) %>%
  group_by(id_projet, id_concours, name_pa, cofinanciers) %>%
  slice(1) %>%
  ungroup() 

  #For PAs without WDPAIDs nor name_pa : for the PA identified by id_projet/iso3, keep id_concours/confinanciers
data_fund_na = data_fund_pa %>%
  filter(is.na(wdpaid) == TRUE & is.na(name_pa) == TRUE) %>%
  group_by(id_projet, iso3, id_concours, cofinanciers) %>%
  slice(1) %>%
  ungroup() 


data_fund_pa_nodupl = rbind(data_fund_wdpa, data_fund_name, data_fund_na)

#fwrite(data_fund, "data_tidy/BDD_PA_AFD_fund.csv")
# s3write_using(x = data_fund_pa_nodupl,
#               FUN = readr::write_delim,
#               delim = ";",
#               object = "data_tidy/BDD_AFD_fund_PA.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

### A polygon dataset for specific use

The funding and non-funding datasets with polygon, for maps creation.

```{r, eval = FALSE}
#Loading the datasets
##WDPA data (polygons)
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, wdpa_pid, geom)) %>%
  mutate(geom_type = sf::st_geometry_type(geom))

## Non-confidential dataset
data_pa_nofund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

## Confidential dataset
data_pa_fund_nodupl = 
  #fread("data_tidy/BDD_AFD_fund_PA.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_AFD_fund_PA.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#Creating the dataset of with geospatial information (polygons)
data_pa_nofund_shp = data_pa_nofund_nodupl %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))
data_pa_fund_shp = data_pa_fund_nodupl %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))
data_pa_nofund_polygon_shp = data_pa_nofund_shp %>%
  filter(geom_type == "MULTIPOLYGON")


#Saving the datasets 

# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_nofund_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_nofund_polygon_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_nofund_polygon_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
    
# st_write(pa_shp,
#          dsn = "data_tidy/BDD_pa_afd_shp_pub.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_pa_fund_shp,
#               FUN = sf::st_write,
#               delim = ";",
#               object = "data_tidy/BDD_PA_AFD_fund_shp.geojson",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))
```

## Computing total areas covered by PAs in the sample

Knowing the total area covered by PAs at different level of aggregation is interesting per se. It is also necessary to compute several statistics (e.g average funding by unit of area). According to the WDPA documentation, it is likely that some reported polygons overlap. Simply summing the areas would thus lead to a biased estimate of the total area at a given level of aggregation. We follow the procedure of the WDPA (<https://www.protectedplanet.net/en/resources/calculating-protected-area-coverage>). Our case is simpler as all of the PAs we consider are given a polygon.

1.  The layer is converted to Mollweide (an equal area projection) and the area of each polygon is calculated, in km2.

2.  Intersection of polygons and the corresponding area are computed.

3.  Then the intersection can be aggregated at country, region or world level. Then it is subtracted to the sum of areas at country, region or world level. Note that intersections between PAs whose polygon is unknown won't be taken into account.

Note that the following codes are about computing total area at country/region/world level, taking potential intersections into account. It is not about generating a new shape files for the impact analysis. Indeed the overlap should be taken into account in the impact evaluation analysis codes.

### Computations of polygons' area

```{r, eval = FALSE}

#Importing shapefiles
sf_use_s2(FALSE)
pa_shp = 
  #read_sf("data_tidy/BDD_PA_AFD_shp.gpkg") %>%
  aws.s3::s3read_using(
  FUN = sf::read_sf,
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_nofund_shp.gpkg",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = "")) %>%
  #Take polygons only
  mutate(geom_type = as.character(st_geometry_type(geom))) %>%
  filter(geom_type == "MULTIPOLYGON") %>%
  #Ensure all geometries are valid
  st_make_valid() %>%
  #From multipolygon to polygon
  sf::st_cast(to="POLYGON") %>%
  #Select relevant variables
  dplyr::select(c(wdpaid, area_afd_km2, rep_area, geom, iso3, region_afd, region, sub_region, year_funding_first, year_funding_all)) 

#Spatial definition of wdpaid 555547988 overlaps CMR and CAF. Wdpaid 1245 corresponds to the CMR part. The overlap is removed and iso3 redefined so that 555547988 is CAF only. 
geom_555547988_1245 = st_difference(pa_shp[pa_shp$wdpaid == 555547988,]$geom, pa_shp[pa_shp$wdpaid == 1245,]$geom)
pa_shp[pa_shp$wdpaid == 555547988,]$geom = geom_555547988_1245
pa_shp[pa_shp$wdpaid == 555547988,]$iso3 = "CAF"

#Define a tidy version of the former dataset, with modifications on wdpaid 555547988
pa_shp_tidy = pa_shp %>%
  #Project to Mollweide to compute relevant areas in km2
  st_transform(crs = "+proj=moll +datum=WGS84") %>%
  #Compute areas in km2 from the geometry, in km2. It must be equal to gis_a by definition 
  #Then to take into account potential refinements of the geometries (as for wdpaid 55547988), a variable for relevant area is defined. It takes rep_a value except for modified geometries where area_sf_moll is taken
  mutate(area_sf_moll = as.numeric(st_area(geom)/1e6),
         area_afd_km2 = ifelse(wdpaid == 555547988, yes = area_sf_moll, no = rep_area))
```

### Computing the intersection at country, region, world level

```{r, eval = FALSE}

#Compute intersecting areas of polygons
pa_int = st_intersection(pa_shp_tidy, pa_shp_tidy) %>%
  #Remove intersection of polygons with themselves
  subset(wdpaid != wdpaid.1) %>%
  #If one of the two intersectin polygon have unknwon area, then it is not necessary to subtract the interesction area. Indeed there is no double-counting of the intersection in this case, when both polygon areas are summed.
  subset(is.na(area_afd_km2) == FALSE & is.na(area_afd_km2.1) == FALSE) %>%
  #Compute the intersecting areas (pa_shp already in Mollweide projection) in km2
  mutate(area_int = as.numeric(st_area(geom)/1e6)) %>%
  #Now duplicates need to be removed : intersection of X with Y AND intersection of Y with X are reported. We need only one.
  #An id_int to identify the intersection of a given pair
  mutate(id_int = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  mutate(id_int_temp = paste0(wdpaid, "_", wdpaid.1), .before = wdpaid) %>%
  #create a mirror idX_idY --> idY_idX so that we identify the both member of a pair with the same id
  separate(id_int_temp, into = c("id_temp1", "id_temp2"), sep = "_") %>%
  mutate(id_int_rev = case_when(
    id_temp1 < id_temp2 ~ paste(id_temp1, id_temp2, sep = "_"),
    id_temp1 > id_temp2 ~ paste(id_temp2, id_temp1, sep = "_"),
    TRUE ~ paste(id_temp1, id_temp2, sep = "_")),
    .after = id_int) %>%
  #finally, get rid of the duplicates (have the same id_int_rev)
  group_by(id_int_rev) %>%
  slice(1) %>%
  ungroup() %>%
  #select relevant variables only
  select(wdpaid, iso3, region_afd, region, sub_region, year_funding_first, wdpaid.1, iso3.1, region_afd.1, region.1, sub_region.1, year_funding_first.1, geom, area_int)

#Computing the total area of intersections
#At country level ...
pa_int_ctry = pa_int %>%
  #Only overlapping PAs in the same country are considered
  subset(iso3 ==  iso3.1) %>%
  group_by(iso3) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

#At region level
#AFD regions : not performed as some PAs have multiple DR and only one kept
# pa_int_dr = pa_int %>%
#   #Only overlapping PAs in the same DR are considered
#   subset(region_afd == region_afd.1) %>%
#   group_by(region_afd) %>%
#   summarize(tot_area_int = sum(area_int)) %>%
#   st_drop_geometry()

#UN regions
pa_int_region = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(region == region.1) %>%
  group_by(region) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()
#UN sub-regions
pa_int_subregion = pa_int %>%
  #Only overlapping PAs in the same DR are considered
  subset(sub_region == sub_region.1) %>%
  group_by(sub_region) %>%
  summarize(tot_area_int = sum(area_int)) %>%
  st_drop_geometry()

##At world level : all overlap are considered
pa_int_wld = sum(pa_int$area_int) 

#Compute the total intersection for each year
pa_int_yr = pa_int %>%
  #Define intersection year : the date ann_c of the later PA in the pair
  rowwise() %>%
  mutate(annee_int = max(year_funding_first, year_funding_first.1)) %>% 
  group_by(annee_int) %>%
  summarize(tot_int_km2 = sum(area_int)) %>%
  st_drop_geometry()

# fwrite(pa_int_yr,
#        "data_tidy/area/pa_int_yr.csv")
s3write_using(x = pa_int_yr,
              FUN = data.table::fwrite,
              object = "data_tidy/area/pa_int_yr.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))
```

### Computing total areas without intersection

```{r, eval = FALSE}

data_pa_afd = 
  #fread("data_raw/BDD_PA_AFD_nofund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

#At country level ...
pa_area_ctry = data_pa_afd %>%
  #Compute total area at country level
  group_by(iso3) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  #Add information on intersection area in each country. Modify the variable so that NA value -> 0
  left_join(pa_int_ctry, by = "iso3") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~ 0, TRUE ~ tot_area_int)) %>%
  #Compute the total area at country level without intersection
  mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) 

#fwrite(pa_area_ctry, "data_tidy/area/pa_area_ctry.csv")
# s3write_using(x = pa_area_ctry,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_ctry.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At AFD region level ...
# pa_area_dr = data_pa_afd %>%
#   #Compute total area at dr level
#   group_by(region_afd) %>%
#   summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
#   ungroup() %>%
#   #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
#   left_join(pa_int_dr, by = "region_afd") %>%
#   mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
#   #Compute the total area at country level without intersection
#     mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
#   st_drop_geometry()
# 
# #fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_dr,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_dr.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At UN region level
pa_area_region = data_pa_afd %>%
  #Compute total area at dr level
  group_by(region) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_region, by = "region") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
    mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_region,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_region.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At UN sub-region level
pa_area_subregion = data_pa_afd %>%
  #Compute total area at dr level
  group_by(sub_region) %>%
  summarize(area_tot_km2 = sum(area_afd_km2, na.rm = TRUE)) %>% 
  ungroup() %>%
  #Add information on intersection area in each DR. Modify the variable so that NA value -> 0
  left_join(pa_int_subregion, by = "sub_region") %>%
  mutate(tot_area_int = case_when(is.na(tot_area_int) == TRUE ~0, TRUE ~tot_area_int)) %>%
  #Compute the total area at country level without intersection
    mutate(area_tot_noint_km2 = area_tot_km2 - tot_area_int) %>%
  st_drop_geometry()

#fwrite(pa_area_dr, "data_tidy/area/pa_area_dr.csv")
# s3write_using(x = pa_area_subregion,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_subregion.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

#At world level
pa_area_wld = sum(data_pa_afd$area_afd_km2, na.rm = TRUE) - pa_int_wld %>%
  as.data.frame() %>%
  rename("area_tot_noint_km2" = ".")
#fwrite(pa_area_wld, "data_tidy/area/pa_area_wld.csv")
# s3write_using(x = pa_area_wld,
#               FUN = data.table::fwrite,
#               object = "data_tidy/area/pa_area_wld.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

<!--chapter:end:00_data_build.Rmd-->

# Biodiversity in the protected areas

THIS SCRIPT IS UNFINISHED

In this document are computed and plotted descriptive statistics for the protected areas (PAs) using the mapme biodiversity package. This package provides an easy access to biodiversity-related data and allow to compute different indicators.

## Importing packages and functions

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
source("scripts/functions/02_fns_DesStat_biodiv.R", encoding = "UTF-8")
```

```{r message=FALSE, warning=FALSE, eval = FALSE}
#The last version of mapme.biodiversity package is downloaded directly from github
# remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")
library(mapme.biodiversity)
library(sf)
library(tidyverse)
library(mapview)
library(magrittr)
library(stargazer)
library(dplyr)
library(openxlsx)
library(writexl)
library(ggplot2)
library(questionr)
library(readxl)
library(data.table)
library(sp)
library(raster)
library(terra)
library(janitor)
library(ARTofR)
library(aws.s3)
```

```{r, eval = FALSE}
#A first look at mapme biodiversity indicators

resources <- names(available_resources())
indicators <- names(available_indicators())
cat(paste("Supported resources:\n-",
            paste(resources, collapse = "\n- "),
          "\n\nSupported indicators:\n-",
            paste(indicators, collapse = "\n- ")))
```

## Setting the environment

This might be necessary to access SSPCloud storage from mapme.biodiversity functions.

```{r, eval = FALSE}

# Sys.setenv("AWS_ACCESS_KEY_ID" = "GD8CI0UQQPTETOZS65J2",
#            "AWS_SECRET_ACCESS_KEY" = "e0bsXE55qz+xmNeVdwhTb39wKoQuIJFC0Y6eqPoG",
#            "AWS_DEFAULT_REGION" = "us-east-1",
#            "AWS_SESSION_TOKEN" = "eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3NLZXkiOiJHRDhDSTBVUVFQVEVUT1pTNjVKMiIsImFsbG93ZWQtb3JpZ2lucyI6WyIqIl0sImF1ZCI6WyJtaW5pby1kYXRhbm9kZSIsIm9ueXhpYSIsImFjY291bnQiXSwiYXV0aF90aW1lIjoxNjg4NjUxNjk5LCJhenAiOiJvbnl4aWEiLCJlbWFpbCI6InZ1aWxsb3RhQGFmZC5mciIsImVtYWlsX3ZlcmlmaWVkIjp0cnVlLCJleHAiOjE2ODg3Mzg4NzgsImZhbWlseV9uYW1lIjoiVnVpbGxvdCIsImdpdmVuX25hbWUiOiJBbnRvaW5lIiwiZ3JvdXBzIjpbImFmZC1ldmEtYXAiXSwiaWF0IjoxNjg4NjUxNzAwLCJpc3MiOiJodHRwczovL2F1dGgubGFiLnNzcGNsb3VkLmZyL2F1dGgvcmVhbG1zL3NzcGNsb3VkIiwianRpIjoiN2ZmMjJhNmEtM2IyYS00NWFiLWJmYTItNmVhZDZkNzY5YzBhIiwibmFtZSI6IkFudG9pbmUgVnVpbGxvdCIsIm5vbmNlIjoiYjQzM2E1N2MtMjZiNS00NmE0LTkzOGItOGMyM2FmOTVlYTI5IiwicG9saWN5Ijoic3Rzb25seSIsInByZWZlcnJlZF91c2VybmFtZSI6InZ1aWxsb3RhIiwicmVhbG1fYWNjZXNzIjp7InJvbGVzIjpbIm9mZmxpbmVfYWNjZXNzIiwidW1hX2F1dGhvcml6YXRpb24iLCJkZWZhdWx0LXJvbGVzLXNzcGNsb3VkIl19LCJyZXNvdXJjZV9hY2Nlc3MiOnsiYWNjb3VudCI6eyJyb2xlcyI6WyJtYW5hZ2UtYWNjb3VudCIsIm1hbmFnZS1hY2NvdW50LWxpbmtzIiwidmlldy1wcm9maWxlIl19fSwic2NvcGUiOiJvcGVuaWQgcHJvZmlsZSBncm91cHMgZW1haWwiLCJzZXNzaW9uUG9saWN5IjoiZXlKV1pYSnphVzl1SWpvaU1qQXhNaTB4TUMweE55SXNJbE4wWVhSbGJXVnVkQ0k2VzNzaVJXWm1aV04wSWpvaVFXeHNiM2NpTENKQlkzUnBiMjRpT2xzaWN6TTZLaUpkTENKU1pYTnZkWEpqWlNJNld5SmhjbTQ2WVhkek9uTXpPam82Y0hKdmFtVjBMV0ZtWkMxbGRtRXRZWEFpTENKaGNtNDZZWGR6T25Nek9qbzZjSEp2YW1WMExXRm1aQzFsZG1FdFlYQXZLaUpkZlN4N0lrVm1abVZqZENJNklrRnNiRzkzSWl3aVFXTjBhVzl1SWpwYkluTXpPa3hwYzNSQ2RXTnJaWFFpWFN3aVVtVnpiM1Z5WTJVaU9sc2lZWEp1T21GM2N6cHpNem82T2lvaVhTd2lRMjl1WkdsMGFXOXVJanA3SWxOMGNtbHVaMHhwYTJVaU9uc2ljek02Y0hKbFptbDRJam9pWkdsbVpuVnphVzl1THlvaWZYMTlMSHNpUldabVpXTjBJam9pUVd4c2IzY2lMQ0pCWTNScGIyNGlPbHNpY3pNNlIyVjBUMkpxWldOMElsMHNJbEpsYzI5MWNtTmxJanBiSW1GeWJqcGhkM002Y3pNNk9qb3FMMlJwWm1aMWMybHZiaThxSWwxOVhYMD0iLCJzZXNzaW9uX3N0YXRlIjoiYWYyMDdlY2UtOWEzNi00OTQyLTllODYtNjA1NTJmNGYxZTg1Iiwic2lkIjoiYWYyMDdlY2UtOWEzNi00OTQyLTllODYtNjA1NTJmNGYxZTg1Iiwic3ViIjoiOTI3N2Y3MzMtNTBmMy00MjM4LWI1YzctNjRjMmU4YTZiNDI0IiwidHlwIjoiQmVhcmVyIn0.40_wwJeo7HhTJjvPyob96nNEvbCmvohcN7Wnd02ETirLobdTmE7QZZbd9q5P1ZGANkkIkAf8who86ELp1crWfw",
#            "AWS_S3_ENDPOINT"= "minio.lab.sspcloud.fr",
#            "AWS_HTTPS" = "FALSE",
#            "AWS_VIRTUAL_HOSTING"="FALSE")

```

## Importing PAs datasets

```{r message=FALSE, warning=FALSE, eval = FALSE}

#Load spatial data and transform into polygons (requirement of the mapme package)

#If the function get_resources used later returns an error "...Loop 0 is not valid: Edge 94 crosses edge 96>...", then the following function might solve it. It works if sf was updated v1.0 and more, and brings back to old way of working. sf uses mostly a flat Earth model instead of s2 spherical geometry in the new versions. 
sf_use_s2(FALSE)

#/!\ : in pa_shp, variable sprfc is the area reported by AFD members, and is not equal to rep_a (area reported by WDPA) nor superficie in the BDD_joint. The latter is a combination of rep_a and sprfc, where superficie = rep_a except if rep_a = 0 or not reported.
pa_shp = 
  read_sf("data_tidy/BDD_SHP_pub.gpkg") %>%
  # aws.s3::s3read_using(
  # FUN = sf::read_sf,
  # object = "data_tidy/BDD_shp_pub.gpkg",
  # bucket = "projet-afd-eva-ap",
  # opts = list("region" = "")) %>%
  st_make_valid() %>%
  sf::st_cast(to = "POLYGON")

#From BDD_joint, that is the combination of the SIOP dataset and the AP dataset from ARB team in AFD. Imported to have the information on the PA area (combination of areas reported by WDPA and ARB)
pa_nodupl = 
  fread("data_tidy/BDD_nofund_nodupl.csv") %>%
  # aws.s3::s3read_using(
  # FUN = data.table::fread,
  # encoding = "UTF-8",
  # object = "data_tidy/BDD_nofund_nodupl.csv",
  # bucket = "projet-afd-eva-ap",
  # opts = list("region" = "")) %>%
  dplyr::select(c(wdpaid, superficie))

#mapview(pa_shp)
```

## Downloading data of interests and compute relevant indicators

For the moment, mapme.biodiversity functions do not support reading/writing in a S3 server like SSPCloud. Waiting for the new release of the package, the following process is followed :

1.  Create a sub-folder in the temporary folder (RAM of the R session) to download and store the raw data

2.  Associate the portfolio to this sub-folder

3.  Download the raw data and compute the indicators of interest, unnest the data obtained

4.  Then, a dataframe can be saved.

Note that this solution is not time-optimal : raw data must be downloaded each time.

### Creating the portfolio

```{r, eval = FALSE}
#The raw data from mapme package are stored in a temporary folder
tmp = paste(tempdir(), "mapme", sep = "/")
#save_folder = get_bucket("projet-afd-eva-ap", region = "")

#Creating the portfolio
pa_pfolio = pa_shp[pa_shp$wdpaid == 1245,] %>%
  init_portfolio(2000:2021,
                 outdir = "data_raw/mapme_bio_data",
                 #cores = 4,
                 add_resources = TRUE,
                 verbose = TRUE)
```

### TEST : importing data from SSPCloud

data are downloaded from an other script and stored in the SSPCloud. Here : copy these data to the temporary storage of the R session, and use them to compute indicators.

```{r, eval = FALSE}

df_files = aws.s3::get_bucket("projet-afd-eva-ap",
                   prefix = "data_raw/mapme_bio_data/gfw_treecover/",
                   region = "") %>%
  as.data.frame()
list_files = df_files$Key
i = list_files[1]
for (i in list_files) 
{
  temp_file = s3read_using(FUN = terra::rast,
               object = i,
               bucket = "projet-afd-eva-ap",
               opts = list("region"=""))
  terra::writeRaster(temp_file, file.path(tempdir(), "test.tif"), overwrite = TRUE)
}
plot(temp_file)
```

### Compute indicators from geospatial data

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~
##  ~ Forests ----
##~~~~~~~~~~~~~~~~

#Modifying tile index
##Emissions
# tileindex_gfw_emissions = read_sf("D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/gfw_treecover/tileindex_gfw_emissions.gpkg") %>%
#   mutate(location = gsub("/tmp/Rtmp79IZ3f/mapme/",
#                          "D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/",
#                          location))
# write_sf(tileindex_gfw_emissions,
#          "D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/gfw_treecover/tileindex_gfw_emissions.gpkg")

##Treecover
# tileindex_gfw_treecover = read_sf("D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/gfw_treecover/tileindex_gfw_treecover.gpkg") %>%
#   mutate(location = gsub("/tmp/RtmpYU2AvZ/mapme/",
#                          "D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/",
#                          location))
# write_sf(tileindex_gfw_treecover,
#          "D:/Documents/Github/EVA-impact-aires-protegees/data_raw/mapme_bio_data/gfw_treecover/tileindex_gfw_treecover.gpkg")


##Downloading data and computing indicators 
pa_pfolio_tcover =
  get_resources(pa_pfolio,
    resources = c("gfw_lossyear","gfw_treecover","gfw_emissions"),
    vers_treecover = "GFC-2020-v1.8",
    vers_lossyear = "GFC-2020-v1.8") %>%
  # FAO forest definition here: Minimum treecover = 10%, minimum size =1 hectare
  calc_indicators(indicators = "treecover_area",
                min_cover = 10,
                min_size = 1, overwrite=T)



#Unest the sf file into a classic data frame without geometry
data_pfolio_tcover = unnest(pa_pfolio_tcover, cols="treecover_area") %>%
  sf::st_drop_geometry() %>%
  dplyr::select(wdpaid, assetid, years,treecover) %>%
  mutate(treecover = case_when(treecover == 0 ~ NA, TRUE ~ treecover)) %>%
  filter(!is.na(treecover))

#Write the dataframe into the bucket
s3write_using(data_pfolio_tcover,
              data.table::fwrite,
              object = "data_tidy/mapme_bio_data/data_pfolio_tcover.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")
              )

#Copying files to SSPCloud
##emissions
files_emi <- list.files(paste(tmp, "gfw_emissions", sep = "/"), 
                        full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files_emi) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_emissions", 
                     region = "", show_progress = TRUE)
}

##loss years
files_lossyear <- list.files(paste(tmp, "gfw_lossyear", sep = "/"), 
                        full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files_emi) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_lossyear", 
                     region = "", show_progress = TRUE)
}

##Treecover loss
files_treecover <- list.files(paste(tmp, "gfw_treecover", sep = "/"), 
                        full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files_emi) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/data_raw/mapme_bio_data/gfw_treecover", 
                     region = "", show_progress = TRUE)
}

#Removing files from temp
do.call(file.remove, list(list.files(paste(tmp, "gfw_emissions", sep = "/"), full.names = TRUE)))
do.call(file.remove, list(list.files(paste(tmp, "gfw_lossyear", sep = "/"), full.names = TRUE)))
do.call(file.remove, list(list.files(paste(tmp, "gfw_treecover", sep = "/"), full.names = TRUE)))


```

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~~~
##  ~ Mangroves ----
##~~~~~~~~~~~~~~~~~~

##Downloading data and computing indicators 
pa_pfolio_mang =
  get_resources(pa_pfolio,
    resources = c("gmw")) %>%
  # FAO forest definition here: Minimum treecover = 10%, minimum size =1      #hectare
  calc_indicators(indicators = "mangroves_area",
                overwrite=T)

##Unest the sf file into a classic data frame without geometry
data_pfolio_mang = unnest(pa_pfolio_mang, cols="mangroves_area") %>%
  sf::st_drop_geometry() %>%
  dplyr::select(wdpaid, assetid, year,mangrove_extent)
# s3write_using(data_pfolio_mang,
#               data.table::fwrite,
#               object = "data_tidy/mapme_bio_data/data_pfolio_mang.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = "")
#               )

# data_pfolio_mang = s3read_using(data.table::fread,
#               object = "data_tidy/mapme_bio_data/data_pfolio_mang.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = "")
#                                 )

#Removing files from temp
##emissions
files_mang <- list.files(paste(tmp, "gmw", sep = "/"), 
                        full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files_mang) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/data_raw/mapme_bio_data/gmw", 
                     region = "", show_progress = TRUE)
}

do.call(file.remove, list(list.files(paste(tmp, "gmw", sep = "/"), full.names = TRUE)))
```

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~~~~~
##  ~ Land cover   --
##~~~~~~~~~~~~~~~~~~~~

##Downloading data and computing indicators 
pa_pfolio_land = 
  get_resources(pa_pfolio,
    resources = c("esalandcover")) %>%
  calc_indicators(indicators = "landcover",
                overwrite=T) 

##Unnest data
data_pfolio_land = unnest(pa_pfolio_land, cols = "landcover") %>%
  st_drop_geometry() %>%
  dplyr::select(wdpaid, assetid, year, area, classes)
s3write_using(data_pfolio_land,
              data.table::fwrite,
              object = "data_tidy/mapme_bio_data/data_pfolio_land.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")
              )

# data_pfolio_land = s3read_using(data.table::fread,
#               object = "data_tidy/mapme_bio_data/data_pfolio_land.csv",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = "")
#                                 )

```

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~~~~
##  ~ Emissions  ----
##~~~~~~~~~~~~~~~~~~~

# pa_pfolio_emi = 
#     get_resources(pa_pfolio,
#     resources = c("gfw_lossyear","gfw_treecover","gfw_emissions"), 
#     vers_treecover = "GFC-2020-v1.8",
#     vers_lossyear = "GFC-2020-v1.8") %>%
#     calc_indicators(indicators = "treecoverloss_emissions",
#                   min_cover = 30,
#                   min_size = 1, overwrite=T)

# write_portfolio(pa_pfolio_emi,
#       dsn = "data_tidy/mapme_bio_data/pa_pfolio_emi.gpkg",
#       overwrite = FALSE)

pa_pfolio_emi = read_portfolio("data_tidy/mapme_bio_data/pa_pfolio_emi.gpkg")

# data_pfolio_emi = unnest(pa_pfolio_emi,
#                   cols="treecoverloss_emissions") %>%
#     sf::st_drop_geometry() %>%
#     dplyr::select(id_pr,wdpaid,years,emissions)

# fwrite(data_pfolio_emi,
#        "data_tidy/mapme_bio_data/data_pfolio_emi.csv")

data_pfolio_emi = fread("data_tidy/mapme_bio_data/data_pfolio_emi.csv")


```

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~~~~~
##  ~ Biome       ----
##~~~~~~~~~~~~~~~~~~~~

##Downloading data and computing indicators 
pa_pfolio_biome =
  get_resources(pa_pfolio,
    resources = c("teow")) %>%
  calc_indicators(indicators = "biome",
                overwrite=T)

# write_portfolio(pa_pfolio_biome, 
#       dsn = "01_data_tidy/mapme_bio_data/pa_pfolio_biome.gpkg",
#       overwrite = FALSE)

##Unest the sf file into a classic data frame without geometry
# data_biome = unnest(pa_pfolio_biome, cols="biome") %>%
#   sf::st_drop_geometry() %>%
#   dplyr::select(id_pr,wdpaid,year,mangrove_extent)


```

```{r message=FALSE, warning=FALSE, eval = FALSE}

##~~~~~~~~~~~~~~~~~~~~
##  ~ Soil features --
##~~~~~~~~~~~~~~~~~~~~

#/!\ voir quels indicateurs/mesures prendre !!

##Downloading data and computing indicators 

pa_pfolio_soil = 
  get_resources(pa_pfolio,
    resources = c("soilgrids")) %>%
  # FAO forest definition here: Minimum treecover = 10%, minimum size =1      #hectare
  calc_indicators(indicators = "soilproperties",
                overwrite=T) 

# write_portfolio(pa_pfolio_mang, 
#       dsn = "01_data_tidy/mapme_bio_data/pa_pfolio_mang.gpkg",
#       overwrite = FALSE)

##Unest the sf file into a classic data frame without geometry
# data_biome = unnest(pa_pfolio_biome, cols="biome") %>%
#   sf::st_drop_geometry() %>%
#   dplyr::select(id_pr,wdpaid,year,mangrove_extent)



```

```{r message=FALSE, warning=FALSE, eval = FALSE}
##~~~~~~~~~~~~~~~~~~~~
##  ~ Accessibility --
##~~~~~~~~~~~~~~~~~~~~

##Downloading data and computing indicators 
pa_pfolio_acc = 
  get_resources("nelson_et_al",
                range_traveltime = c("5k_10k", "100k_200k", 
                                     "500k_1mio", "1mio_5mio")) %>%
  calc_indicators("traveltime", 
                  stats_accessibility = c("min", "max"), 
                  engine = "extract")

# write_portfolio(pa_pfolio_mang, 
#       dsn = "01_data_tidy/mapme_bio_data/pa_pfolio_mang.gpkg",
#       overwrite = FALSE)

##Unest the sf file into a classic data frame without geometry
# data_biome = unnest(pa_pfolio_biome, cols="biome") %>%
#   sf::st_drop_geometry() %>%
#   dplyr::select(id_pr,wdpaid,year,mangrove_extent)
```

Faire une fonction pour l'extraction de tout jeu de données ? Répétitif en soit de faire forêts, mangroves, etc.

Warning and errors face and their meaning.

-   *although coordinates are longitude/latitude, st_intersects assumes that they are planar*.

    -   See <https://r-spatial.org/r/2020/06/17/s2.html> and <https://r-spatial.github.io/sf/articles/sf7.html#>. Basically I used sf_use_s2(FALSE) at the creation of the portfolio. Thus sf uses flat Earth model instead of s2 spherical geometry. The operation st_intersects assumes the data lie in a flat plane where one degree longitude equals one degree latitude, irrespective where the PA is on the world (equirectangular projection). Thus if the polygons are drawn from coordinates in a spherical geometry, the operation is performed on the wrong projection. Is it a problem in itself ? Well as a projection is a bijection between two coordinate systems, plygons that intersect (or not) in a projection will intersect in the second. However the polygons will be distorded (the more so as they are located closer to the poles), and the areas computed could be wrong. Anyway according to the documentation the WDPA polygons are provided in WGS84 geographic coordinate system, i.e a planar projection (Plate Carree) . No problem should arise from the warning then.

    -   So according to Florent Bedecarrats, this warning is related to an other issue. The sphere representing the Earth is transformed into a plane through a cut on a given line. If a polygon is located on this line, the flattened polygon is considered to go around the Earth. To test for this possibility, compare the area of the polygon to the true area of the PA.

-   *Avis : TIFFFillStrip:Read error at scanline 4294967295; got 0 bytes, expected 1387 (GDAL error 1)Avis : TIFFReadEncodedStrip() failed. (GDAL error 1).*

    This advice occurs during the computation of indicators (a few tenths for emissions). Fail to read some parts of the raster file ? Is it problematic for the whole process ?

    Best solution : remove the corresponding TIFF and download data again.

-   *Avis : D:/projet_AiresProtegees/00_data_raw/mapme_bio_data/gfw_lossyear/Hansen_GFC-2020-v1.8_lossyear_10N_010E.tif, band 1: IReadBlock failed at X offset 0, Y offset 29995: TIFFReadEncodedStrip() failed. (GDAL error 1)*

    Same as before. Best solution : remove the corresponding TIFF and download data again.

-   *Avis : Error : [crop] incorrect number of values (too many) for writing*

    Check the error in more details.

## Computing statistics

From the datasets obtained, statistics of interest can be computed and plotted.

### Forests

Variation of forest loss over time :

-   Building the figure dataset

```{r, eval = FALSE}
#Building the dataset
data_stat_treeloss = data_pfolio_forest %>%
  group_by(nm_ap) %>% 
  #Comoute variation over time in each PA
  mutate(lag_treecov = lag(treecover),
         loss = ((treecover - lag_treecov)/lag_treecov)*100) %>%
  ungroup() %>%
  #Regroup years for analysis in five years intervals
  mutate(years_regroup = case_when(
  years <= 2005 ~ "2000-2005",
  years <= 2010 ~ "2005-2010",
  years <= 2015 ~ "2010-2015",
  years <=2020 ~ "2015-2020",
  TRUE ~ NA),
  .after = years) %>%
  #Remove NA values for loss
  filter(!is.na(loss)) %>%
  #Compute mean loss for five years intervals in each PA
  group_by(nm_ap, years_regroup) %>%
  mutate(moy_5 = mean(loss)) %>%
  ungroup()

```

-   Statistics at PA level

```{r message=FALSE, warning=FALSE, eval = FALSE}

#Evolution for a given PA
##Buba
stat_forest_buba = stat_treeloss_id(df = data_stat_treeloss,
                                    id = "317051",
                                    name_pa = "AP Buba",
                                    treatment_yr = 2007)
fig_evo_buba = stat_forest_buba[[1]]
ggsave(plot = fig_evo_buba,
       filename = "fig_forest_loss_evo_ap_buba.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)
fig_evo5_buba = stat_forest_buba[[2]]
ggsave(plot = fig_evo5_buba,
       filename = "fig_forest_loss_evo5_ap_buba.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

#Niumi
stat_forest_niumi = stat_treeloss_id(df = data_stat_treeloss,
                                    id = "109037",
                                    name_pa = "AP Niumi",
                                    treatment_yr = 2008)
fig_evo_niumi = stat_forest_niumi[[1]]
ggsave(plot = fig_evo_niumi,
       filename = "fig_forest_loss_evo_ap_niumi.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)
fig_evo5_niumi = stat_forest_niumi[[2]]
ggsave(plot = fig_evo5_niumi,
       filename = "fig_forest_loss_evo5_ap_niumi.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

#Bamboung
stat_forest_bamboung = stat_treeloss_id(df = data_stat_treeloss,
                                    id = "555651496",
                                    name_pa = "AP Bamboung",
                                    treatment_yr = 2008)
fig_evo_bamboung = stat_forest_bamboung[[1]]
ggsave(plot = fig_evo_bamboung,
       filename = "fig_forest_loss_evo_ap_bamboung.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)
fig_evo5_bamboung = stat_forest_bamboung[[2]]
ggsave(plot = fig_evo5_bamboung,
       filename = "fig_forest_loss_evo5_ap_bamboung.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)




```

/! Modifier le code précédent pour inclure plusieurs aires ???

-   Statistics at region level

```{r, eval = FALSE}
#Evolution at region level : dataset
data_stat_treeloss_reg = data_stat_treeloss %>%
  group_by(drct, years) %>%
  #For each region and each period, compute average evolution
  mutate(evo_avg_reg = mean(treecover)) %>%
  ungroup() %>%
  group_by(drct) %>% 
  #Variation of the average evolution over time in each region
  mutate(lag_region = lag(evo_avg_reg),
         loss_region = ((evo_avg_reg - lag_region)/lag_region)*100) %>%
  #remove 2001 : either NA, or take value above when two regions are consecutive in the data frame (lag by region not applied) ???
  mutate(loss_region = case_when(
    !is.na(loss_region) & years == 2001 ~ NA,
    TRUE ~loss_region))

#Sahel
fig_evo_sahel = stat_treeloss_reg(df = data_stat_treeloss_reg,
                                  reg = "Dr Grand Sahel",
                                  name_reg = "Sahel")
ggsave(plot = fig_evo_sahel,
       filename = "fig_forest_loss_evo_reg_sahel.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

#Guinea gulf
fig_evo_guinee = stat_treeloss_reg(df = data_stat_treeloss_reg,
                                  reg = "Dr Golfe De Guinee",
                                  name_reg = "Golfe de Guinée")

ggsave(plot = fig_evo_guinee,
       filename = "fig_forest_loss_evo_reg_guinee.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

#Eastern Africa
fig_evo_eastAf = stat_treeloss_reg(df = data_stat_treeloss_reg,
                                  reg = "Dr Afrique De L'Est",
                                  name_reg = "Afrique de l'Est")
ggsave(plot = fig_evo_eastAf,
       filename = "fig_forest_loss_evo_reg_eastAf.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

#Eastern Africa
fig_evo_austAf = stat_treeloss_reg(df = data_stat_treeloss_reg,
                                  reg = "Dr Afrique Australe",
                                  name_reg = "Afrique australe")

ggsave(plot = fig_evo_austAf,
       filename = "fig_forest_loss_evo_reg_austAf.png",
       path = "05_StatDes/biodiversity/forest/loss",
       width = 7, height = 5)

```

### Mangrove

Summary table of mangrove area in each PA :

```{r, eval = FALSE}
tbl_mang_summary = data_mang %>%
  dplyr::group_by(wdpaid) %>%
  summarize(area_sqkm = sum(value))
```

### Emissions

/! pas clair

Summary table of emissions in each PA :

```{r, eval = FALSE}
# create summary table 
tbl_emi_summary = data_emi %>%
  group_by(name) %>%
  summarize(area_sqkm = sum(value))
```

### Biome/TEOW

<!--chapter:end:01_stat_biodiv.Rmd-->

# Generating maps

## Importing relevant packages

```{r setup, include = FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r message=TRUE, warning=TRUE, eval = FALSE}
install.packages(c("janitor", "wdpar", "countrycode"))
library(tidyverse)
library(dplyr)
library(data.table)
library(readxl)
library(janitor)
library(stringi)
library(sf)
library(terra)
library(mapview)
library(wdpar)
library(aws.s3)
library(countrycode)

#Install webdriver to download WDPA data
#webdriver::install_phantomjs()

```

## Importing datasets

```{r, eval = FALSE}

#Import dataset of PAs (1 row = 1 PA)
data_pa_fund_nodupl = 
  #fread("data_raw/BDD_PA_AFD_fund_nodupl.csv")
  s3read_using(readr::read_delim,
               delim = ";",
               show_col_types = FALSE,
               object = "data_tidy/BDD_PA_AFD_fund_nodupl.csv",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

data_pa_fund_wdpa = data_pa_fund_nodupl %>%
  filter(is.na(wdpaid) == FALSE)
#Define a list of iso to download WDPA data
list_iso = data_pa_fund_wdpa %>%
  filter(!(iso3 %in% c("COG;CMR;CAF", "ZZ") | is.na(iso3))) %>%
  select(iso3) %>%
  unique() 
list_iso = list_iso$iso3

#Import WDPA data
##Either download and store it ...
# data_wdpa = wdpa_fetch(x = list_iso, wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)
# s3write_using(x = data_wdpa,
#               FUN = sf::st_write,
#               object = "data_raw/wdpa/17_08_2023/wdpa_shp_global_raw.gpkg",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

##... or import it from SSP Cloud
data_wdpa =
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  clean_names() %>%
  select(c(wdpaid, wdpa_pid, geom)) %>%
  mutate(geom_type = st_geometry_type(geom))


#Polygons from WDPA are added to the PAs funded
data_pa_fund_shp = data_pa_fund_wdpa %>%
  left_join(data_wdpa, by = c("wdpaid", "wdpa_pid"))

# s3write_using(x = data_pa_fund_shp,
#               FUN = sf::st_write,
#               object = "data_tidy/BDD_PA_AFD_fund_shp.gpkg",
#               bucket = "projet-afd-eva-ap",
#               opts = list("region" = ""))

```

<!--chapter:end:01_stat_maps.Rmd-->

# Miscellaneous statistics

In this document are performed and plotted statistics for particular needs (analysis of a particular portfolio, some specific group of PAs, etc.)

## Initial settings

Configuring Rmarkdown.

# ```{r setup, include=FALSE, eval = FALSE}
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
# ```

Installing and importing relevant packages.

```{r message=FALSE, warning=FALSE, eval = FALSE}
install.packages(c("stargazer", "janitor", "questionr", "countrycode", "WDI"))
library(tidyverse)
library(stargazer)
library(dplyr)
library(sf)
library(ggplot2)  
library(ggrepel)
library(RColorBrewer)
library(countrycode)
library(data.table)
#library(readxl)
#library(splitstackshape) 
library(janitor)
library(xtable)
library(questionr)
library(aws.s3)
library(WDI)
library(countrycode)
```

## Importing datasets

A dataset with information for each protected area funded by the AFD, and datasets on aggregated size at country/region/world level and by year. The latter takes into account potential overlap between PAs reported in the World Database on Protected Areas (WDPA).

```{r, eval = FALSE}
#Dataset of AFD supported protected area, with one line per protected area
data_stat_nodupl = 
  #fread("data_tidy/BDD_PA_AFD_nofund_nodupl.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

# Portfolio of protected areas supported by the FAPBM
data_pa_fapbm = 
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_FAPBM.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

#Import WDPA data
## Download and save data
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)
## Load data
data_wdpa = 
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  #st_drop_geometry() %>%
  clean_names() %>%
  #Add region, sub-region and country names 
  mutate(region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") 

#Subset of WDPA data for Madagascar, with IUCN category description (English and French)
data_wdpa_mdg = data_wdpa %>%
  filter(iso3 == "MDG") %>%
  #Add the description of IUCN from its category
    mutate(iucn_des_fr = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Réserve naturelle intégrale",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Zone de nature sauvage",
  !is.na(wdpaid) & iucn_cat == "II" ~ "Parc national", 
  !is.na(wdpaid) & iucn_cat == "III" ~ "Monument naturel",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Gest. des habitats/espèces",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Paysage protégé",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Gest. de ress. protégées",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Non catégorisée",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Non catégorisée",
  TRUE ~ "Non référencée"), .after = iucn_cat) %>%
      mutate(iucn_des_en = case_when(
  !is.na(wdpaid) & iucn_cat == "Ia" ~ "Strict nature reserve",
  !is.na(wdpaid) & iucn_cat == "Ib" ~ "Wilderness area",
  !is.na(wdpaid) & iucn_cat == "II" ~ "National park",
  !is.na(wdpaid) & iucn_cat == "III" ~ "Natural monument or feature",
  !is.na(wdpaid) & iucn_cat == "IV" ~ "Habitat or species management area",
  !is.na(wdpaid) & iucn_cat == "V" ~ "Protected landscape or seascape",
  !is.na(wdpaid) & iucn_cat == "VI" ~ "Protected area with sust. use of nat. res.",
  !is.na(wdpaid) & iucn_cat == "Not Applicable" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Reported" ~ "Not categorized",
  !is.na(wdpaid) & iucn_cat == "Not Assigned" ~ "Not categorized",
  TRUE ~ "Not referenced"), .after = iucn_cat) %>%
  st_drop_geometry()

#To perform statistics on the distribution of PAs reported by the WDPA across countries/regions, we focus on not high-income countries.
#Precisely, we restrict to countries defined as low-income, lower middle-income, upper-middle income, minus Russia, and including Chile, Uruguay New Caledonia and Panama
df_ctry_stat_wdpa = WDI(country = "all", start = "1960", end = "2022", extra = TRUE, language = "en") %>%
  group_by(iso3c) %>%
  slice(1) %>%
  ungroup() %>%
  select(c("iso3c", "income")) %>%
  rename("iso3" = "iso3c",
         "wb_inc_grp" = "income") %>%
  filter((wb_inc_grp %in% c("Low income",  "Lower middle income", "Upper middle income") & iso3 != "RUS") | iso3 %in% c("CHL", "URY", "PAN", "NCL"))

lst_ctry_stat_wdpa = df_ctry_stat_wdpa$iso3


```

## Performing descriptive statistics

### FAPBM portfolio and Madagascar

#### IUCN

FAPBM

```{r, eval = FALSE}
#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_pa_fapbm %>%
  filter(marine %in% c(0,1)) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_pa_fapbm %>%
  filter(marine %in% c(0,1)) %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Pie charts
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas funded by FAPBM")) %>%
  #+ scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_en

pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories \nexcept for not categorized (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "non-marine protected areas funded by FAPBM")) %>%
  #+ scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
    + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_ref_en


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/FAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

All protected areas in Madagascar (reported by the WDPA)

```{r, eval = FALSE}
#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Pie charts
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas in Madagascar")) %>%
  # + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
      + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_en

pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories \nexcept for not categorized (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "non-marine protected areas in Madagascar")) %>%
  # + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
    + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_ref_en

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/MDG/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

Madagascar protected areas without FAPBM funded protected areas.

```{r, eval = FALSE}
#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Pie charts
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine, not FAPBM funded protected areas in Madagascar")) %>%
  # + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
      + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_en

pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories \nexcept for not categorized (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "non-marine, not FAPBM funded protected areas in Madagascar")) %>%
  # + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
    + scale_fill_manual(name = "Categories",
                      values = c("Not categorized" = "#7570B3",
                                 "Habitat or species management area" = "#E7298A",
                                 "Protected landscape or seascape" = "#66A61E",
                                 "Protected area with sust. use of nat. res." = "#D95F02",
                                 "National park" = "#1B9E77",
                                 "Strict nature reserve" = "#E6AB02")) %>%
  + theme_void()
pie_cat_iucn_ref_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/MDG_noFAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Ecosystem

FAPBM funded protected areas.

```{r, eval = FALSE}

#Build datasets
data_eco = data_pa_fapbm %>%
  #subset non-referencded PAs (have NA ecosysteme)
  subset(is.na(marine) == FALSE) %>%
  mutate(marine = as.factor(marine))
data_eco$ecosyst_en = fct_recode(data_eco$marine, 
                              "Terrestrial"="0", 
                              "Coastal"="1", 
                              "Marine"="2")
data_eco$ecosyst_fr = fct_recode(data_eco$marine, 
                              "Terrestre"="0", 
                              "Côtier"="1", 
                              "Marin"="2")

data_eco_hist = data_eco %>%
  group_by(ecosyst_en, ecosyst_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_eco), 2)*100) %>%
  ungroup()

#Histogram in number (in English)
pie_eco_en = ggplot(data_eco_hist, 
                     aes(x = "", y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = "Proportion of protected areas by ecosystem type",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "protected areas funded by the FAPBM"),
         x = "Ecosystem type",
         y = "Proportion of protected areas") %>%
  #+ scale_fill_brewer(name = "Ecosystem", palette="Paired") %>%
  + scale_fill_manual(name = "Ecosystem",
                      values = c("Marine" = "#1F78B4",
                                 "Terrestrial" = "#B2DF8A",
                                 "Coastal" = "#A6CEE3")) %>%
  + theme_void()
pie_eco_en

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_eco_en.png", sep = "/"),
       plot = pie_eco_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/ecosysteme/FAPBM", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

All protected areas in Madagascar (reported by the WDPA)

```{r, eval = FALSE}

#Build datasets
data_eco = data_wdpa_mdg %>%
  #subset non-referencded PAs (have NA ecosysteme)
  subset(is.na(marine) == FALSE) %>%
  mutate(marine = as.factor(marine))
data_eco$ecosyst_en = fct_recode(data_eco$marine, 
                              "Terrestrial"="0", 
                              "Coastal"="1", 
                              "Marine"="2")
data_eco$ecosyst_fr = fct_recode(data_eco$marine, 
                              "Terrestre"="0", 
                              "Côtier"="1", 
                              "Marin"="2")

data_eco_hist = data_eco %>%
  group_by(ecosyst_en, ecosyst_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_eco), 2)*100) %>%
  ungroup()

#Histogram in number (in English)
pie_eco_en = ggplot(data_eco_hist, 
                     aes(x = "", y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = "Proportion of protected areas by ecosystem type",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "protected areas in Madagascar"),
         x = "Ecosystem type",
         y = "Proportion of protected areas") %>%
  # + scale_fill_brewer(name = "Ecosystem", palette="Paired") %>%
  + scale_fill_manual(name = "Ecosystem",
                      values = c("Marine" = "#1F78B4",
                                 "Terrestrial" = "#B2DF8A",
                                 "Coastal" = "#A6CEE3")) %>%
  + theme_void()
pie_eco_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_eco_en.png", sep = "/"),
       plot = pie_eco_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/ecosysteme/MDG", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

Madagascar without FAPBM

```{r, eval = FALSE}

#Build datasets
data_eco = data_wdpa_mdg %>%
  #subset non-referencded PAs (have NA ecosysteme)
  subset(is.na(marine) == FALSE) %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  mutate(marine = as.factor(marine))
data_eco$ecosyst_en = fct_recode(data_eco$marine, 
                              "Terrestrial"="0", 
                              "Coastal"="1", 
                              "Marine"="2")
data_eco$ecosyst_fr = fct_recode(data_eco$marine, 
                              "Terrestre"="0", 
                              "Côtier"="1", 
                              "Marin"="2")

data_eco_hist = data_eco %>%
  group_by(ecosyst_en, ecosyst_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_eco), 2)*100) %>%
  ungroup()

#Histogram in number (in English)
pie_eco_en = ggplot(data_eco_hist, 
                     aes(x = "", y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = "Proportion of protected areas by ecosystem type",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "protected areas in Madagascar, not funded by the FAPBM"),
         x = "Ecosystem type",
         y = "Proportion of protected areas") %>%
  # + scale_fill_brewer(name = "Ecosystem", palette="Paired") %>%
  + scale_fill_manual(name = "Ecosystem",
                      values = c("Marine" = "#1F78B4",
                                 "Terrestrial" = "#B2DF8A",
                                 "Coastal" = "#A6CEE3")) %>%
  + theme_void()
pie_eco_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "pie_eco_en.png", sep = "/"),
       plot = pie_eco_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/ecosysteme/MDG_noFAPBM", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Governance

FAPBM funded protected areas

```{r, eval = FALSE}

#Table of the governance type distribution
##English version
data_gov_en = data_pa_fapbm %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_pa_fapbm %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")


##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Governance type of non-marine protected areas \nexcept for not reported governance",
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "out of", sum(data_gov_en$n), "non-marine protected areas funded by FAPBM")) %>%
  # + scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + scale_fill_manual(name = "Governance",
                      values = c("Not Reported" = "#A6CEE3",
                                 "Local communities" = "#1F78B4",
                                 "Government-delegated management" = "#B2DF8A",
                                 "Non-profit organisations" = "#33A02C",
                                 "Collaborative governance" = "#FB9A99",
                                 "Federal or national ministry or agency" = "#E31A1C")) %>%
  + theme_void()
pie_gov_knwn_en


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_knwn_en, 
             caption = "Governance of non-marine protected areas funded by FAPBM (when known)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))

ggsave(paste(tmp, "pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/gouvernance/FAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

All protected areas in Madagascar (reported by the WDPA)

```{r, eval = FALSE}

#Table of the governance type distribution
##English version
data_gov_en = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_wdpa_mdg %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")


##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Governance type of non-marine protected areas \nexcept for not reported governance",
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "out of", sum(data_gov_en$n), "protected areas in Madagascar")) %>%
  #+ scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + scale_fill_manual(name = "Governance",
                      values = c("Not Reported" = "#A6CEE3",
                                 "Local communities" = "#1F78B4",
                                 "Government-delegated management" = "#B2DF8A",
                                 "Non-profit organisations" = "#33A02C",
                                 "Collaborative governance" = "#FB9A99",
                                 "Federal or national ministry or agency" = "#E31A1C")) %>%
  + theme_void()
pie_gov_knwn_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_knwn_en, 
             caption = "Governance of non-marine protected areas in Madagascar (when known)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))

ggsave(paste(tmp, "pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/gouvernance/MDG/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

Madagascar without FAPBM funded protected areas

```{r, eval = FALSE}

#Table of the governance type distribution
##English version
data_gov_en = data_wdpa_mdg %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_wdpa_mdg %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")


##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Governance type of non-marine protected areas \nexcept for not reported governance",
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "out of", sum(data_gov_en$n), "protected areas in Madagascar, not funded by the FAPBM")) %>%
  #+ scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + scale_fill_manual(name = "Governance",
                      values = c("Not Reported" = "#A6CEE3",
                                 "Local communities" = "#1F78B4",
                                 "Government-delegated management" = "#B2DF8A",
                                 "Non-profit organisations" = "#33A02C",
                                 "Collaborative governance" = "#FB9A99",
                                 "Federal or national ministry or agency" = "#E31A1C")) %>%
  + theme_void()
pie_gov_knwn_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_knwn_en, 
             caption = "Governance of non-marine protected areas in Madagascar, not funded by the FAPBM (when known)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))

ggsave(paste(tmp, "pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/gouvernance/MDG_noFAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Number of PAs

```{r, eval = FALSE}
#Statistics

## PAs in the WDAP
n_mdg = data_wdpa_mdg %>%
  filter(iso3 == "MDG") %>%
  nrow()
n_fapbm = data_pa_fapbm %>%
  filter(iso3 == "MDG") %>%
  nrow()

## PAs in the WDAP, not marine
n_mdg_nomarine = data_wdpa_mdg %>%
  filter(iso3 == "MDG" & marine %in% c(0,1)) %>%
  nrow()
n_fapbm_nomarine = data_pa_fapbm %>%
  filter(iso3 == "MDG" & marine %in% c(0,1)) %>%
  nrow()

## PA we can analyze with our methodology
yr_min = 2002
n_mdg_ie = data_wdpa_mdg %>%
  filter(iso3 == "MDG") %>%
  filter(status_yr >= yr_min & marine %in% c(0,1) & rep_area > 1 ) %>%
  nrow()
n_fapbm_ie = data_pa_fapbm %>%
  filter(iso3 == "MDG") %>%
  filter(status_yr >= yr_min & marine %in% c(0,1) & area_km2 > 1 ) %>%
  nrow()
```

#### Area of PAs

FAPBM funded protected areas

```{r, eval = FALSE}

tbl_area_fapbm = data_pa_fapbm %>%
  filter(marine %in% c(0,1)) %>%
  summarize(n = n(),
            tot = format(sum(area_km2), big.mark = ",", digits = 1, scientific = FALSE),
            min = format(min(area_km2), big.mark = ",", digits = 1, scientific = FALSE),
            max = format(max(area_km2), big.mark = ",", digits = 1, scientific = FALSE),
            mean = format(mean(area_km2), big.mark = ",", digits = 1, scientific = FALSE)
            )
names(tbl_area_fapbm) = c("Number of PAs", "Total area (km²)", "Min. area (km²)", "Max. area (km²)", "Average area (km²)")
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_area_fapbm, 
             caption = "Statistics on non-marine protected areas funded by FAPBM",
             type = "latex"), 
      file = paste(tmp, "tbl_area_fapbm.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/surface/FAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory 

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))  
```

All protected areas in Madagascar (reported by the WDPA)

```{r, eval = FALSE}

tbl_area_mdg = data_wdpa_mdg %>%
  st_drop_geometry() %>%
  filter(marine %in% c(0,1)) %>%
  summarize(n = n(),
            tot = format(sum(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            min = format(min(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            max = format(max(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            mean = format(mean(rep_area), big.mark = ",", digits = 1, scientific = FALSE)
            )
names(tbl_area_mdg) = c("Number of PAs", "Total area (km²)", "Min. area (km²)", "Max. area (km²)", "Average area (km²)")
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_area_mdg, 
             caption = "Statistics on non-marine protected areas in Madagascar",
             type = "latex"), 
      file = paste(tmp, "tbl_area_mdg.tex", sep = "/"))


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/surface/MDG/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

Madagascar without FAPBM funded protected areas.

```{r, eval = FALSE}

tbl_area_mdg_nofapbm = data_wdpa_mdg %>%
  st_drop_geometry() %>%
  filter(marine %in% c(0,1)) %>%
  filter(!(wdpaid %in% data_pa_fapbm$wdpaid)) %>%
  summarize(n = n(),
            tot = format(sum(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            min = format(min(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            max = format(max(rep_area), big.mark = ",", digits = 1, scientific = FALSE),
            mean = format(mean(rep_area), big.mark = ",", digits = 1, scientific = FALSE)
            )
names(tbl_area_mdg_nofapbm) = c("Number of PAs", "Total area (km²)", "Min. area (km²)", "Max. area (km²)", "Average area (km²)")
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_area_mdg_nofapbm, 
             caption = "Statistics on non-marine protected areas in Madagascar, not funded by the FAPBM",
             type = "latex"), 
      file = paste(tmp, "tbl_area_mdg_nofapbm.tex", sep = "/"))


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/surface/MDG_noFAPBM/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

## Evolution of tree cover and deforestation

All protected areas in Madagascar (reported by the WDPA)

```{r, eval = F}
##2000 tree cover 
data_treecover_2000 = 
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/GFW/MDG/treecover_extent_2000__ha.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

##Deforestation 2001-2022
data_treeloss = 
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/GFW/MDG/treecover_loss__ha.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

data_plot_mdg = data_treeloss %>%
  left_join(data_treecover_2000, by = "iso") %>%
  rename("year" = "umd_tree_cover_loss__year",
         "loss_ha" = "umd_tree_cover_loss__ha",
         "emissions_Mg" = "gfw_gross_emissions_co2e_all_gases__Mg",
         "area_ha" = "area__ha",
         "treecover_2000_ha" = "umd_tree_cover_extent_2000__ha" 
         ) %>%
  arrange(year) %>%
  mutate(cum_loss = cumsum(loss_ha),
         treecover_ha_mdg = treecover_2000_ha - cum_loss,
         treecover_rel00_mdg = treecover_ha_mdg/treecover_2000_ha*100)

fig_treeloss_mdg = ggplot(data = data_plot_mdg,
                      aes(x = year, y = treecover_rel00_mdg)) %>%
  + geom_line(color = "#3182BD") %>%
  + geom_point(color = "#3182BD") %>%
  + labs(x = "", y = "% of 2000 tree cover", 
         title = "Evolution of forest cover in Madagascar",
         subtitle = paste("Treecover in 2000 :", format(data_plot_mdg$treecover_2000_ha[1], digits = 1, big.mark = ",", scientific = F), "ha"),
         caption = "Data : Global Forest Watch") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_treeloss_mdg
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_treeloss_mdg.png", sep = "/"),
       plot =  fig_treeloss_mdg,
       device = "png",
       height = 6, width = 9)


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/GFW/MDG/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

FAPBM funded protected areas.

```{r, eval = FALSE}
#Filter the WDPA to non-marine PAs in MDG funded by the FAPBM
wdpa_fapbm = data_wdpa %>%
  filter(iso3 == "MDG" & marine %in% c(0,1) & st_geometry_type(geom) == "MULTIPOLYGON" & wdpaid %in% unique(data_pa_fapbm$wdpaid)) %>%
  st_make_valid() %>%
  st_cast(to = "POLYGON") %>%
  mutate()

#Download the data with the MAPME package 
data.tree.fapbm = init_portfolio(wdpa_fapbm,
                     years = 2000:2022,
                     add_resources = FALSE) %>%
  get_resources(resources = c("gfw_treecover", "gfw_lossyear")) %>%
  calc_indicators(indicators = "treecover_area",
                  min_size=1, # indicator-specific argument
                  min_cover=10) %>%
  unnest(treecover_area) %>%
  drop_na(treecover) %>% #get rid of units with NA values 
  mutate(across(c("treecover"), \(x) round(x, 3))) %>% # Round numeric columns
  pivot_wider(names_from = "years", values_from = "treecover", names_prefix = "treecover_") %>%
  st_drop_geometry() %>%
  group_by(wdpaid) %>%
  summarize(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%
  ungroup()

#Build a plotting dataset
data_plot_fapbm = data.tree.fapbm %>%
  st_drop_geometry() %>%
  group_by(wdpaid) %>%
  summarize(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%
  ungroup() %>%
  mutate(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%
  slice(1) %>%
  # mutate(across(.cols = starts_with("treecover"),
  #                .fns = ~.x/treecover_2000*100))  %>%
  pivot_longer(cols = c(starts_with("treecover")),
               names_to = c("var", "year"),
               names_sep = "_",
               values_to = "treecover_ha_fapbm") %>%
  mutate(treecover_rel00_fapbm = treecover_ha_fapbm/treecover_ha_fapbm[year == 2000]*100) %>%
  select(c(year, treecover_ha_fapbm, treecover_rel00_fapbm)) %>%
  mutate(year = as.numeric(year)) 
  

fig_treeloss_fapbm = ggplot(data = data_plot_fapbm,
                      aes(x = year, y = treecover_rel00_fapbm)) %>%
  + geom_line(color = "#3182BD") %>%
  + geom_point(color = "#3182BD") %>%
  + labs(x = "", y = "% of 2000 tree cover", 
         title = "Evolution of forest cover in FAPBM funded protected areas",
        subtitle = paste("Treecover in 2000 :", format(data_plot_fapbm[data_plot_fapbm$year == 2000,]$treecover_ha_fapbm, digits = 1, big.mark = ",", scientific = F), "ha"),
         caption = "Data : Global Forest Watch") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_treeloss_fapbm

# aws.s3::s3write_using(
# FUN = data.table::fwrite,
# data.tree.fapbm,
# # Mettre les options de FUN ici
# object = "data_tidy/GFW/MDG/FAPBM/data_treecover_2000_2022.csv",
# bucket = "projet-afd-eva-ap",
# opts = list("region" = ""))

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_treeloss_fapbm.png", sep = "/"),
       plot =  fig_treeloss_fapbm,
       device = "png",
       height = 6, width = 9)


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/GFW/MDG/FAPBM", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

Madagascar protected areas without FAPBM funded ones.

```{r, eval = FALSE}

wdpa_nofapbm = data_wdpa %>%
  filter(iso3 == "MDG" & marine %in% c(0,1) & st_geometry_type(geom) == "MULTIPOLYGON" & !(wdpaid %in% unique(data_pa_fapbm$wdpaid))) %>%
  st_make_valid() %>%
  st_cast(to = "POLYGON")

data.tree.nofapbm = init_portfolio(wdpa_nofapbm,
                     years = 2000:2022,
                     add_resources = FALSE) %>%
  get_resources(resources = c("gfw_treecover", "gfw_lossyear")) %>%
  calc_indicators(indicators = "treecover_area",
                  min_size=1, # indicator-specific argument
                  min_cover=10) %>%
  unnest(treecover_area) %>%
  drop_na(treecover) %>% #get rid of units with NA values 
  mutate(across(c("treecover"), \(x) round(x, 3))) %>% # Round numeric columns
  pivot_wider(names_from = "years", values_from = "treecover", names_prefix = "treecover_") %>%
  st_drop_geometry() %>%
  group_by(wdpaid) %>%
  summarize(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%   
  ungroup()

aws.s3::s3write_using(
FUN = data.table::fwrite,
data.tree.nofapbm,
# Mettre les options de FUN ici
object = "data_tidy/GFW/MDG/noFAPBM/data_treecover_2000_2022.csv",
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))

data_plot_nofapbm = data.tree.nofapbm %>%
  st_drop_geometry() %>%
  group_by(wdpaid) %>%
  summarize(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%
  ungroup() %>%
  mutate(across(.cols = starts_with("treecover"),
                   .fns = ~sum(.x, na.rm = TRUE))) %>%
  slice(1) %>%
  # mutate(across(.cols = starts_with("treecover"),
  #                .fns = ~.x/treecover_2000*100))  %>%
  pivot_longer(cols = c(starts_with("treecover")),
               names_to = c("var", "year"),
               names_sep = "_",
               values_to = "treecover_ha_nofapbm") %>%
  mutate(treecover_rel00_nofapbm = treecover_ha_nofapbm/treecover_ha_nofapbm[year == 2000]*100) %>%
  select(c(year, treecover_ha_nofapbm, treecover_rel00_nofapbm)) %>%
  mutate(year = as.numeric(year)) 
  

fig_treeloss_nofapbm = ggplot(data = data_plot_nofapbm,
                      aes(x = year, y = treecover_rel00_nofapbm)) %>%
  + geom_line(color = "#3182BD") %>%
  + geom_point(color = "#3182BD") %>%
  + labs(x = "", y = "% of 2000 tree cover", 
         title = "Evolution of forest cover, in protected areas not FAPBM funded",
        subtitle = paste("Treecover in 2000 :", format(data_plot_nofapbm[data_plot_nofapbm$year == 2000,]$treecover_ha_nofapbm, digits = 1, big.mark = ",", scientific = F), "ha"),
         caption = "Data : Global Forest Watch") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_treeloss_nofapbm
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_treeloss_nofapbm.png", sep = "/"),
       plot =  fig_treeloss_nofapbm,
       device = "png",
       height = 6, width = 9)


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/GFW/MDG/noFAPBM", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

Plotting the evolution of forest cover in Madagascar, FAPBM funded and not FAPMB funded protected areas in the same figure.

```{r, eval = FALSE}
data_plot_all = data_plot_fapbm %>%
  left_join(data_plot_nofapbm, by = "year") %>%
  left_join(select(data_plot_mdg, c(year, treecover_ha_mdg, treecover_rel00_mdg)), by = "year") %>%
  mutate(treecover_rel00_mdg = case_when(is.na(treecover_rel00_mdg) == TRUE ~ 100,
                   TRUE ~ treecover_rel00_mdg),
         treecover_ha_mdg = case_when(is.na(treecover_ha_mdg) == TRUE ~ data_plot_mdg$treecover_2000_ha[1],
                   TRUE ~ treecover_ha_mdg))
#CARFEUL NEED TO RENAME VARIABLES   

fig_treeloss_all =  ggplot(data_plot_all,
                           aes(x = year)) %>%
  + geom_line(aes(y = treecover_rel00_mdg, color = "Madagascar")) %>%
  + geom_point(aes(y = treecover_rel00_mdg, color = "Madagascar")) %>%
  + geom_line(aes(y = treecover_rel00_nofapbm, color = "Not FAPBM")) %>%
  + geom_point(aes(y = treecover_rel00_nofapbm, color = "Not FAPBM")) %>%
  + geom_line(aes(y = treecover_rel00_fapbm, color = "FAPBM")) %>%
  + geom_point(aes(y = treecover_rel00_fapbm, color = "FAPBM")) %>%
  + scale_color_manual(name = "", values = c("Madagascar" = "grey50",
                                  "Not FAPBM" = "#DE2D26",
                                  "FAPBM" = "#31A354")) %>%
  + labs(x = "", y = "% of 2000 tree cover", 
         title = "Evolution of forest cover",
        caption = paste("Data : Global Forest Watch\nTreecover in 2000 :", format(data_plot_all[data_plot_all$year == 2000,]$treecover_ha_mdg, digits = 1, big.mark = ",", scientific = F), "ha in Madagascar,", format(data_plot_all[data_plot_all$year == 2000,]$treecover_ha_fapbm, digits = 1, big.mark = ",", scientific = F), "ha of FAPBM funded protected areas and", format(data_plot_all[data_plot_all$year == 2000,]$treecover_ha_nofapbm, digits = 1, big.mark = ",", scientific = F), "ha of non-funded.")) %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white',  
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_treeloss_all
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_treeloss_all.png", sep = "/"),
       plot =  fig_treeloss_all,
       device = "png",
       height = 6, width = 9)


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/GFW/MDG", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

<!--chapter:end:01_stat_misc.Rmd-->

# (PART\*) Descriptive statistics {.unnumbered}

# Projects funded by the AFD

In this document are performed and plotted the following descriptive statistics on the protected areas (PAs) funded by Agence Française de Développement (AFD) :

-   Distribution of PAs among IUCN categories, at country, region and world level

-   Distribution in terms of ecosystems

-   Distribution of PAs across countries and regions, in terms of numbers or areas

-   Temporal evolution in the number and area of PAs funded by the AFD

-   Distribution in terms of governance types

In general, PAs refer to AFD funded PAs. When all PAs reported through the world are considered (typically for comparative statistics between general PAs and AFD funded PAs), it will be stated.

Some statistics are performed for all PAs across the world, while others are done for some regions and some specific PAs. Typically some statistics are performed for non-marine PAs, i.e terrestrial or coastal ones. These categories are defined by the WDPA and are indicative. A terrestrial PA has less than 10% of its area covered by sea or ocean, a marine one more than 90% and coastal PAs are in between.

The statistics are derived from datasets stored in the SSPCloud, and saved into the SSPCloud. Thus specific functions from the aws.S3 package are used (s3read_using() and s3write_using()). These can be replaced by other R functions to read/write locally (fread() typically). The ggplot2::ggsave() function cannot be used to write directly in the SSPCloud storage. Instead, plots from ggplot2 are stored in the temporary memory, then moved to the SSPCloud storage. Working locally, ggsave() can be directly used once the plots are created.

## Initial settings

Configuring the Rmarkdown

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

Importing the relevant packages

```{r message=FALSE, warning=FALSE, eval = FALSE}
install.packages(c("stargazer", "janitor", "questionr", "countrycode", "WDI"))
library(tidyverse)
library(stargazer)
library(dplyr)
library(sf)
library(ggplot2)
library(ggrepel)
library(RColorBrewer)
library(countrycode)
library(data.table)
#library(readxl)
#library(splitstackshape) 
library(janitor)
library(xtable)
library(questionr)
library(aws.s3)
library(WDI)
```

## Importing the datasets

A dataset with information for each PA funded by the AFD, a dataset of all PAs reported by the World Database on Protected Areas (WDPA), and datasets on aggregated size at country/region/world level and by year. The latter takes into account potential overlap between PAs reported in the WDPA.

```{r, eval = FALSE}
##Dataset with one line per PA
data_stat_nodupl = 
  #fread("data_tidy/BDD_PA_AFD_nofund_nodupl.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_nofund_nodupl.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

#Import WDPA data
## Downoad and save data directly using the WDPA R package
# data_wdpa = wdpa_fetch(x = "global", wait = TRUE, download_dir = "data_raw",
#                        page_wait = 2, verbose = TRUE)
# st_write(wdpa,
#          dsn = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
#          delete_dsn = TRUE)
##Loading from the storage
data_wdpa = 
  #st_read("data_raw/wdpa/wdpa_shp_global_raw.gpkg") %>%
  s3read_using(sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = "")) %>%
  st_drop_geometry() %>%
  clean_names() %>%
  #Add region, sub-region and country names 
  mutate(region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.region.name"),
         sub_region = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.regionsub.name"),
         country_en = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.en"),
         country_fr = countrycode(sourcevar = iso3,
                              origin = "iso3c",
                              destination = "un.name.fr"),
         .after = "iso3") 

##Datasets on aggregated size of PAs supported by the AFD per country/region/year and at world level, taking into account the potential spatial overlap.
###Country 
pa_area_ctry = 
  #fread("data_tidy/area/pa_area_ctry.csv", encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/area/pa_area_ctry.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))
### Region
pa_area_region =
  #fread("data_tidy/area/pa_area_region.csv", encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/area/pa_area_region.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))
### World
pa_area_wld = 
  #fread("data_tidy/area/pa_area_wld.csv", encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/area/pa_area_wld.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))
### By year
pa_int_yr = 
  #fread("data_tidy/area/pa_area_dr.csv", encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/area/pa_int_yr.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

#To perform statistics on the distribution of PAs reported by the WDPA across countries/regions, we focus on not high-income countries.
#Precisely, we restrict to countries defined as low-income, lower middle-income, upper-middle income, minus Russia, and including Chile, Uruguay New Caledonia and Panama. Indeed the latter are potential AFD partners while Russia is not, so this country list is more relevant for comparisons between AFD supported PAs and the others.
df_ctry_stat_wdpa = WDI(country = "all", start = "1960", end = "2022", extra = TRUE, language = "en") %>%
  group_by(iso3c) %>%
  slice(1) %>%
  ungroup() %>%
  select(c("iso3c", "income")) %>%
  rename("iso3" = "iso3c",
         "wb_inc_grp" = "income") %>%
  filter((wb_inc_grp %in% c("Low income",  "Lower middle income", "Upper middle income") & iso3 != "RUS") | iso3 %in% c("CHL", "URY", "PAN", "NCL"))

lst_ctry_stat_wdpa = df_ctry_stat_wdpa$iso3
```

## Performing descriptive statistics

The figures and tables are drawn and saved as follow. In a first code chunk, a dataset specific to the statistic needed is generated, then plots are built from ggplot package. Finally, a specific code chunk saves the figures and tables (thanks to xtable package) to a temporary folder and put it in the SSPCloud.

Importantly, a specific statistic performed at world and regional level for all and non-marine PAs use same naming for conciseness. See IUCN categories statistics for instance. It is then necessary to generate the relevant plots before running saving chunk, otherwise the lots won't be saved in the good folder.

### IUCN categories

The distribution of PAs across the different IUCN categories. This information is reported by the WDPA, thus PAs funded by the AFD but not reported in this database have no information on IUCN categories, and assigned to "not referenced" category. The information on IUCN category is not mandatory in the WDPA, and some PAs have no category reported ("not categorized").

#### Share of PAs by IUCN categories (world, all)

For all PAs in the world, marine and non-marine.

```{r, eval = FALSE}
#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_stat_nodupl %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_stat_nodupl %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Latex table
##French
tbl_cat_iucn_fr = data_cat_iucn %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
tbl_cat_iucn_ref_fr = data_cat_iucn_ref %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
##English
tbl_cat_iucn_en = data_cat_iucn %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")
tbl_cat_iucn_ref_en = data_cat_iucn_ref %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")


#Histogram including non-referenced PAs
##French
hist_cat_iucn_fr = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Proportion d'aires protégées par catégorie IUCN",
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Proportion (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_fr
##English
hist_cat_iucn_en = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Distribution of protected areas by IUCN categories",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_en

#Histogram excluding non-referenced PAs
#French
hist_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Proportion d'aires protégées par catégorie IUCN (hors AP non-répertoriées)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Nombre (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_fr
#English
hist_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Distribution of protected areas by IUCN categories (excluding not reported/categorized)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn), "protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_en


#Pie chart INcluding non-referenced PAs
##French
pie_cat_iucn_fr = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Proportion d'aires protégées par catégorie IUCN (%)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_fr
##English
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of protected areas by IUCN categories (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_en



#Pie chart EXcluding non-referenced PAs
##French
pie_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Proportion d'aires protégées par catégorie IUCN \nhors aires non répertoriées (%)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_fr
##English
pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of protected areas by IUCN categories \nexcluding not reported/categorized (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_cat_iucn_fr.png", sep = "/"),
       plot = hist_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_en.png", sep = "/"),
       plot = hist_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_fr.png", sep = "/"),
       plot = hist_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_en.png", sep = "/"),
       plot = hist_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_fr.png", sep = "/"),
       plot = pie_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_fr.png", sep = "/"),
       plot = pie_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

print(xtable(tbl_cat_iucn_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_en.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Share of PAs by IUCN categories (world, no marine)

For PAs across the world, non-marine only.

```{r, eval = FALSE}

#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_stat_nodupl %>%
  #Keep only terrestrial or coastal PA (when unknown, discarded)
  filter(marine %in% c(0,1)) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_stat_nodupl %>%
  #Keep only terrestrial or coastal PA (when unknown, discarded)
  filter(marine %in% c(0,1)) %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Latex table
##French
tbl_cat_iucn_fr = data_cat_iucn %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
tbl_cat_iucn_ref_fr = data_cat_iucn_ref %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
##English
tbl_cat_iucn_en = data_cat_iucn %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")
tbl_cat_iucn_ref_en = data_cat_iucn_ref %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")


#Histogram including non-referenced PAs
##French
hist_cat_iucn_fr = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Proportion d'aires protégées non-marines par catégorie IUCN",
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées non-marines. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Proportion (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_fr
##English
hist_cat_iucn_en = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Distribution of non-marine protected areas by IUCN categories",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_en

#Histogram excluding non-referenced PAs
#French
hist_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Proportion d'aires protégées non-marines par catégorie IUCN \n(hors AP non-répertoriées)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées non-marines. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Nombre (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_fr
#English
hist_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = "Distribution of non-marine protected areas by IUCN categories \n(excluding not reported/categorized)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn), "non-marine protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_en


#Pie chart INcluding non-referenced PAs
##French
pie_cat_iucn_fr = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Proportion d'aires protégées non-marines par catégorie IUCN (%)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées non-marines")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_fr
##English
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_en



#Pie chart EXcluding non-referenced PAs
##French
pie_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Proportion d'aires protégées non-marines par catégorie IUCN \nhors aires non répertoriées (%)",
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées non-marines")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_fr
##English
pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = "Distribution of non-marine protected areas by IUCN categories \nexcluding not reported/categorized (%)",
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "non-marine protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_en

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_cat_iucn_fr.png", sep = "/"),
       plot = hist_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_en.png", sep = "/"),
       plot = hist_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_fr.png", sep = "/"),
       plot = hist_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_en.png", sep = "/"),
       plot = hist_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_fr.png", sep = "/"),
       plot = pie_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_fr.png", sep = "/"),
       plot = pie_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

print(xtable(tbl_cat_iucn_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_en.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Share of PAs by IUCN categories (region, no marine)

Pas in a specific region, non-marine only.

```{r, eval = FALSE}

#Define the region of interest (see region variable in the main dataset).
roi = "Africa"

#Building the relevant dataset
##For all PAs ..
data_cat_iucn = data_stat_nodupl %>%
  #Keep only terrestrial or coastal PA (when unknown, discarded)
  filter(marine %in% c(0,1) & region == roi) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(desc(iucn_des_en)) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 


##... and for referenced PAs only
data_cat_iucn_ref = data_stat_nodupl %>%
  #Keep only terrestrial or coastal PA (when unknown, discarded)
  filter(marine %in% c(0,1) & region == roi) %>%
  #Remove not referenced PAs
  subset(!(iucn_des_fr %in% c("Non catégorisée", "Non référencée"))) %>%
  group_by(iucn_des_en, iucn_des_fr) %>%
  #number of PAs per IUCN category
  summarize(n_iucn = n()) %>%
  ungroup() %>%
  #Frequency of IUCN categories
  mutate(n_pa = sum(n_iucn),
         freq_iucn = round(n_iucn/n_pa*100, 2)) %>%
  arrange(freq_iucn) %>%
  mutate(ypos_iucn = cumsum(freq_iucn) - 0.5*freq_iucn) 

#Latex table
##French
tbl_cat_iucn_fr = data_cat_iucn %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
tbl_cat_iucn_ref_fr = data_cat_iucn_ref %>%
  select(c(iucn_des_fr, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_fr) <- c("Catégories IUCN","Nombre d'AP", "Proportion d'AP (%)")
##English
tbl_cat_iucn_en = data_cat_iucn %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")
tbl_cat_iucn_ref_en = data_cat_iucn_ref %>%
  select(c(iucn_des_en, n_iucn, freq_iucn))
names(tbl_cat_iucn_ref_en) <- c("IUCN categories","Number of PAs", "Share of PAs (%)")


#Histogram including non-referenced PAs
##French
hist_cat_iucn_fr = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = paste("Proportion d'aires protégées non-marines par catégorie IUCN,", roi),
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées non-marines. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Proportion (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_fr
##English
hist_cat_iucn_en = ggplot(data_cat_iucn, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = paste("Distribution of non-marine protected areas by IUCN categories,", roi),
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_en

#Histogram excluding non-referenced PAs
#French
hist_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_fr, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_fr)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = paste("Proportion d'aires protégées non-marines par catégorie IUCN,", roi, "\n(hors AP non-répertoriées)"),
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées non-marines. Nombre d'aires indiqué sur les barres."),
          x = "Catégories IUCN", 
          y = "Nombre (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_fr
#English
hist_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                       aes(x = reorder(iucn_des_en, -freq_iucn), 
                           y = freq_iucn, fill = iucn_des_en)) %>% 
  + geom_bar(stat = "identity", width = 0.50, fill="#3182BD") %>%
  + geom_text(aes(label = round(n_iucn, 1), y = freq_iucn), 
            vjust = -0.1, color="black",
            size=3.5) %>%
  + labs(title = paste("Distribution of non-marine protected areas by IUCN categories,", roi, "\n(excluding not reported/categorized)"),
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn), "non-marine protected areas. Number of areas indicated above the bars."),
          x = "IUCN categories", 
          y = "Share (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=9, hjust = .5, vjust = .6),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_cat_iucn_ref_en


#Pie chart INcluding non-referenced PAs
##French
pie_cat_iucn_fr = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = paste("Proportion d'aires protégées non-marines par catégorie IUCN (%),", roi),
         subtitle = paste("Echantillon :", sum(data_cat_iucn$n_iucn), "aires protégées non-marines")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_fr
##English
pie_cat_iucn_en = ggplot(data_cat_iucn, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = paste("Distribution of non-marine protected areas by IUCN categories (%),", roi),
         subtitle = paste("Sample :", sum(data_cat_iucn$n_iucn), "non-marine protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_en



#Pie chart EXcluding non-referenced PAs
##French
pie_cat_iucn_ref_fr = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_fr)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = paste("Proportion d'aires protégées non-marines par catégorie IUCN,",  roi, "\nhors aires non répertoriées (%)"),
         subtitle = paste("Echantillon :", sum(data_cat_iucn_ref$n_iucn), "sur", sum(data_cat_iucn$n_iucn), "aires protégées non-marines")) %>%
  + scale_fill_brewer(name = "Catégories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_fr
##English
pie_cat_iucn_ref_en = ggplot(data_cat_iucn_ref, 
                      aes(x="", y= freq_iucn, fill = iucn_des_en)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + coord_polar("y", start=0) %>%
  + geom_label_repel(aes(x=1.2, label = paste0(round(freq_iucn, 1), "%")), 
             color = "white", 
             position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
  # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
  #              color = "white", 
  #              position = position_stack(vjust = 0.7), size=2.5, 
  #              show.legend = FALSE) %>%
  + labs(x = "", y = "",
         title = paste("Distribution of non-marine protected areas by IUCN categories,", roi, "\nexcluding not reported/categorized (%)"),
         subtitle = paste("Sample :", sum(data_cat_iucn_ref$n_iucn), "out of", sum(data_cat_iucn$n_iucn),  "non-marine protected areas")) %>%
  + scale_fill_brewer(name = "Categories", palette = "Dark2") %>%
  + theme_void()
pie_cat_iucn_ref_en

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_cat_iucn_fr.png", sep = "/"),
       plot = hist_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_en.png", sep = "/"),
       plot = hist_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_fr.png", sep = "/"),
       plot = hist_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "hist_cat_iucn_ref_en.png", sep = "/"),
       plot = hist_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_fr.png", sep = "/"),
       plot = pie_cat_iucn_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_en.png", sep = "/"),
       plot = pie_cat_iucn_en,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_fr.png", sep = "/"),
       plot = pie_cat_iucn_ref_fr,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "pie_cat_iucn_ref_en.png", sep = "/"),
       plot = pie_cat_iucn_ref_en,
       device = "png",
       height = 6, width = 9)

print(xtable(tbl_cat_iucn_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_en.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_fr, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_fr.tex", sep = "/"))

print(xtable(tbl_cat_iucn_ref_en, type = "latex"),
      file = paste(tmp, "tbl_cat_iucn_ref_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/IUCN", roi, "no_marine", sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### IUCN categories by countries and regions (world, all)

For each country/region, the percentage of PAs in the different IUCN categories.

```{r, eval = FALSE}

#Build the distribution of IUCN categories at country level ...
data_iucn_ctry_en = table(data_stat_nodupl$iucn_des_en,
                       data_stat_nodupl$iso3) %>%
  #Create a table with all iucn categories for each country, and compute the frequencies in percent
  prop.table(2) %>%
  as.data.frame() %>%
  mutate(Freq = round(Freq, 3)*100) %>%
  pivot_wider(names_from = Var2, values_from = Freq) %>%
  rename("iucn_des_en" = "Var1")

#... and regional level
data_iucn_reg_en = table(data_stat_nodupl$iucn_des_en,
                       data_stat_nodupl$region_afd) %>%
    #Create a table with all iucn categories for each country, and compute the frequencies in percent
  prop.table(2) %>%
  as.data.frame() %>%
  mutate(Freq = round(Freq, 3)*100) %>%
  pivot_wider(names_from = Var2, values_from = Freq) %>%
  rename("iucn_des_en" = "Var1")

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(data_iucn_ctry_en, type = "latex"),
      file = paste(tmp, "tbl_iucn_ctry_en.tex", sep = "/"))
print(xtable(data_iucn_reg_en, type = "latex"),
      file = paste(tmp, "tbl_iucn_reg_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
  {
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/IUCN/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

### Ecosystems (excluding non-referenced PAs)

The percentage of PAs in the ecosystem categories of WDPA : terrestrial, coastal and marine. A terrestrial PA has less than 10% of its area covered by sea or ocean, a marine one more than 90% and coastal PAs are in between. This definition is taken from the WDPA.

#### Proportion of PAs by marine or terrestrial areas (world)

All PAs in the world.

```{r, eval = FALSE}

#Build datasets
data_eco = data_stat_nodupl %>%
  #subset non-referencded PAs (have NA ecosysteme)
  subset(is.na(marine) == FALSE) %>%
  mutate(marine = as.factor(marine))
data_eco$ecosyst_en = fct_recode(data_eco$marine, 
                              "Terrestrial"="0", 
                              "Coastal"="1", 
                              "Marine"="2")
data_eco$ecosyst_fr = fct_recode(data_eco$marine, 
                              "Terrestre"="0", 
                              "Côtier"="1", 
                              "Marin"="2")

data_eco_hist = data_eco %>%
  group_by(ecosyst_en, ecosyst_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_eco), 2)*100) %>%
  ungroup()

#Define tables
tbl_eco_fr = data_eco_hist %>%
  select(c(ecosyst_fr, n, freq)) %>%
  rename("Ecosystème" = "ecosyst_fr",
         "Nombre d'AP" = "n",
         "Proportion d'AP(%)" = "freq")

tbl_eco_en = data_eco_hist %>%
  select(c(ecosyst_en, n, freq)) %>%
  rename("Ecosystem" = "ecosyst_en",
         "Number of PAs" = "n",
         "Share of PAs(%)" = "freq")


#Histogram in share (in French)
hist_eco_shr_fr = ggplot(data_eco_hist, 
                     aes(x = ecosyst_fr, y = freq, fill = ecosyst_fr)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ geom_text(aes(label = round(n, 1), y = freq), 
        vjust = -0.1, color="black",
        size=3.5) %>%
+ labs(title = "Proportion d'aires protégées par type d'écosystème \n(hors AP non-référencées)",
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(data_stat_nodupl), "aires protégées. Nombre d'aires indiqué sur les barres."),
         x = "Type d'écosystème",
         y = "Proportion d'aires protégées(%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_shr_fr
# 



#Histogram in share (in English)
hist_eco_shr_en = ggplot(data_eco_hist, 
                     aes(x = ecosyst_en, y = freq, fill = ecosyst_en)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ geom_text(aes(label = round(n, 1), y = freq), 
        vjust = -0.1, color="black",
        size=3.5) %>%
+ labs(title = "Proportion of protected areas by ecosystem type \n(excluding not referenced PAs)",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(data_stat_nodupl), "protected areas. Number of areas indicated above."),
         x = "Ecosystem type",
         y = "Proportion of protected areas(%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
#hist_eco_shr_en


  
#Histogram in number (in French)
hist_eco_n_fr = ggplot(data_eco_hist, 
                     aes(x = ecosyst_fr, y = n, fill = ecosyst_fr)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Proportion d'aires protégées par type d'écosystème \n(hors AP non-référencées)",
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(data_stat_nodupl), "aires protégées"),
         x = "Type d'écosystème",
         y = "# d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_n_fr


#Histogram in number (in English)
hist_eco_n_en = ggplot(data_eco_hist, 
                     aes(x = ecosyst_en, y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Proportion of protected areas by ecosystem type \n(excluding not referenced PAs)",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(data_stat_nodupl), "protected areas"),
         x = "Ecosystem type",
         y = "# of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
#hist_eco_n_en

#Pie chart (in French)
pie_eco_fr = ggplot(data_eco_hist, 
                     aes(x = "", y = freq, fill = ecosyst_fr)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = "Proportion d'aires protégées par type d'écosystème \n(hors AP non-référencées)",
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(data_stat_nodupl), "aires protégées"),
         x = "Type d'écosystème",
         y = "Proportion d'aires protégées") %>%
  + scale_fill_brewer(name = "Ecosystème", palette="Paired") %>%
  + theme_void()
pie_eco_fr


#Histogram in number (in English)
pie_eco_en = ggplot(data_eco_hist, 
                     aes(x = "", y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = "Proportion of protected areas by ecosystem type \n(excluding not referenced PAs)",
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(data_stat_nodupl), "protected areas"),
         x = "Ecosystem type",
         y = "Proportion of protected areas") %>%
  + scale_fill_brewer(name = "Ecosystem", palette="Paired") %>%
  + theme_void()
pie_eco_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")


ggsave(paste(tmp, "hist_eco_shr_fr.png", sep = "/"),
       plot = hist_eco_shr_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_eco_shr_en.png", sep = "/"),
       plot = hist_eco_shr_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_eco_n_fr.png", sep = "/"),
       plot = hist_eco_n_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_eco_n_en.png", sep = "/"),
       plot = hist_eco_n_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "pie_eco_fr.png", sep = "/"),
       plot = pie_eco_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "pie_eco_en.png", sep = "/"),
       plot = pie_eco_en,
       device = "png",
       height = 6, width = 9)

print(xtable(tbl_eco_fr, type = "latex"), 
      file = paste(tmp, "tbl_ecosyst_fr.tex", sep = "/"))
print(xtable(tbl_eco_en, type = "latex"), 
      file = paste(tmp, "tbl_ecosyst_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/ecosysteme/world", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Proportion of PAs by marine or terrestrial areas (region)

PAs in a given region to specify.

```{r, eval = FALSE}

#Define the region of interest where the stats are performed
roi = "Africa"

#Build datasets
data_eco = data_stat_nodupl %>%
  #subset non-referencded PAs (have NA ecosysteme)
  subset(is.na(marine) == FALSE & region == roi) %>%
  mutate(marine = as.factor(marine))
data_eco$ecosyst_en = fct_recode(data_eco$marine, 
                              "Terrestrial"="0", 
                              "Coastal"="1", 
                              "Marine"="2")
data_eco$ecosyst_fr = fct_recode(data_eco$marine, 
                              "Terrestre"="0", 
                              "Côtier"="1", 
                              "Marin"="2")

data_eco_hist = data_eco %>%
  group_by(ecosyst_en, ecosyst_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_eco), 2)*100) %>%
  ungroup()

tbl_eco_fr = data_eco_hist %>%
  select(c(ecosyst_fr, n, freq)) %>%
  rename("Ecosystème" = "ecosyst_fr",
         "Nombre d'AP" = "n",
         "Proportion d'AP(%)" = "freq")

tbl_eco_en = data_eco_hist %>%
  select(c(ecosyst_en, n, freq)) %>%
  rename("Ecosystem" = "ecosyst_en",
         "Number of PAs" = "n",
         "Share of PAs(%)" = "freq")


#Histogram in share (in French)
hist_eco_shr_fr = ggplot(data_eco_hist, 
                     aes(x = ecosyst_fr, y = freq, fill = ecosyst_fr)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ geom_text(aes(label = round(n, 1), y = freq), 
        vjust = -0.1, color="black",
        size=3.5) %>%
+ labs(title = paste("Proportion d'aires protégées par type d'écosystème,", roi, "\n(hors AP non-référencées)"),
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(subset(data_stat_nodupl, region == roi)), "aires protégées. Nombre d'aires indiqué sur les barres."),
         x = "Type d'écosystème",
         y = "Proportion d'aires protégées(%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_shr_fr
# 



#Histogram in share (in English)
hist_eco_shr_en = ggplot(data_eco_hist, 
                     aes(x = ecosyst_en, y = freq, fill = ecosyst_en)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ geom_text(aes(label = round(n, 1), y = freq), 
        vjust = -0.1, color="black",
        size=3.5) %>%
+ labs(title = paste("Proportion of protected areas by ecosystem type,", roi,  "\n(excluding not referenced PAs)"),
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(subset(data_stat_nodupl, region == roi)), "protected areas. Number of areas indicated above."),
         x = "Ecosystem type",
         y = "Proportion of protected areas(%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_shr_en


  
#Histogram in number (in French)
hist_eco_n_fr = ggplot(data_eco_hist, 
                     aes(x = ecosyst_fr, y = n, fill = ecosyst_fr)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = paste("Proportion d'aires protégées par type d'écosystème,", roi, "\n(hors AP non-référencées)"),
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(subset(data_stat_nodupl, region == roi)), "aires protégées"),
         x = "Type d'écosystème",
         y = "# d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_n_fr


#Histogram in number (in English)
hist_eco_n_en = ggplot(data_eco_hist, 
                     aes(x = ecosyst_en, y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = paste("Proportion of protected areas by ecosystem type,", roi, "\n(excluding not referenced PAs)"),
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(subset(data_stat_nodupl, region == roi)), "protected areas"),
         x = "Ecosystem type",
         y = "# of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_eco_n_en

#Pie chart (in French)
pie_eco_fr = ggplot(data_eco_hist, 
                     aes(x = "", y = freq, fill = ecosyst_fr)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = paste("Proportion d'aires protégées par type d'écosystème,", roi, "\n(hors AP non-référencées)"),
       subtitle = paste("Echantillon :", sum(data_eco_hist$n), "sur", nrow(subset(data_stat_nodupl, region == roi)), "aires protégées"),
         x = "Type d'écosystème",
         y = "Proportion d'aires protégées") %>%
  + scale_fill_brewer(name = "Ecosystème", palette="Paired") %>%
  + theme_void()
pie_eco_fr


#Histogram in number (in English)
pie_eco_en = ggplot(data_eco_hist, 
                     aes(x = "", y = n, fill = ecosyst_en)) %>%
+ geom_bar(width = 1, stat = "identity",color="white") %>%
+ geom_label(aes(x=1.3, label = paste0(freq, "%")), 
             color = "black", position = position_stack(vjust = 0.55), 
             size=2.5, show.legend = FALSE) %>%
+ coord_polar("y", start=0) %>%
+ labs(title = paste("Proportion of protected areas by ecosystem type,", roi, "\n(excluding not referenced PAs)"),
       subtitle = paste("Sample :", sum(data_eco_hist$n), "out of", nrow(subset(data_stat_nodupl, region == roi)), "protected areas"),
         x = "Ecosystem type",
         y = "Proportion of protected areas") %>%
  + scale_fill_brewer(name = "Ecosystem", palette="Paired") %>%
  + theme_void()
pie_eco_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")


ggsave(paste(tmp, paste0("hist_eco_shr_", roi, "_fr.png"), sep = "/"),
       plot = hist_eco_shr_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, paste0("hist_eco_shr_", roi, "_en.png"), sep = "/"),
       plot = hist_eco_shr_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, paste0("hist_eco_n_", roi, "_fr.png"), sep = "/"),
       plot = hist_eco_n_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, paste0("hist_eco_n_", roi, "_en.png"), sep = "/"),
       plot = hist_eco_n_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, paste0("pie_eco_", roi, "_fr.png"), sep = "/"),
       plot = pie_eco_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, paste0("pie_eco_", roi, "_en.png"), sep = "/"),
       plot = pie_eco_en,
       device = "png",
       height = 6, width = 9)

print(xtable(tbl_eco_fr, type = "latex"), 
      file = paste(tmp, paste0("tbl_ecosyst_", roi, "_fr.tex"), sep = "/"))
print(xtable(tbl_eco_en, type = "latex"), 
      file = paste(tmp, paste0("tbl_ecosyst_", roi, "_en.tex"), sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/ecosysteme", roi, sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

### Distribution (\# and surface) of PAs across countries and regions

Number/share of PAs in the different countries/regions.

#### Statistics at country level (all)

For all PAs in the world.

```{r message=FALSE, warning=FALSE, eval = FALSE}

#Surface and number of PAs by country
data_distrib_ctry = data_stat_nodupl %>%
  group_by(iso3, country_en, country_fr) %>%
  summarize(n = n(),
            area_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot = sum(n, na.rm = TRUE),
         area_tot_km2 = sum(area_km2, na.rm = TRUE),
         freq_n = round(n/n_tot*100, 2),
         freq_area = round(area_km2/area_tot_km2*100, 2)) %>%
  pivot_longer(cols = c("n", "freq_n", "area_km2", "freq_area"),
               names_to = "metric")

#Top targeted countries in terms of number/surface of PAs
data_distrib_ctry_top_n = data_distrib_ctry %>%
  filter(metric == "freq_n") %>%
  arrange(-value) %>%
  slice(1:5)
data_distrib_ctry_top_area = data_distrib_ctry %>%
  filter(metric == "freq_area") %>%
  arrange(-value) %>%
  slice(1:5)

#Histogram in share (in French) for top countries
##Number of PAs
hist_distrib_ctry_top_n_shr = ggplot(data_distrib_ctry_top_n, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Countries most targeted by AFD funded protected areas (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_n_shr

##Area of PAs
hist_distrib_ctry_top_area_shr = ggplot(data_distrib_ctry_top_area, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Countries most targeted by AFD funded protected areas (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_area_shr

#Histogram for all countries
#Histogram in number
hist_distrib_ctry_n_shr = ggplot(filter(data_distrib_ctry, metric == "freq_n"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of protected areas by country (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_n_shr

# Histogram in surfaces
hist_distrib_ctry_area_shr = ggplot(filter(data_distrib_ctry, metric == "freq_area"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of protected areas by country (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_area_shr

## Both
hist_distrib_ctry_top_both_shr = ggplot(filter(data_distrib_ctry, metric %in% c("freq_n", "freq_area")), 
                     aes(x = reorder(iso3, -value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Distribution of AFD funded protected areas by country",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("Area", "Number"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_both_shr
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_ctry_top_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_top_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_top_both_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_both_shr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

#### Statistics at country level (non-marine)

Non-marine PAs across the world.

```{r message=FALSE, warning=FALSE, eval = FALSE}

#Surface and number of PAs by country
data_distrib_ctry = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  group_by(iso3, country_en, country_fr) %>%
  summarize(n = n(),
            area_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot = sum(n, na.rm = TRUE),
         area_tot_km2 = sum(area_km2, na.rm = TRUE),
         freq_n = round(n/n_tot*100, 2),
         freq_area = round(area_km2/area_tot_km2*100, 2)) %>%
  pivot_longer(cols = c("n", "freq_n", "area_km2", "freq_area"),
               names_to = "metric")

#Top targeted countries in terms of number/surface of PAs
data_distrib_ctry_top_n = data_distrib_ctry %>%
  filter(metric == "freq_n") %>%
  arrange(-value) %>%
  slice(1:5)
data_distrib_ctry_top_area = data_distrib_ctry %>%
  filter(metric == "freq_area") %>%
  arrange(-value) %>%
  slice(1:5)

#Histogram in share (in French) for top countries
##Number of PAs
hist_distrib_ctry_top_n_shr = ggplot(data_distrib_ctry_top_n, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Countries most targeted by AFD funded, non-marine protected areas (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_n_shr

##Area of PAs
hist_distrib_ctry_top_area_shr = ggplot(data_distrib_ctry_top_area, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Countries most targeted by AFD funded, non-marine protected areas (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_area_shr

#Histogram for all countries
#Histogram in number
hist_distrib_ctry_n_shr = ggplot(filter(data_distrib_ctry, metric == "freq_n"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by country (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_n_shr
# Histogram in surfaces
hist_distrib_ctry_area_shr = ggplot(filter(data_distrib_ctry, metric == "freq_area"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by country (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "Countries",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_area_shr

## Both
hist_distrib_ctry_top_both_shr = ggplot(filter(data_distrib_ctry, metric %in% c("freq_area", "freq_n")), 
                     aes(x = reorder(iso3, -value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by country",
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("Area", "Number"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_both_shr
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_ctry_top_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_top_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_top_both_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_both_shr,
       device = "png",
       height = 6, width = 9)


#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Statistics at country level (region, non-marine)

Non-marine PAs in a given region.

```{r message=FALSE, warning=FALSE, eval = FALSE}

roi = "Africa"

#Surface and number of PAs by country
data_distrib_ctry = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  group_by(iso3, country_en, country_fr) %>%
  summarize(n = n(),
            area_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot = sum(n, na.rm = TRUE),
         area_tot_km2 = sum(area_km2, na.rm = TRUE),
         freq_n = round(n/n_tot*100, 2),
         freq_area = round(area_km2/area_tot_km2*100, 2)) %>%
  pivot_longer(cols = c("n", "freq_n", "area_km2", "freq_area"),
               names_to = "metric")

#Top targeted countries in terms of number/surface of PAs
data_distrib_ctry_top_n = data_distrib_ctry %>%
  filter(metric == "freq_n") %>%
  arrange(-value) %>%
  slice(1:5)
data_distrib_ctry_top_area = data_distrib_ctry %>%
  filter(metric == "freq_area") %>%
  arrange(-value) %>%
  slice(1:5)

#Histogram in share (in French) for top countries
##Number of PAs
hist_distrib_ctry_top_n_shr = ggplot(data_distrib_ctry_top_n, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = paste0("Countries most targeted by AFD funded, non-marine protected areas (#) \n", roi),
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_n_shr

##Area of PAs
hist_distrib_ctry_top_area_shr = ggplot(data_distrib_ctry_top_area, 
                     aes(x = reorder(country_en, -value), y = value, fill = value)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = paste0("Countries most targeted by AFD funded, non-marine protected areas (area)\n", roi),
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_top_area_shr

#Histogram for all countries
#Histogram in number
hist_distrib_ctry_n_shr = ggplot(filter(data_distrib_ctry, metric == "freq_n"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = paste0("Distribution of AFD funded, non-marine protected areas by country (#)\n", roi),
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_n_shr
# Histogram in surfaces
hist_distrib_ctry_area_shr = ggplot(filter(data_distrib_ctry, metric == "freq_area"), 
                     aes(x = reorder(iso3, -value), y = value, fill = iso3)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = paste0("Distribution of AFD funded, non-marine protected areas by country (area)\n", roi),
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of area funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_area_shr

## Both
hist_distrib_ctry_both_shr = ggplot(filter(data_distrib_ctry, metric %in% c("freq_area", "freq_n")), 
                     aes(x = reorder(iso3, -value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = paste0("Distribution of AFD funded, non-marine protected areas by country\n", roi),
       subtitle = paste("Sample :", sum(filter(data_distrib_ctry, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_ctry, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("Area", "Number"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_ctry_both_shr
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_ctry_top_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_top_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_n_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_area_shr.png", sep = "/"),
       plot = hist_distrib_ctry_top_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_both_shr.png", sep = "/"),
       plot = hist_distrib_ctry_both_shr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/distribution", roi, "no_marine", sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

#### Statistics at country level (non-marine, WDPA vs AFD)

```{r, eval = FALSE}
#For AFD funded PAs
##Distribution across countries (all)
data_distrib_ctry_afd = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  group_by(iso3, country_en) %>%
  summarize(n_afd = n(),
            area_km2_afd = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot_afd = sum(n_afd),
         area_km2_afd_tot = sum(area_km2_afd, na.rm = TRUE),
         freq_n_afd = round(n_afd/n_tot_afd*100, 2),
         freq_area_afd = round(area_km2_afd/area_km2_afd_tot*100, 2))
##Top 10 funded countries
###Number
data_distrib_ctry_afd_top_n = data_distrib_ctry_afd %>%
  arrange(-freq_n_afd) %>%
  slice(1:10)
###Surface
data_distrib_ctry_afd_top_area = data_distrib_ctry_afd %>%
  arrange(-freq_area_afd) %>%
  slice(1:10)

#For WDPA PAs
## All countries in the list of interest
data_distrib_ctry_wdpa = data_wdpa %>%
  #Non-marine areas only
  filter(marine %in% c(0,1)) %>%
  #Countries of interest only
  filter(iso3 %in% lst_ctry_stat_wdpa) %>%
  group_by(iso3, country_en) %>%
  summarize(n_wdpa = n(),
            area_km2_wdpa = sum(rep_area, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot_wdpa = sum(n_wdpa),
         area_km2_wdpa_tot = sum(area_km2_wdpa, na.rm = TRUE),
         freq_n_wdpa = round(n_wdpa/n_tot_wdpa*100, 2),
         freq_area_wdpa = round(area_km2_wdpa/area_km2_wdpa_tot*100, 2))
## Top 10 targeted countries
data_distrib_ctry_wdpa_top_n = data_distrib_ctry_wdpa %>%
  arrange(-freq_n_wdpa) %>%
  slice(1:10)
data_distrib_ctry_wdpa_top_area = data_distrib_ctry_wdpa %>%
  arrange(-freq_area_wdpa) %>%
  slice(1:10)

#Then create a plotting dataset with WDPA vs AFD distribution
##the distribution for top targeted countries by AFD
### in terms of numbers
data_distrib_ctry_vs_n = data_distrib_ctry_afd_top_n %>%
  left_join(data_distrib_ctry_wdpa, c("iso3", "country_en")) %>%
  select(-contains("area")) %>%
  pivot_longer(cols = c("n_afd", "freq_n_afd", "n_wdpa", "freq_n_wdpa"),
               names_to = "metric") 
###in terms of areas
data_distrib_ctry_vs_area = data_distrib_ctry_afd_top_area %>%
  left_join(data_distrib_ctry_wdpa, c("iso3", "country_en")) %>%
  select(-contains("n_")) %>%
  pivot_longer(cols = c("area_km2_afd", "freq_area_afd", "area_km2_wdpa", "freq_area_wdpa"),
               names_to = "metric") 

#Histogram in share for top countries
##For WDPA PAs
### number
hist_distrib_ctry_wdpa_top_n = ggplot(data_distrib_ctry_wdpa_top_n,
                                  aes(x = reorder(iso3, -freq_n_wdpa), y = freq_n_wdpa, fill = freq_n_wdpa)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Top countries of non-marine protected areas (#)",
       subtitle = paste("Sample :", min(data_distrib_ctry_wdpa$n_tot_wdpa), "non-marine protected areas reported by the WDPA, covering", format(min(data_distrib_ctry_wdpa$area_km2_wdpa_tot), scientific = TRUE, digits = 2), "km²"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\nThese are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_wdpa_top_n 
### Area
hist_distrib_ctry_wdpa_top_area = ggplot(data_distrib_ctry_wdpa_top_area,
                                  aes(x = reorder(iso3, -freq_area_wdpa), y = freq_area_wdpa, fill = freq_area_wdpa)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Top countries of non-marine protected areas (area)",
       subtitle = paste("Sample :", min(data_distrib_ctry_wdpa$n_tot_wdpa), "non-marine protected areas reported by the WDPA, covering", format(min(data_distrib_ctry_wdpa$area_km2_wdpa_tot), scientific = TRUE, digits = 2), "km²"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\nThese are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_wdpa_top_area

##For AFD funded PAs
### number
hist_distrib_ctry_afd_top_n = ggplot(data_distrib_ctry_afd_top_n,
                                  aes(x = reorder(iso3, -freq_n_afd), y = freq_n_afd, fill = freq_n_afd)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Top countries of AFD funded, non-marine protected areas (#)",
       subtitle = paste("Sample :", min(data_distrib_ctry_afd$n_tot_afd), "non-marine protected areas reported by the WDPA, covering", format(min(data_distrib_ctry_afd$area_km2_afd_tot), scientific = TRUE, digits = 2), "km²"),
      caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\nThese are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_afd_top_n 
### Area
hist_distrib_ctry_afd_top_area = ggplot(data_distrib_ctry_afd_top_area,
                                  aes(x = reorder(iso3, -freq_area_afd), y = freq_area_afd, fill = freq_area_afd)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
+ labs(title = "Top countries of AFD funded, non-marine protected areas (area)",
       subtitle = paste("Sample :", min(data_distrib_ctry_afd$n_tot_afd), "non-marine protected areas reported by the WDPA, covering", format(min(data_distrib_ctry_afd$area_km2_afd_tot), scientific = TRUE, digits = 2), "km²"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\nThese are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_afd_top_area


## For top AFD, comparison with WDPA in terms of numbers
hist_distrib_ctry_vs_n = ggplot(filter(data_distrib_ctry_vs_n, grepl("freq", metric)),
                                  aes(x = reorder(iso3, value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity", na.rm = TRUE) %>%
+ labs(title = "Top countries targeted by AFD funded non-marine protected areas (#)",
       subtitle = paste("Sample :", min(data_distrib_ctry_wdpa$n_tot_wdpa), "non-marine protected areas reported by the WDPA,",  min(data_distrib_ctry_afd$n_tot_afd), "funded by AFD"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\n*These are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_vs_n 

## For top AFD, comparison with WDPA in terms of area
hist_distrib_ctry_vs_area = ggplot(filter(data_distrib_ctry_vs_area, grepl("freq", metric)),
                                  aes(x = reorder(iso3, value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity", na.rm = TRUE) %>%
+ labs(title = "Top countries targeted by AFD funded non-marine protected areas (area)",
       subtitle = paste("Sample :", min(data_distrib_ctry_wdpa$n_tot_wdpa), "non-marine protected areas reported by the the WDPA,",  min(data_distrib_ctry_afd$n_tot_afd), "funded by AFD"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\n*These are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of funded areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_ctry_vs_area


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_ctry_wdpa_top_n.png", sep = "/"),
       plot = hist_distrib_ctry_wdpa_top_n,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_wdpa_top_area.png", sep = "/"),
       plot = hist_distrib_ctry_wdpa_top_area,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_afd_top_n.png", sep = "/"),
       plot = hist_distrib_ctry_afd_top_n,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_afd_top_area.png", sep = "/"),
       plot = hist_distrib_ctry_afd_top_area,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_vs_n.png", sep = "/"),
       plot = hist_distrib_ctry_vs_n,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_ctry_vs_area.png", sep = "/"),
       plot = hist_distrib_ctry_vs_area,
       device = "png",
       height = 6, width = 9)
#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/wdpa_vs_afd/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Statistics at region level (all)

All PAs across the world.

```{r, eval = FALSE}
#Surface and number of PAs by country
data_distrib_reg = data_stat_nodupl %>%
  group_by(region) %>%
  summarize(n = n(),
            area_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot = sum(n, na.rm = TRUE),
         area_tot_km2 = sum(area_km2, na.rm = TRUE),
         freq_n = round(n/n_tot*100, 2),
         freq_area = round(area_km2/area_tot_km2*100, 2)) %>%
  pivot_longer(cols = c("n", "freq_n", "area_km2", "freq_area"),
               names_to = "metric") %>%
  filter(is.na(region) == FALSE)


#Histogram for all countries
#Histogram in number
hist_distrib_reg_n_shr = ggplot(filter(data_distrib_reg, metric == "freq_n"), 
                     aes(x = reorder(region, -value), y = value, fill = region)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of protected areas by region (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_n_shr

# Histogram in surfaces
hist_distrib_reg_area_shr = ggplot(filter(data_distrib_reg, metric == "freq_area"), 
                     aes(x = reorder(region, -value), y = value, fill = region)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of protected areas by region (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of areas funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_area_shr

## Both
hist_distrib_reg_top_both_shr = ggplot(filter(data_distrib_reg, metric %in% c("freq_area", "freq_n")), 
                     aes(x = reorder(region, -value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Distribution of AFD funded protected areas by region",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("Area", "Number"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_top_both_shr
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_reg_n_shr.png", sep = "/"),
       plot = hist_distrib_reg_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_reg_area_shr.png", sep = "/"),
       plot = hist_distrib_reg_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_reg_top_both_shr.png", sep = "/"),
       plot = hist_distrib_reg_top_both_shr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Statistics at region level (non-marine)

```{r, eval = FALSE}

#Surface and number of PAs by country
data_distrib_reg = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  group_by(region) %>%
  summarize(n = n(),
            area_km2 = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot = sum(n, na.rm = TRUE),
         area_tot_km2 = sum(area_km2, na.rm = TRUE),
         freq_n = round(n/n_tot*100, 2),
         freq_area = round(area_km2/area_tot_km2*100, 2)) %>%
  pivot_longer(cols = c("n", "freq_n", "area_km2", "freq_area"),
               names_to = "metric") %>%
  filter(is.na(region) == FALSE)


#Histogram for all countries
#Histogram in number
hist_distrib_reg_n_shr = ggplot(filter(data_distrib_reg, metric == "freq_n"), 
                     aes(x = reorder(region, -value), y = value, fill = region)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by region (#)",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_n_shr

# Histogram in surfaces
hist_distrib_reg_area_shr = ggplot(filter(data_distrib_reg, metric == "freq_area"), 
                     aes(x = reorder(region, -value), y = value, fill = region)) %>%
+ geom_bar(width = 0.50, fill= "#3182BD", stat="identity") %>%
# + geom_text(aes(label = n, y = n), 
#         vjust = -0.1, color="black",
#         size=3) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by region (area)",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of areas funded (%)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_area_shr

## Both
hist_distrib_reg_top_both_shr = ggplot(filter(data_distrib_reg, metric %in% c("freq_area", "freq_n")), 
                     aes(x = reorder(region, -value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity") %>%
# + geom_text(aes(label = paste(value, "PAs"), y = value), 
#         vjust = -0.1, color="black",
#         size=3.5) %>%
+ labs(title = "Distribution of AFD funded, non-marine protected areas by region",
       subtitle = paste("Sample :", sum(filter(data_distrib_reg, metric == "n")$value), "non-marine protected areas covering", format(sum(filter(data_distrib_reg, metric == "area_km2")$value), digits = 2, scientific = TRUE), "km²"),
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("Area", "Number"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain'))
hist_distrib_reg_top_both_shr
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_reg_n_shr.png", sep = "/"),
       plot = hist_distrib_reg_n_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_reg_area_shr.png", sep = "/"),
       plot = hist_distrib_reg_area_shr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_reg_top_both_shr.png", sep = "/"),
       plot = hist_distrib_reg_top_both_shr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Statistics at region level (non-marine, WDPA vs AFD)

Distribution of PAs funded by the AFD across regions, is compared to the distribution of the full WDPA database. Note the comparison in terms of number instead of percentage is irrelevant. Indeed WDPA reports around 3e5 PAs, and about 100 are AFD funded.

```{r, eval = FALSE}
#For AFD funded PAs
##Distribution across countries (all)
data_distrib_reg_afd = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  group_by(region) %>%
  summarize(n_afd = n(),
            area_km2_afd = sum(area_km2, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot_afd = sum(n_afd),
         area_km2_afd_tot = sum(area_km2_afd, na.rm = TRUE),
         freq_n_afd = round(n_afd/n_tot_afd*100, 2),
         freq_area_afd = round(area_km2_afd/area_km2_afd_tot*100, 2))

#For WDPA PAs
## All countries
data_distrib_reg_wdpa = data_wdpa %>%
  #Non-marine areas only
  filter(marine %in% c(0,1)) %>%
  #Countries of interest only
  filter(iso3 %in% lst_ctry_stat_wdpa) %>%
  group_by(region) %>%
  summarize(n_wdpa = n(),
            area_km2_wdpa = sum(rep_area, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(n_tot_wdpa = sum(n_wdpa),
         area_km2_wdpa_tot = sum(area_km2_wdpa, na.rm = TRUE),
         freq_n_wdpa = round(n_wdpa/n_tot_wdpa*100, 2),
         freq_area_wdpa = round(area_km2_wdpa/area_km2_wdpa_tot*100, 2))

#Then create a plotting dataset with WDPA vs AFD distribution
##the distribution for top targeted countries by AFD
### in terms of numbers
data_distrib_reg_vs_n = data_distrib_reg_wdpa %>%
  left_join(data_distrib_reg_afd, by = "region") %>%
  select(-contains("area")) %>%
  pivot_longer(cols = c("n_afd", "freq_n_afd", "n_wdpa", "freq_n_wdpa"),
               names_to = "metric") %>%
  filter(is.na(region) == FALSE)
 ###in terms of areas
data_distrib_reg_vs_area = data_distrib_reg_wdpa %>%
  left_join(data_distrib_reg_afd, by = "region") %>%
  select(-contains("n_")) %>%
  pivot_longer(cols = c("area_km2_afd", "freq_area_afd", "area_km2_wdpa", "freq_area_wdpa"),
               names_to = "metric") %>%
  filter(is.na(region) == FALSE)

## For top AFD, comparison with WDPA in terms of numbers
hist_distrib_reg_vs_n = ggplot(filter(data_distrib_reg_vs_n, grepl("freq", metric)),
                                  aes(x = reorder(region, value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity", na.rm = TRUE) %>%
+ labs(title = "Distribution of non-marine protected areas across regions (#)",
       subtitle = paste("Sample :", min(data_distrib_reg_wdpa$n_tot_wdpa), "non-marine protected areas reported by the WDPA,",  min(data_distrib_reg_afd$n_tot_afd), "funded by AFD"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\n*These are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of protected areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_reg_vs_n 

## For top AFD, comparison with WDPA in terms of area
hist_distrib_reg_vs_area = ggplot(filter(data_distrib_reg_vs_area, grepl("freq", metric)),
                                  aes(x = reorder(region, value), y = value, fill = metric)) %>%
+ geom_bar(position="dodge", stat="identity", na.rm = TRUE) %>%
+ labs(title = "Distribution of non-marine protected areas across regions (area)",
       subtitle = paste("Sample :", min(data_distrib_reg_wdpa$n_tot_wdpa), "non-marine protected areas reported by the WDPA -", format(min(data_distrib_reg_wdpa$area_km2_wdpa_tot), scientific = TRUE, digits = 2), "km² - \nand",  min(data_distrib_reg_afd$n_tot_afd), "funded by AFD -", format(min(data_distrib_reg_afd$area_km2_afd_tot) , scientific = TRUE, digits = 2), "km² -"),
       caption = "Note : we consider non-marine PAs reported by the WDPA on the full period covered by the data, in countries that are potential AFD partners.\n*These are low-, lower-middle, upper-middle countries according to the World Bank 2022 classification, \nexcluding Russia and including Uruguay, Panama, Chile, New Caledonia.\nA subset of these PAs is AFD funded, though some PAs funded by the AFD are not reported by the WDPA.",
         x = "",
         y = "Share of areas (%)") %>%
+ scale_fill_brewer(name = "", labels = c("AFD funded", "Low- to upper-middle income*"),
                    type = "seq", palette = "Blues") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 0,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
hist_distrib_reg_vs_area
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "hist_distrib_reg_vs_area.png", sep = "/"),
       plot = hist_distrib_reg_vs_area,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "hist_distrib_reg_vs_n.png", sep = "/"),
       plot = hist_distrib_reg_vs_n,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/distribution/wdpa_vs_afd/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

### Surface of PAs

Statistics on PAs surfaces in the different regions and countries.

#### Distribution of surfaces

```{r, eval = FALSE}

tbl_distrib_area_no0 = summary(
  filter(data_stat_nodupl, area_km2 != 0)$area_km2) %>%
  format(scientific = FALSE, big.mark = " ") %>%
  as.array() %>%
  t() %>%
  as.data.frame() %>%
  select(-c("1st Qu.","3rd Qu."))


```

#### Average surface in countries and regions

```{r, eval = FALSE}
#Distribution of PA WITH SURFACE >0 across countries and regions
##Country
data_distrib_no0_ctry = data_stat_nodupl %>%
  filter(area_km2 != 0) %>%
  group_by(iso3, country_en, country_fr) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_stat_nodupl), 1)*100) %>%
  ungroup()

##Region
data_distrib_no0_region = data_stat_nodupl %>%
  filter(area_km2 != 0) %>%
  group_by(region) %>%
  summarize(n = n(),
            freq = round(n/nrow(data_stat_nodupl), 1)*100) %>%
  ungroup()

#By country..
##French
tbl_area_avg_ctry_fr = data_distrib_no0_ctry %>%
  select(-freq) %>%
  left_join(pa_area_ctry, by = "iso3") %>%
  select(-c(iso3, area_tot_km2, tot_area_int)) %>%
  mutate(area_avg_noint_km2 = format(area_tot_noint_km2/n, big.mark = " ", scientific = FALSE, digits = 1),
         area_tot_noint_km2 = format(area_tot_noint_km2, big.mark  = " ", scientific = FALSE, digits = 1),
         )
names(tbl_area_avg_ctry_fr) = c("Pays", "Nombre d'AP", "Superficie totale (km2)", "Superficie moyenne (km2)")
##English
tbl_area_avg_ctry_en = data_distrib_no0_ctry %>%
  select(-freq) %>%
  left_join(pa_area_ctry, by = "iso3") %>%
  select(-c(iso3, area_tot_km2, tot_area_int)) %>%
  mutate(area_avg_noint_km2 = format(area_tot_noint_km2/n, big.mark = " ", scientific = FALSE, digits = 1),
         area_tot_noint_km2 = format(area_tot_noint_km2, big.mark  = " ", scientific = FALSE, digits = 1),
         )
names(tbl_area_avg_ctry_en) = c("Country", "Number of PAs", "Total area (km2)", "Average area (km2)")

#By region
##French
tbl_area_avg_region_fr = data_distrib_no0_region %>%
  select(-freq) %>%
  left_join(pa_area_region, by = "region") %>%
  select(-c(area_tot_km2, tot_area_int, region)) %>%
  mutate(area_avg_noint_km2 = format(area_tot_noint_km2/n, big.mark = " ", scientific = FALSE, digits = 1),
         area_tot_noint_km2 = format(area_tot_noint_km2, big.mark  = " ", scientific = FALSE, digits = 1),
         )
names(tbl_area_avg_region_fr) = c("Région", "Nombre d'AP", "Superficie totale (km2)", "Superficie moyenne (km2)")
##English
tbl_area_avg_region_en = data_distrib_no0_region %>%
  select(-freq) %>%
  left_join(pa_area_region, by = "region") %>%
  select(-c(area_tot_km2, tot_area_int, region)) %>%
  mutate(area_avg_noint_km2 = format(area_tot_noint_km2/n, big.mark = " ", scientific = FALSE, digits = 1),
         area_tot_noint_km2 = format(area_tot_noint_km2, big.mark  = " ", scientific = FALSE, digits = 1),
         )
names(tbl_area_avg_region_en) = c("Rgion", "Number of PAs", "Total area (km2)", "Average area (km2)")

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_distrib_area_no0, type = "latex"), 
      file = paste(tmp, "tbl_distrib_area_no0.tex", sep = "/"))
print(xtable(tbl_area_avg_ctry_fr, type = "latex"), 
      file = paste(tmp, "tbl_area_avg_ctry_fr.tex", sep = "/"))
print(xtable(tbl_area_avg_ctry_en, type = "latex"), 
      file = paste(tmp, "tbl_area_avg_ctry_en.tex", sep = "/"))
print(xtable(tbl_area_avg_region_fr, type = "latex"), 
      file = paste(tmp, "tbl_area_avg_region_fr.tex", sep = "/"))
print(xtable(tbl_area_avg_region_en, type = "latex"), 
      file = paste(tmp, "tbl_area_avg_region_en.tex", sep = "/"))

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/surface/world", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

### Temporal evolution

#### Number of PAs (world, all)

```{r, eval = FALSE}

data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_n = data_stat_nodupl %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(n = n()) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(n = case_when(is.na(n)~0, TRUE~n)) %>%
  arrange(year_funding_first) %>%
  mutate(n_cum = cumsum(n)) 

#Number of PAs funded by year 
#French
fig_n_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = "Nombre d'aires protégées appuyées par année par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_fr
#English
fig_n_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = "Number of protected areas funded each year by AFD",
       subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
       x = "Year",
       y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_en


#Cumulative number over time
#French
fig_ncum_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = "Evolution cumulée du nombre d'aires protégées appuyées par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_fr
#English
fig_ncum_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = "Cumulative number of protected areas funded by AFD",
         subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
         x = "Year",
         y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_en


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_n_pa_fr.png", sep = "/"),
       fig_n_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_n_pa_en.png", sep = "/"),
       fig_n_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_fr.png", sep = "/"),
       fig_ncum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_en.png", sep = "/"),
       fig_ncum_pa_en,
       device = "png",
       height = 6, width = 9)



#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/time_evolution/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Number of PAs (world, non-marine)

```{r, eval = FALSE}

data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_n = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(n = n()) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(n = case_when(is.na(n)~0, TRUE~n)) %>%
  arrange(year_funding_first) %>%
  mutate(n_cum = cumsum(n)) 

#Number of PAs funded by year 
#French
fig_n_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = "Nombre d'aires protégées non-marines appuyées par année par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées non-marines financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_fr
#English
fig_n_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = "Number of non-marine protected areas funded each year by AFD",
         subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known, non-marine funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
         x = "Year",
         y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_en


#Cumulative number over time
#French
fig_ncum_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = "Evolution cumulée du nombre d'aires protégées non-marines appuyées par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées non-marines financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_fr
#English
fig_ncum_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = "Cumulative number of non-marine protected areas funded by AFD",
         subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known, non-marine funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
         x = "Year",
         y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_en


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_n_pa_fr.png", sep = "/"),
       fig_n_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_n_pa_en.png", sep = "/"),
       fig_n_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_fr.png", sep = "/"),
       fig_ncum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_en.png", sep = "/"),
       fig_ncum_pa_en,
       device = "png",
       height = 6, width = 9)



#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/time_evolution/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Number of PAs (region, non-marine)

```{r, eval = FALSE}

roi = "Africa"

data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_n = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(n = n()) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(n = case_when(is.na(n)~0, TRUE~n)) %>%
  arrange(year_funding_first) %>%
  mutate(n_cum = cumsum(n)) 

#Number of PAs funded by year 
#French
fig_n_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = paste("Nombre d'aires protégées non-marines appuyées par année par l'AFD,", roi),
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées non-marines financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_fr
#English
fig_n_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>% 
  # + geom_text(aes(y = n, label = ifelse(n == 0, NA, n)), 
  #             color = "black", size=4, vjust = -0.3) %>%
  + labs(title = paste("Number of non-marine protected areas funded each year by AFD,", roi),
         subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known non-marine, funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
         x = "Year",
         y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_n_pa_en


#Cumulative number over time
#French
fig_ncum_pa_fr = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = paste("Evolution cumulée du nombre d'aires protégées non-marines,", roi),
         subtitle = paste("Echantillon :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "aires protégées"),
         caption = paste("Sur les", sum(data_time_n$n), "aires protégées non-marines financées recensées,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "ont une date de financement inconnue."),
         x = "Année",
         y = "Nombre d'aires protégées") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_fr
#English
fig_ncum_pa_en = ggplot(subset(data_time_n, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = n_cum)) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = n_cum, label = n_cum), 
              color = "black", size=3, vjust = -0.3) %>%
  + labs(title = paste("Cumulated number of non-marine protected areas funded by AFD,", roi),
         subtitle = paste("Sample :", sum(subset(data_time_n, is.na(year_funding_first) == FALSE)$n), "protected areas"),
       caption = paste("Out of", sum(data_time_n$n), "known non-marine, funded protected areas,", sum(subset(data_time_n, is.na(year_funding_first) == TRUE)$n, na.rm = TRUE), "have unknown funding year."),
         x = "Year",
         y = "Number of protected areas") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_ncum_pa_en


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_n_pa_fr.png", sep = "/"),
       fig_n_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_n_pa_en.png", sep = "/"),
       fig_n_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_fr.png", sep = "/"),
       fig_ncum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_ncum_pa_en.png", sep = "/"),
       fig_ncum_pa_en,
       device = "png",
       height = 6, width = 9)



#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/time_evolution", roi, "no_marine", sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Surface of PAs (world, all)

```{r, eval = FALSE}
data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_area = data_stat_nodupl %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(tot_area_km2 = sum(area_km2),
            n = n()) %>%
  left_join(pa_int_yr, by = c("year_funding_first" = "annee_int")) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(tot_area_km2 = case_when(is.na(tot_area_km2)~0, TRUE~tot_area_km2),
         tot_int_km2 = case_when(is.na(tot_int_km2)~0, TRUE~tot_int_km2),
         tot_area_noint_km2 = tot_area_km2 - tot_int_km2) %>%
  arrange(year_funding_first)

#Evolution of area over time
##French
fig_area_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = "Evolution de la superficie financée par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n, na.rm = TRUE), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_fr
##English
fig_area_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = "Evolution of AFD funded area",
         subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n, na.rm = TRUE), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Year",
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_en



#Cumulative area over time
##French
fig_area_cum_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = "Evolution cumulée de la superficie des aires protégées, financées par l'AFD",
          subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_fr
#English
fig_area_cum_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = "Cumulative evolution of area funded by AFD",
          subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_en



```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_area_pa_fr.png", sep = "/"),
       fig_area_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_pa_en.png", sep = "/"),
       fig_area_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_fr.png", sep = "/"),
       fig_area_cum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_en.png", sep = "/"),
       fig_area_cum_pa_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/time_evolution/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Surface of PAs (world, non-marine)

```{r, eval = FALSE}
data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_area = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(tot_area_km2 = sum(area_km2),
            n = n()) %>%
  left_join(pa_int_yr, by = c("year_funding_first" = "annee_int")) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(tot_area_km2 = case_when(is.na(tot_area_km2)~0, TRUE~tot_area_km2),
         tot_int_km2 = case_when(is.na(tot_int_km2)~0, TRUE~tot_int_km2),
         tot_area_noint_km2 = tot_area_km2 - tot_int_km2) %>%
  arrange(year_funding_first)

#Evolution of area over time
##French
fig_area_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = "Evolution de la superficie non-marine financée par l'AFD",
         subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n, na.rm = TRUE), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_fr
##English
fig_area_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = "Evolution of AFD funded non-marine protected areas",
         subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n, na.rm = TRUE), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Year",
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_en



#Cumulative area over time
##French
fig_area_cum_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = "Evolution cumulée de la superficie des aires protégées non-marines, financées par l'AFD",
          subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n, na.rm = TRUE), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_fr
#English
fig_area_cum_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = "Cumulated evolution of non-marine protected areas funded by AFD",
          subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n, na.rm = TRUE), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Year",
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_area_pa_fr.png", sep = "/"),
       fig_area_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_pa_en.png", sep = "/"),
       fig_area_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_fr.png", sep = "/"),
       fig_area_cum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_en.png", sep = "/"),
       fig_area_cum_pa_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/time_evolution/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### Surface of PAs (region, non-marine)

```{r, eval = FALSE}

roi = "Africa"

data_time_range = data.frame(year = 
                              c(min(data_stat_nodupl$year_funding_first, na.rm = TRUE):max(data_stat_nodupl$year_funding_first, na.rm = TRUE))
)


data_time_area = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  #filter(is.na(year_funding_first) == FALSE) %>%
  group_by(year_funding_first) %>%
  summarize(tot_area_km2 = sum(area_km2),
            n = n()) %>%
  left_join(pa_int_yr, by = c("year_funding_first" = "annee_int")) %>%
  full_join(data_time_range, by = c("year_funding_first" = "year")) %>%
  mutate(tot_area_km2 = case_when(is.na(tot_area_km2)~0, TRUE~tot_area_km2),
         tot_int_km2 = case_when(is.na(tot_int_km2)~0, TRUE~tot_int_km2),
         tot_area_noint_km2 = tot_area_km2 - tot_int_km2) %>%
  arrange(year_funding_first)

#Evolution of area over time
##French
fig_area_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = paste("Evolution de la superficie non-marine financée par l'AFD,", roi), 
         subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n, na.rm = TRUE), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_fr
##English
fig_area_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first), y = tot_area_noint_km2)) %>%
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = tot_area_noint_km2, 
                  label = ifelse(tot_area_noint_km2 != 0,
                                 format(tot_area_noint_km2, 
                                        digits = 2, 
                                        scientific = TRUE),
                                 NA)), 
              color = "black", size=2, vjust = -0.3) %>%
  + scale_y_log10(breaks = scales::trans_breaks("log10", function(x) 10^x),
                  labels = scales::trans_format("log10", scales::math_format(10^.x))) %>%
  + annotation_logticks(base = 10, sides = "l", 
                        color = "grey20", outside = "TRUE",
                        short = unit(.5,"mm"),
                        mid = unit(1,"mm"),
                        long = unit(2,"mm")) %>%
  + coord_cartesian(clip = "off") %>%
  + labs(title = paste("Evolution of AFD funded non-marine protected areas,", roi),
         subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n, na.rm = TRUE), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Year",
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_pa_en



#Cumulative area over time
##French
fig_area_cum_pa_fr = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = paste("Evolution cumulée de la superficie des aires protégées non-marines financées par l'AFD\n", roi),
          subtitle = paste("Echantillon :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "aires protégées couvrant", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Sur les ", sum(data_time_area$n, na.rm = TRUE), " aires protégées financées recensées, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " ont une date de financement connue.\nSoit ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² sur ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Année",
         y = "Superficie (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_fr
#English
fig_area_cum_pa_en = ggplot(subset(data_time_area, is.na(year_funding_first) == FALSE),
                  aes(x = factor(year_funding_first),
                      y = cumsum(tot_area_noint_km2))) %>%
  # + geom_point(color = "#3182BD", size = 1.5) %>%
  # + geom_line(color = "#3182BD", size = 1) %>% 
  + geom_bar(stat = 'identity', fill = "#3182BD") %>%
  + geom_text(aes(y = cumsum(tot_area_noint_km2), 
                  label = format(cumsum(tot_area_noint_km2), 
                                 digits = 2,
                                 scientific = TRUE)), 
              color = "black", size=2, vjust = -0.3) %>%
  + labs(title = paste("Cumulated evolution of non-marine protected areas funded by AFD,", roi),
          subtitle = paste("Sample :", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), "protected areas covering", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), "km²"),
         caption = paste0("Out of ", sum(data_time_area$n, na.rm = TRUE), " known funded protected areas, ", sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$n, na.rm = TRUE), " have a known funding year.\nIn terms of area, ", format(sum(subset(data_time_area, is.na(year_funding_first) == FALSE)$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km² out of ", format(sum(data_time_area$tot_area_noint_km2), digits = 1, scientific = FALSE, big.mark = " "), " km²."),
         x = "Year",
         y = "Area (km²)") %>%
  + theme(legend.position = "bottom",
      legend.key = element_rect(fill = "white"),
      plot.title = element_text(size = 14, face = "bold"), 
      axis.text.x = element_text(angle = 45,size=10, hjust = .5, vjust = .6),
      axis.title.x = element_text(margin = margin(t = 10)),
      panel.background = element_rect(fill = 'white', colour = 'white', 
                                      linewidth = 0.5, linetype = 'solid'),
      panel.grid.major = element_line(colour = 'grey90', linetype = 'solid'),
      panel.grid.minor = element_line(colour = 'grey90', linetype = 'solid'),
      plot.caption = element_text(color = 'grey50', size = 8.5, face = 'plain', hjust = 0))
fig_area_cum_pa_en
```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_area_pa_fr.png", sep = "/"),
       fig_area_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_pa_en.png", sep = "/"),
       fig_area_pa_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_fr.png", sep = "/"),
       fig_area_cum_pa_fr,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "fig_area_cum_pa_en.png", sep = "/"),
       fig_area_cum_pa_en,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/time_evolution", roi, "no_marine", sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

### Governance

#### World, all

```{r, eval = FALSE}

#Table of the governance type distribution
##English version
data_gov_en = data_stat_nodupl %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


##French Version
data_gov_fr = data_stat_nodupl %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_fr = data_gov_fr
names(tbl_gov_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")



#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_stat_nodupl %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")

###French
data_gov_knwn_fr = data_stat_nodupl %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Non référencée" & gov_type != "Non rapportée") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_fr = data_gov_knwn_fr
names(tbl_gov_knwn_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")
 

##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Governance type of protected areas except not referenced/reported",
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "protected areas")) %>%
  + scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_en


###French
pie_gov_knwn_fr =
  ggplot(data_gov_knwn_fr, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Gouvernance, hors non-rapportées/référencées",
         subtitle = paste("Echantillon :", sum(data_gov_knwn_fr$n), "aires protégées" )) %>%
  + scale_fill_brewer(name = "Gouvernance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_fr

```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_en,
             caption = "Governance of protected areas funded by AFD",
             type = "latex"),
      file = paste(tmp, "tbl_gov_en.tex", sep  ="/"))
print(xtable(tbl_gov_fr,
             caption = "Gouvernance des aires protégées appuyées par l'AFD",
             type = "latex"),
      file = paste(tmp, "tbl_gov_fr.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_en, 
             caption = "Governance of protected areas funded by AFD (when known)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_fr, 
             caption = "Gouvernance des aires protégées appuyées par l'AFD (si connu)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_fr.tex", sep  ="/"))

ggsave(paste(tmp, " pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "pie_gov_knwn_fr.png", sep = "/"),
       plot = pie_gov_knwn_fr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/gouvernance/world/all", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

#### World, non-marine

```{r, eval = FALSE}

#Table of the governance type distribution
##English version
data_gov_en = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


##French Version
data_gov_fr = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_fr = data_gov_fr
names(tbl_gov_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")



#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")

###French
data_gov_knwn_fr = data_stat_nodupl %>%
  filter(marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Non référencée" & gov_type != "Non rapportée") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_fr = data_gov_knwn_fr
names(tbl_gov_knwn_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")
 

##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Governance type of non-marine protected areas except not referenced/reported",
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "non-marines protected areas")) %>%
  + scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_en


###French
pie_gov_knwn_fr =
  ggplot(data_gov_knwn_fr, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = "Gouvernance des aires protégées non-marines hors non-rapportées/référencées",
         subtitle = paste("Echantillon :", sum(data_gov_knwn_fr$n), "aires protégées non-marines")) %>%
  + scale_fill_brewer(name = "Gouvernance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_fr


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_en,
             caption = "Governance of non-marine protected areas funded by AFD",
             type = "latex"),
      file = paste(tmp, "tbl_gov_en.tex", sep  ="/"))
print(xtable(tbl_gov_fr,
             caption = "Gouvernance des aires protégées non-marines appuyées par l'AFD",
             type = "latex"),
      file = paste(tmp, "tbl_gov_fr.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_en, 
             caption = "Governance of non-marine protected areas funded by AFD (when known)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_fr, 
             caption = "Gouvernance des aires protégées non-marines appuyées par l'AFD (si connu)",
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_fr.tex", sep  ="/"))


ggsave(paste(tmp, "pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "pie_gov_knwn_fr.png", sep = "/"),
       plot = pie_gov_knwn_fr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = "projet-afd-eva-ap/descriptive_stats/gouvernance/world/no_marine", 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))

```

#### Region, non-marine

```{r, eval = FALSE}

roi = "Africa"

#Table of the governance type distribution
##English version
data_gov_en = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_en = data_gov_en
names(tbl_gov_en) = c("Governance","Number of PAs","Share of PAs (%)")


##French Version
data_gov_fr = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_fr = data_gov_fr
names(tbl_gov_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")



#PAs with nureported or unreferenced governance types are removed
##Tables
###English
data_gov_knwn_en = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Not referenced",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Not Reported" & gov_type != "Not referenced") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_en = data_gov_knwn_en
names(tbl_gov_knwn_en) = c("Governance","Number of PAs","Share of PAs (%)")

###French
data_gov_knwn_fr = data_stat_nodupl %>%
  filter(region == roi & marine %in% c(0,1)) %>%
  mutate(gov_type = case_when(is.na(gov_type) == TRUE ~ "Non référencée",
                              gov_type == "Collaborative governance" ~ "Gouvernance collaborative",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Federal or national ministry or agency" ~ "Ministère ou agence, fédérale ou nationale",
                              gov_type == "Government-delegated management" ~ "Gestion déléguée par le gouvernement",
                              gov_type == "Indigenous peoples" ~ "Peuples indigènes",
                              gov_type == "Joint governance" ~ "Gouvernance conjointe",
                              gov_type == "Local communities" ~ "Communautés locales",
                              gov_type == "Non-profit organisations" ~ "Organisations non-lucratives",
                              gov_type == "Not Reported" ~ "Non rapportée",
                              gov_type == "Sub-national ministry or agency" ~ "Ministère ou agence sous-nationale",
                              TRUE ~ gov_type)) %>%
  filter(gov_type != "Non référencée" & gov_type != "Non rapportée") %>%
  group_by(gov_type) %>%
  summarize(n = n()) %>%
  mutate(n_tot = sum(n),
         freq = round(n/n_tot*100,1)) %>%
  select(-n_tot) %>%
  arrange(-freq)

tbl_gov_knwn_fr = data_gov_knwn_fr
names(tbl_gov_knwn_fr) = c("Gouvernance","Nombre d'AP","Proportion (%)")
 

##Pie charts
###English
pie_gov_knwn_en = 
  ggplot(data_gov_knwn_en, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = paste0("Governance type of non-marine protected areas except not referenced/reported\n", roi),
         subtitle = paste("Sample :", sum(data_gov_knwn_en$n), "non-marine protected areas")) %>%
  + scale_fill_brewer(name = "Governance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_en


###French
pie_gov_knwn_fr =
  ggplot(data_gov_knwn_fr, 
       aes(x="", y= freq, fill= gov_type)) %>%
  + geom_bar(width = 1, stat = "identity", color="white") %>%
  + geom_label(aes(x=1.3, 
                   label = paste0(format(freq, digits = 2), "%")), 
               color = "black", 
               position = position_stack(vjust = 0.55), 
               size=2.5, show.legend = FALSE) %>%
  + coord_polar("y", start=0) %>%
  + labs(title = paste0("Gouvernance des aires protégées non-marines hors non-rapportées/référencées\n", roi),
         subtitle = paste("Echantillon :", sum(data_gov_knwn_fr$n), "aires protégées")) %>%
  + scale_fill_brewer(name = "Gouvernance", palette="Paired") %>%
  + theme_void()
pie_gov_knwn_fr


```

```{r, eval = FALSE}
#Saving figures

tmp = paste(tempdir(), "fig", sep = "/")

print(xtable(tbl_gov_en,
             caption = paste("Governance of non-marine protected areas funded by AFD,", roi),
             type = "latex"),
      file = paste(tmp, "tbl_gov_en.tex", sep  ="/"))
print(xtable(tbl_gov_fr,
             caption = paste("Gouvernance des aires protégées non-marines appuyées par l'AFD,", roi),
             type = "latex"),
      file = paste(tmp, "tbl_gov_fr.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_en, 
             caption = paste("Governance of non-marine protected areas funded by AFD,", roi, "(when known)"),
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_en.tex", sep  ="/"))
print(xtable(tbl_gov_knwn_fr, 
             caption = paste("Gouvernance des aires protégées non-marines appuyées par l'AFD,", roi, "(si connu)"),
             type = "latex"),
      file = paste(tmp, "tbl_gov_knwn_fr.tex", sep  ="/"))

ggsave(paste(tmp, "pie_gov_knwn_en.png", sep = "/"),
       plot =  pie_gov_knwn_en,
       device = "png",
       height = 6, width = 9)
ggsave(paste(tmp, "pie_gov_knwn_fr.png", sep = "/"),
       plot = pie_gov_knwn_fr,
       device = "png",
       height = 6, width = 9)

#Export to S3 storage

##List of files to save in the temp folder
files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
count = 0
for(f in files) 
{
  count = count+1
  cat("Uploading file", paste0(count, "/", length(files), " '", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap/descriptive_stats/gouvernance" , roi, "no_marine", sep = "/"), 
                     region = "", show_progress = TRUE)
  }

#Erase the files in the temp directory

do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

<!--chapter:end:01_stat_project.Rmd-->

# (PART\*) Impact analysis {.unnumbered}

# Difference-in-difference

In this script are performed the last steps of the analysis. Using the datasets of matched treated and control units, it is possible to compute the effect of the conservation for each protected area. Then these results can be aggregated at country and region level. Some secondary metrics are also computed : the annual deforestation rates faced by treated and control units, before and after treatment (à la Wolf et al. 2021); the total and average forest loss across groups of protected areas on the period considered, compared to the value in control units, before and after matching.

The process consists of the following steps.

1.  For a given country, load the list of protected areas whose observational units (treated pixels composing this area) have been matched to control units.

2.  For each protected area in this list :

    1.  Compute annual deforestation rates : before and after treatment for treated units, on the whole period for control units.

    2.  Compute treatment effect from matched treated and control pixels. Note that two functions exist depending on the portfolio analyzed : for AFD supported protected areas, funding-related information are added to the analysis (e.g year of funding). For the others, a general script is used.

    3.  Compute treatment effect for unmatched treated and control pixels. This can be useful to assess the bias induced by the selection into treatment. In other words, the bias due to not using matching. Indeed protected areas tend to be located in region less prone to deforestation (e.g further away from cities or roads). Simply using non-protected areas as a counterfactual, without matching, would then overestimate the effect of the conservation program. Note that this step can be time and computationally intensive, because the number of unmatched units is higher than the number of matched ones. It is usually skipped.

    4.  Plot the total area deforested on the period considered, in the protected area and its counterfactual, before and after matching. This is useful to illustrate the bias described above. Note that ideally the deforestation estimated in the protected area before and after matching should be the same. If note, the matched treated units are not representative of the overall protected area and the a local treatment effect will be estimated.

3.  The treatment effects, annual deforestation rates and estimations of total deforested area computed for each protected areas are gathered in specific datasets. This makes it possible to compute metrics aggregated at country and region level. These datastes are saved to the storage.

4.  If relevant, results of the analysis at protected area level are aggregated at country and region level.

5.  Finally, figures and tables are created to display the results.

## Initial settings

Configuring the Rmarkdown.

```{r setup, include=FALSE, eval = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

```

Downloading and importing relevant packages.

```{r, eval = FALSE}
#Install some libraries
install.packages(c("tictoc", "fixest", "cobalt", "future", "progressr", "did", "latex2exp", "janitor", "stringi"))

# Load Libraries
library(dplyr)
library(stringi)
library(tictoc) #For timing
library(xtable)
library(tidyr)
library(stringr)
library(ggplot2) # For plotting
library(RColorBrewer)
library(ggrepel)
library(aws.s3)
library(fixest) #For estimating the models
library(did)
library(latex2exp)
library(janitor)
```

To keep this document concise, each step calls a function defined in a R script. Interested reader can delve deeper into the data processing by looking at this script. The following chunck load the functions in the workspace.

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_did.R")
```

## Load datasets and define critical parameters

```{r, eval = F}
#Define working directories
##Temporary directory
tmp_did = paste(tempdir(), "did", sep = "/")
##Loading and saving directories on the storage. This is either define on today's date, or by a user-defined date.
#load_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/")
load_dir = paste("impact_analysis/matching", "2023-09-21", sep = "/")
#save_dir = paste("impact_analysis/did", Sys.Date(), sep = "/")
save_dir = paste("impact_analysis/did", "2023-09-21", sep = "/")

## Dataset specific to the PAs portfolio to analyze. Only one is selected depending on the analysis one wants to perform. 

## AFD portfolio
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_AFD_ie.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = "")) %>%
#   #Sangha trinational (555547988) created in 2012 actually gathers three former PAs
#   #in CAF (31458), CMR (1245) and COG (72332) implemented in
#   #1990, 2001 and 1993 respectively.
#   # Evaluating the trinational PA is not relevant here : our method relies on pre-treatment obervsations (for matching and DiD) and the outcome is likely to be affected by the initial PAs. On the other hand, evaluating the three earlier PAs might be irrelevant for us : are they funded by the AFD ?? In a first approach, the trinational is removed.
#   filter(is.na(wdpaid) == TRUE | wdpaid != 555547988)

##FAPBM
data_fapbm =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_FAPBM.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

##Madagascar (all PAs)
data_pa =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_MDG.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

# The list of countries (ISO3 codes) to analyze. This can be define manually or from the the dataset loaded.

# list_iso = data_pa %>%
#   filter(region == "Africa") %>%
#   filter(!(iso3 %in% c("ZZ")))
# list_iso = unique(list_iso$iso3)

list_iso = "MDG"

## Information on funding from AFD internal datasets, on AFD funded projects related to protected areas.
data_fund = 
  #fread("data_tidy/BDD_PA_AFD_fund.csv")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  # Mettre les options de FUN ici
  object = "data_tidy/BDD_PA_AFD_fund.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))
data_fund_nodupl = data_fund %>%
  group_by(id_projet) %>%
  slice(1) %>%
  ungroup() %>%
  dplyr::select(-c("mt_part_cofinancier_prevu_euro", "cofinanciers_siop")) %>%
  mutate(kfw = grepl("kfw", cofinanciers, ignore.case = TRUE),
         ffem = grepl("ffem", cofinanciers, ignore.case = TRUE))

## List of projects related to protected areas in AFD, reported by technical departments
data_pa_report = 
  #read_delim("data_raw/BDD_PA_AFD.csv", delim = ";")
  s3read_using(readr::read_delim,
                delim = ";",
               show_col_types = FALSE,
                object = "data_raw/BDD_PA_AFD.csv",
                bucket = "projet-afd-eva-ap",
                opts = list("region" = "")) %>%
  mutate(key = paste(id_projet, nom_ap, wdpaid, sep = "_")) %>%
  group_by(key) %>%
  slice(1)

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Specify the margin of error to define confidence interval (0.05 corresponds 95% confidence interval).
alpha = 0.05

```

## Computing treatment effects at protected area level

```{r, eval = F}
#For each country in the list, the different steps of the processing are performed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic = tic() #Start timer
#Create empty dataframes that will store the treatment effects computed for each protected area in the portfolio. 
##Initialize a dataframe to store annual deforestation rate for each PA, à la Wolf et al. 2021
df_fl_annual_wolf = data.frame()
##Initialize a dataframe to store treatment effects of all PA analyzed
df_fc_att = data.frame() #Effect on forest cover for matched units
##df_fc_att_unm = data.frame() #Effect on forest cover for unmacthed units
df_fl_att = data.frame() #Effect on deforestation relative to 2000
##Initialize a dataframe to store forest loss for visual evidence before/after matching
df_plot_forest_loss = data.frame()

for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Load the matching frame
  print("--Loading the list of PAs in the country considered")
  output_pa_i = fn_did_list_pa(iso = i, load_dir = load_dir)
  if(output_pa_i$is_ok == FALSE) {next} else list_pa_i = output_pa_i$list_pa
  
  count_j = 0
  max_j = length(list_pa_i)
  
  for(j in list_pa_i)
  {
    
    count_j = count_j+1
    print(paste0("WDPA ID ", j, " : ", count_j, "/", max_j))
    
    #Compute annual deforestation rates in treated and control matched areas, à la Wolf et al. 2021.
    print("--Compute average deforestation rates à la Wolf et al. 2021")
    output_wolf_m_j = fn_fl_wolf(iso = i, 
                                wdpaid = j, 
                                alpha = alpha, 
                                load_dir = load_dir,
                                ext_input = ".csv")
    
    if(output_wolf_m_j$is_ok == FALSE) 
      {
      next
      } else df_fl_wolf_m_j = output_wolf_m_j$df_fl_wolf_m_j
    df_fl_annual_wolf = rbind(df_fl_annual_wolf, df_fl_wolf_m_j)
    
    #Compute treatment effects
    print("--Compute treatment effects")
    print("----For matched units")
    
    #For AFD projects (funding info)
    # output_att_m_j = fn_did_att_afd(iso = i, wdpaid = j, 
    #                       is_m = TRUE,
    #                   data_pa = data_pa,
    #                   data_fund = data_fund_nodupl,
    #                   data_report = data_pa_report,
    #                   alpha = alpha,
    #                   load_dir = load_dir,
    #                   ext_input = ".csv",
    #                   save_dir = save_dir)
    
    #For PAs in general (no funding info)
      output_att_m_j = fn_did_att_general(iso = i, wdpaid = j, 
                        is_m = TRUE,
                    data_pa = data_pa,
                    alpha = alpha,
                    load_dir = load_dir,
                    ext_input = ".csv",
                    save_dir = save_dir)
    
    if(output_att_m_j$is_ok == FALSE) {next} else df_att_m_j = output_att_m_j
    
    df_fc_att = rbind(df_fc_att, df_att_m_j$df_fc_att)
    df_fl_att = rbind(df_fl_att, df_att_m_j$df_fl_att)
        
    print("----For unmatched units")
    
    #For AFD PAs (funding info known)
    # df_att_unm_j = fn_did_att_afd(iso = i, wdpaid = j, 
    #                       is_m = FALSE,
    #                   data_pa = data_pa,
    #                   alpha = 0.05,
    #                   load_dir = load_dir,
    #                   ext_input = ".csv",
    #                   save_dir = save_dir)
    # df_fc_att_unm = rbind(df_fc_att_unm, df_att_unm_j$df_fc_att)
    # df_fl_att_unm = rbind(df_fl_att, df_att_unm_j$df_fl_att)
    
    #For general PAs (funding info unknown)
    # df_att_unm_j = fn_did_att_general(iso = i, wdpaid = j, 
    #                       is_m = FALSE,
    #                   data_pa = data_pa,
    #                   alpha = 0.05,
    #                   load_dir = load_dir,
    #                   ext_input = ".csv",
    #                   save_dir = save_dir)    
    # df_fc_att_unm = rbind(df_fc_att_unm, df_att_unm_j$df_fc_att)
    # df_fl_att_unm = rbind(df_fl_att, df_att_unm_j$df_fl_att)
    
    #Plot visual evidence before-after matching
    print("--Plot visual evidence before-after matching")
    df_plot_forest_loss_j = fn_plot_forest_loss(iso = i, 
                                                wdpaid = j, 
                                                alpha = alpha,
                                                data_pa = data_pa, 
                                                load_dir = load_dir, 
                                                ext_input = ".csv", 
                                                save_dir = save_dir)
    df_plot_forest_loss = rbind(df_plot_forest_loss, df_plot_forest_loss_j)

  }  

  
  
}

#Finally save the treatment effects computed for every protected areas analyzed
## Treatment effect expressed in forest cover loss avoided (ha)
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_fc_att,
# Mettre les options de FUN ici
object = paste(save_dir, "data_fc_att.csv", sep = "/"),
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))
## Treatment effect expressed in change of deforestation rate (percentage points)
aws.s3::s3write_using(
FUN = data.table::fwrite,
df_fl_att,
# Mettre les options de FUN ici bucket = , iso, wdpaid, sep = "/")
object = paste(save_dir, "data_fl_att.csv", sep = "/"), 
bucket = "projet-afd-eva-ap",
opts = list("region" = ""))

toc = toc()


```

## Compute aggregated metrics at country and region level

The aggregation of results at country and regional level is not necessarily relevant when the number of protected areas by country or region is relatively small and results heterogenous across protected areas. Instead, a figure displaying the results for all protected areas in the sample might be mor relevant. See next section.

### Aggregation of treatment effects

```{r, eval = FALSE}

#Treatment effects are aggregated by region and country
#For total avoided deforestation in ha, treatment effects are summed and so are the confidence intervals (CI).
## If the CI of a treatment effect is NA, then the CI for total treatment effects is NA also. Otherwise CI will be downward biased.
#For avoided deforestation in % of 2000 forest cover, treatment effects are averaged and so are CI. CI being NA is less a problem here as we use a mean, not a sum

avg_att_fc_ctry = df_fc_att %>%
  group_by(region, iso3, time) %>%
  summarize(n_obs = n(),
            att_per_mean = mean(att_per, na.rm = TRUE),
            cband_lower_per = mean(cband_lower_per, na.rm = TRUE),
            cband_upper_per = mean(cband_upper_per, na.rm = TRUE),
            att_pa_tot = sum(att_pa, na.rm = TRUE),
            cband_lower_pa = sum(cband_lower_pa, na.rm = FALSE),
            cband_upper_pa = sum(cband_upper_pa, na.rm = FALSE))

avg_att_fc_region = df_fc_att %>%
  group_by(region, time) %>%
  summarize(n_obs = n(),
            att_per_mean = mean(att_per, na.rm = TRUE),
            cband_lower_per = mean(cband_lower_per, na.rm = TRUE),
            cband_upper_per = mean(cband_upper_per, na.rm = TRUE),
            att_pa_tot = sum(att_pa, na.rm = TRUE),
            cband_lower_pa = sum(cband_lower_pa, na.rm = FALSE),
            cband_upper_pa = sum(cband_upper_pa, na.rm = FALSE))

avg_att_fl_ctry = df_fl_att %>%
  group_by(region, iso3, time) %>%
  summarize(n_obs = n(),
            att_mean = mean(att, na.rm = TRUE),
            cband_lower = mean(cband_lower, na.rm = TRUE),
            cband_upper = mean(cband_upper, na.rm = TRUE))

avg_att_fl_region = df_fl_att %>%
  group_by(region, time) %>%
  summarize(n_obs = n(),
            att_mean = mean(att, na.rm = TRUE),
            cband_lower = mean(cband_lower, na.rm = TRUE),
            cband_upper = mean(cband_upper, na.rm = TRUE))


```

### Aggregation of annual deforestation rates

```{r, eval = F}

#Aggregate at region level
## Compute for each region, for treated units, average annual deforestation rate before treatment, after treatment and on the full period. Confidence intervals are also computed.
avg_fl_annual_wolf_region = df_fl_annual_wolf %>%
  filter(group == "Treated") %>%
  group_by(region) %>%
  summarize(avg_FL_annual_wolf_pre = mean(avgFL_annual_wolf_pre, na.rm = TRUE),
            avg_FL_annual_wolf_pre_ci_up = mean(avgFL_annual_wolf_pre, na.rm = TRUE) +  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_pre, na.rm = TRUE)/sqrt(21),
            avg_FL_annual_wolf_pre_ci_lower = mean(avgFL_annual_wolf_pre, na.rm = TRUE) -  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_pre, na.rm = TRUE)/sqrt(21),
            med_FL_annual_wolf_pre_ci_up = median(avgFL_annual_wolf_pre, na.rm = TRUE),
            avg_FL_annual_wolf_tot = mean(avgFL_annual_wolf_tot, na.rm = TRUE),
            avg_FL_annual_wolf_tot_ci_up = mean(avgFL_annual_wolf_tot, na.rm = TRUE) +  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_tot, na.rm = TRUE)/sqrt(21),
            avg_FL_annual_wolf_tot_ci_lower = mean(avgFL_annual_wolf_tot, na.rm = TRUE) -  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_tot, na.rm = TRUE)/sqrt(21),
            med_FL_annual_wolf_tot_ci_up = median(avgFL_annual_wolf_tot, na.rm = TRUE)) 

#Aggregate at country level
## Same that at region level.
avg_fl_annual_wolf_country = df_fl_annual_wolf %>%
  filter(group == "Treated") %>%
  group_by(iso3) %>%
  summarize(avg_FL_annual_wolf_pre = mean(avgFL_annual_wolf_pre, na.rm = TRUE),
            avg_FL_annual_wolf_pre_ci_up = mean(avgFL_annual_wolf_pre, na.rm = TRUE) +  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_pre, na.rm = TRUE)/sqrt(21),
            avg_FL_annual_wolf_pre_ci_lower = mean(avgFL_annual_wolf_pre, na.rm = TRUE) -  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_pre, na.rm = TRUE)/sqrt(21),
            med_FL_annual_wolf_pre_ci_up = median(avgFL_annual_wolf_pre, na.rm = TRUE),
            avg_FL_annual_wolf_tot = mean(avgFL_annual_wolf_tot, na.rm = TRUE),
            avg_FL_annual_wolf_tot_ci_up = mean(avgFL_annual_wolf_tot, na.rm = TRUE) +  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_tot, na.rm = TRUE)/sqrt(21),
            avg_FL_annual_wolf_tot_ci_lower = mean(avgFL_annual_wolf_tot, na.rm = TRUE) -  qt((1-alpha)/2,df=21-1)*sd(avgFL_annual_wolf_tot, na.rm = TRUE)/sqrt(21),
            med_FL_annual_wolf_tot_ci_up = median(avgFL_annual_wolf_tot, na.rm = TRUE)) %>%
  ungroup() 
  

```

### Average and total forest loss on the period, at country and region level

For each protected area, the total deforestation is estimated on the period in the protected area and a counterfactual, before and after matching. This metric can be aggregated at country and region level : the sum of total deforestation or its average. This can be computed for all protected areas in the sample, a specific subset of protected areas, but also at country or region level.

```{r, eval = F}

#Compute average and total deforestation ... 
## across all protected areas in the sample
df_plot_forest_loss_agg_all = df_plot_forest_loss %>%
  group_by(matched, group, year) %>%
  summarize(tot_fc_rel00_ha = sum(fc_tot_rel00_ha, na.rm = TRUE),
            tot_fc_rel00_ha_ci_lower = sum(fc_tot_rel00_ha_ci_lower, na.rm = FALSE),
            tot_fc_rel00_ha_ci_upper = sum(fc_tot_rel00_ha_ci_upper, na.rm = FALSE),
              avg_fc_rel00_ha = mean(fc_tot_rel00_ha, na.rm = TRUE),
              avg_fc_rel00_ha_ci_lower = mean(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
              avg_fc_rel00_ha_ci_upper = mean(fc_tot_rel00_ha_ci_upper, na.rm = TRUE)) %>%
  ungroup() 
## for each country
df_plot_forest_loss_agg_ctry = df_plot_forest_loss %>%
  group_by(region, iso3, country_en, matched, group, year) %>%
  summarize(tot_fc_rel00_ha = sum(fc_tot_rel00_ha, na.rm = TRUE),
            tot_fc_rel00_ha_ci_lower = sum(fc_tot_rel00_ha_ci_lower, na.rm = FALSE),
            tot_fc_rel00_ha_ci_upper = sum(fc_tot_rel00_ha_ci_upper, na.rm = FALSE),
              avg_fc_rel00_ha = mean(fc_tot_rel00_ha, na.rm = TRUE),
              avg_fc_rel00_ha_ci_lower = mean(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
              avg_fc_rel00_ha_ci_upper = mean(fc_tot_rel00_ha_ci_upper, na.rm = TRUE)) %>%
  ungroup() 
## for each region
df_plot_forest_loss_agg_all = df_plot_forest_loss %>%
  group_by(region, matched, group, year) %>%
  summarize(tot_fc_rel00_ha = sum(fc_tot_rel00_ha, na.rm = TRUE),
            tot_fc_rel00_ha_ci_lower = sum(fc_tot_rel00_ha_ci_lower, na.rm = FALSE),
            tot_fc_rel00_ha_ci_upper = sum(fc_tot_rel00_ha_ci_upper, na.rm = FALSE),
              avg_fc_rel00_ha = mean(fc_tot_rel00_ha, na.rm = TRUE),
              avg_fc_rel00_ha_ci_lower = mean(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
              avg_fc_rel00_ha_ci_upper = mean(fc_tot_rel00_ha_ci_upper, na.rm = TRUE)) %>%
  ungroup() 

## For a specific subset of protected areas (here, protected areas funded by the FAPBM for instance)
df_plot_forest_loss_agg_fapbm = df_plot_forest_loss %>%
  filter(wdpaid %in% unique(data_fapbm$wdpaid)) %>%
  group_by(matched, group, year) %>%
  summarize(tot_fc_rel00_ha = sum(fc_tot_rel00_ha, na.rm = TRUE),
            tot_fc_rel00_ha_ci_lower = sum(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
            tot_fc_rel00_ha_ci_upper = sum(fc_tot_rel00_ha_ci_upper, na.rm = TRUE),
              avg_fc_rel00_ha = mean(fc_tot_rel00_ha, na.rm = TRUE),
              avg_fc_rel00_ha_ci_lower = mean(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
              avg_fc_rel00_ha_ci_upper = mean(fc_tot_rel00_ha_ci_upper, na.rm = TRUE)) %>%
  ungroup()

df_plot_forest_loss_agg_nofapbm = df_plot_forest_loss %>%
  filter(!(wdpaid %in% unique(data_fapbm$wdpaid))) %>%
  group_by(matched, group, year) %>%
  summarize(tot_fc_rel00_ha = sum(fc_tot_rel00_ha, na.rm = TRUE),
            tot_fc_rel00_ha_ci_lower = sum(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
            tot_fc_rel00_ha_ci_upper = sum(fc_tot_rel00_ha_ci_upper, na.rm = TRUE),
              avg_fc_rel00_ha = mean(fc_tot_rel00_ha, na.rm = TRUE),
              avg_fc_rel00_ha_ci_lower = mean(fc_tot_rel00_ha_ci_lower, na.rm = TRUE),
              avg_fc_rel00_ha_ci_upper = mean(fc_tot_rel00_ha_ci_upper, na.rm = TRUE)) %>%
  ungroup()


# Plot the results : total and average deforestation
## The maximum year to consider. The period where total deforestation is computed is then 2000-year.max.
year.max = 2021
## Titles to display
fct.labs <- c("Before Matching", "After Matching")
names(fct.labs) <- c(FALSE, TRUE)
## The number of protected areas (all and in a given subsample, for instance)
n_pa  = length(unique(df_plot_forest_loss$wdpaid))
  fct.labs <- c("Before Matching", "After Matching")
  names(fct.labs) <- c(FALSE, TRUE)
#n_fapbm  = length(unique(data_pa_fapbm[data_pa_fapbm$wdpaid %in% unique(df_plot_forest_loss$wdpaid),]$wdpaid))
  n_nofapbm  = length(unique(data_pa[data_pa$wdpaid %in% unique(df_plot_forest_loss$wdpaid) & !(data_pa$wdpaid %in% unique(data_fapbm$wdpaid)),]$wdpaid))
## The total surface of protected areas (all and in a given subsample, for instance)
area_tot_ha = sum(data_pa[data_pa$wdpaid %in% unique(df_plot_forest_loss$wdpaid),]$area_km2, na.rm = TRUE) *100
#area_fapbm_ha = sum(data_pa_fapbm[data_pa_fapbm$wdpaid %in% unique(df_plot_forest_loss$wdpaid),]$area_km2, na.rm = TRUE) *100
area_nofapbm_ha = sum(data_pa[data_pa$wdpaid %in% unique(df_plot_forest_loss$wdpaid) & !(data_pa$wdpaid %in% unique(data_fapbm$wdpaid)),]$area_km2, na.rm = TRUE) *100

## Define the figures
### For a given subsample
#### Total deforestation
fig_forest_loss_agg_tot_fapbm = ggplot(data = filter(df_plot_forest_loss_agg_fapbm, year == year.max),
               aes(y = abs(tot_fc_rel00_ha), fill = as.factor(group), x = group)) %>%
    + geom_bar(position =  position_dodge(width = 0.8), stat = "identity", show.legend = FALSE) %>%
    + geom_errorbar(aes(ymax=abs(tot_fc_rel00_ha_ci_upper), ymin=abs(tot_fc_rel00_ha_ci_lower)), width=0.3, colour="grey70", alpha=0.9, size=1) %>%
    + geom_label(aes(label = format(round(abs(tot_fc_rel00_ha), 0), big.mark = ","), y = 0),
                 vjust = -0.5,
                 color = "black",
                 show.legend = FALSE) %>%
    + scale_fill_brewer(name = "Group", palette = "Blues") %>%
    + labs(x = "",
           y = "Forest cover loss (ha)",
           title = paste("Total area deforested between 2000 and", year.max),
           subtitle = paste0("Sample : FAPBM protected areas in the analysis (" , n_fapbm, " areas covering ", format(area_fapbm_ha, big.mark = ","), "ha)"),
           caption = paste(((1-alpha)*100), "% confidence intervals")) %>%
    + facet_wrap(~matched,
                 labeller = labeller(matched = fct.labs))  %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),

      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),

      strip.text = element_text(color = "black", size = 12),

      #legend.position = "bottom",
      #legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),

      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
fig_forest_loss_agg_tot_fapbm

#### Average deforestation
fig_forest_loss_agg_avg_nofapbm = ggplot(data = filter(df_plot_forest_loss_agg_nofapbm, year == year.max),
               aes(y = abs(avg_fc_rel00_ha), fill = as.factor(group), x = group)) %>%
    + geom_bar(position =  position_dodge(width = 0.8), stat = "identity", show.legend = FALSE) %>%
    + geom_errorbar(aes(ymax=abs(avg_fc_rel00_ha_ci_upper), ymin=abs(avg_fc_rel00_ha_ci_lower)), width=0.3, colour="grey70", alpha=0.9, size=1) %>%
    + geom_label(aes(label = format(round(abs(avg_fc_rel00_ha), 0), big.mark = ","), y = 0),
                 vjust = -0.5,
                 color = "black",
                 show.legend = FALSE) %>%
    + scale_fill_brewer(name = "Group", palette = "Blues") %>%
    + labs(x = "",
           y = "Forest cover loss (ha)",
           title = paste("Area deforested in protected areas on average, between 2000 and", year.max),
           subtitle = paste0("Sample : non FAPBM protected areas in the analysis (" , n_nofapbm, " areas covering ", format(area_nofapbm_ha, big.mark = ","), " ha)"),
           caption = paste(((1-alpha)*100), "% confidence intervals")) %>%
    + facet_wrap(~matched,
                 labeller = labeller(matched = fct.labs))  %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),

      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),

      strip.text = element_text(color = "black", size = 12),

      #legend.position = "bottom",
      #legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),

      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
fig_forest_loss_agg_avg_nofapbm


```

Eventually the plots are saved in the remote storage.

```{r, eval = F}
##Saving plots
tmp = paste(tempdir(), "fig", sep = "/")

ggsave(paste(tmp, "fig_forest_loss_agg_tot_fapbm.png", sep = "/"),
       plot = fig_forest_loss_agg_tot_fapbm,
       device = "png",
       height = 6, width = 9)

ggsave(paste(tmp, "fig_forest_loss_agg_avg_nofapbm.png", sep = "/"),
       plot = fig_forest_loss_agg_avg_nofapbm,
       device = "png",
       height = 6, width = 9)

  files <- list.files(tmp, full.names = TRUE)
##Add each file in the bucket (same foler for every file in the temp)
for(f in files) 
{
  cat("Uploading file", paste0("'", f, "'"), "\n")
  aws.s3::put_object(file = f, 
                     bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                     region = "", show_progress = TRUE)
}
do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
```

## Display treatment effects in figures and tables

The treatment effects computed for each protected areas can be displayed in figures or tables. Again, a function is used for protected areas supported by the AFD to include information on funding (funding year for instance), and an other for non-supported ones.

Note some protected areas can be removed from the display, because the matching is not satisfying or pre-treatment trends are too different between treated and control units (thus the matched control risk to be an irrelevant counterfactual). Also, one might want to highlight some protected areas. For instance when comparing a subset of protected areas in a given country to the others (protected areas in Madagascar supported by the AFD versus the others for instance).

```{r, eval = F}
# Define a list of protected areas that will not be displayed
list_wdpa_bad = c(352240, #matching
                  352240, #matching
                  555542728, #pre-treatment parallel trend
                  555548846 #no confidence intervals
                  )
# Define a list of protected areas where a focus is needed
list_wdpa_focus = unique(data_fapbm$wdpaid)

# Get rid of some protected areas in the dataset used to plotting figures and tables
df_fc_att_tidy = df_fc_att %>%
  filter(!wdpaid %in% list_wdpa_bad)
df_fl_att_tidy = df_fl_att %>%
  filter(!wdpaid %in% list_wdpa_bad)

# A function to create figures and tables
##For AFD supported protected areas (funding info)
# fn_plot_att_afd(df_fc_att = df_fc_att_tidy,
#             df_fl_att = df_fl_att_tidy, 
#             alpha = alpha,
#             save_dir = save_dir)
##For other protected areas (no funding info)
fn_plot_att_general(df_fc_att = df_fc_att_tidy,
            df_fl_att = df_fl_att_tidy, 
            list_focus = list_wdpa_focus,
            alpha = alpha,
            save_dir = save_dir)

```

## 

<!--chapter:end:02_did.Rmd-->

# (PART\*) Impact analysis {.unnumbered}

# Matching

In this R Markdown are performed the different steps to obtain a matched dataset, i.e a dataset with control and treated observational units to eventually compute the treatment effect. The treatment here is to be under protected area status, and we look at the impact on deforestation.

The steps are the following.   

1.  Pre-processing : in a loop for each country,

    1.  create a gridding of the country;

    2.  import geospatial data on protected areas (PAs) from the World Dataset on Protected Areas (WDPA) and assign each observation unit/pixel to a group : PA of interest and analyzed (treated), PA of interest but not analyzed, PA not of interest, buffer (pixel closed to but not in a PA), other (so potential control). A PA of interest can be a PA known to be supported by the Agence Française de Développement (AFD) for instance. Some PAs are of interest but cannot be analyzed due to the design of the methodology (e.g marine protected areas when the focus is on deforestation);

    3.  compute the covariates and outcome of interest in all pixels thanks to the mapme.biodiversity package;

    4.  build the matching data frame : each pixel is assigned to a group and has covariates and outcome values.

2.  Post-processing : in each country,

    1.  Load the matching dataframe obtained at the end of pre-processing for a given country, and extract the list of protected areas to process.

    2.  For each protected area,

        1.  perform the matching;

        2.  plot covariate balance and density plots to assess the quality of the match;

        3.  panelize the dataframe;

        4.  plot the evolution of forest cover in treated and control areas, before and after matching;

        5.  map the matched treated and control units.

    3.  Map all matched treated and control units in the country.

The methodology is not extensively described here to keep the documentation concise. The interested reader can refer to the working paper for more details.

## Initial settings

Configuring the Rmarkdown

# ```{r setup, include=FALSE, eval = FALSE}
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) 
# ```

Downloading and installing the relevant packages

```{r eval= F, message=FALSE, warning=FALSE}
#Install some libraries
## CRAN version
install.packages(c("tictoc", "geodata", "wdpar", "exactextractr", "MatchIt", "fixest", "cobalt", "future", "progressr", "mapme.biodiversity", "future.callr", "janitor", "geomtextpath", "rstac"))
## Github version (can be relevant if some features have not made it to CRAN version yet)
#remotes::install_github("mapme-initiative/mapme.biodiversity", upgrade="always")
#remotes::install_github("prioritizr/wdpar", upgrade="always")

#Install the web driver to download wdpa data directly
webdriver::install_phantomjs()  

# Load Libraries
library(dplyr)
library(janitor) #Functions to automate name cleaning
library(tictoc) #For timing
library(xtable) #Export dataframes as tables
library(tidyr)
library(stringr) #String specific functions
library(ggplot2) # For plotting
library(geomtextpath) #For annoted vertical lines in ggplot
library(RColorBrewer) #Improved color palettes for plot legends
library(ggrepel) #Refine labelling of some figures
library(sf) # For handling vector data
library(terra) # For handling raster data
library(raster) # For handling raster data
library(rgeos) 
library(geodata) # For getting country files
library(wdpar) # For getting protected areas
library(exactextractr) # For zonal statistics
library(mapme.biodiversity) #Download geospatial data and compute specific indicators
library(rstac) #To downlad NASA SRTM data
library(aws.s3) #Access to storage
library(MatchIt) #For matching
library(fixest) #For estimating the models
library(cobalt) #To visualize density plots and covariate balance from MatchIt outcomes
library(future) #For parallel computing in mapme.biodiversity
library(future.callr)  #For parallel computing in mapme.biodiversity
library(progressr) # To display progress bar   
```

Load the R functions called in the data processing

```{r message=FALSE, warning=FALSE, eval = FALSE}
#Import functions
source("scripts/functions/02_fns_matching.R")      
```

## Datasets and critical parameters

```{r, eval = FALSE}
# Define working directories
## Define the path to a temporary, working directory processing steps.
tmp_pre = paste(tempdir(), "matching_pre", sep = "/")
tmp_post = paste(tempdir(), "matching_post", sep = "/")
## Define a directory where outputs are stored in SSPCloud.
save_dir = paste("impact_analysis/matching", Sys.Date(), sep = "/") #Today's date
# save_dir = paste("impact_analysis/matching", "2023-08-29", sep = "/") #A specific date

# Load datasets
## WDPA database   
## Download and save
# wdpa_wld_raw = wdpa_fetch(x = "global", wait = TRUE, download_dir = tmp_pre, page_wait = 2, verbose = TRUE)
# s3write_using(wdpa_wld_raw,
#               sf::st_write,
#               delete_dsn = TRUE,
#               object = paste0("data_raw/wdpa/wdpa_shp_global_raw.gpkg"),
#               bucket = "projet-afd-eva-ap",   
#               opts = list("region" = ""))

##Load
wdpa_wld_raw = s3read_using(
              sf::st_read,
              object = "data_raw/wdpa/wdpa_shp_global_raw.gpkg",
              bucket = "projet-afd-eva-ap",
              opts = list("region" = ""))

## Dataset specific to the PAs portfolio to analyze. Only one is selected depending on the analysis one wants to perform. 

### PAs supported by the AFD
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_AFD_ie.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = "")) %>%
#   #Sangha trinational (555547988) created in 2012 actually gathers three former PAs
#   #in CAF (31458), CMR (1245) and COG (72332) implemented in
#   #1990, 2001 and 1993 respectively.
#   # Evaluating the trinational PA is not relevant here : our method relies on pre-treatment obervsations (for matching and DiD) and the outcome is likely to be affected by the initial PAs. On the other hand, evaluating the three earlier PAs might be irrelevant for us : are they funded by the AFD ?? In a first approach, the trinational is removed.
#   filter(is.na(wdpaid) == TRUE | wdpaid != 555547988)

## PAs supported by the FAPBM
# data_pa =
#   #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
#   aws.s3::s3read_using(
#   FUN = data.table::fread,
#   encoding = "UTF-8",
#   object = "data_tidy/BDD_PA_FAPBM.csv",
#   bucket = "projet-afd-eva-ap",
#   opts = list("region" = ""))

## All PAs in Madagascar
data_pa =
  #fread("data_tidy/BDD_PA_AFD_ie.csv" , encoding = "UTF-8")
  aws.s3::s3read_using(
  FUN = data.table::fread,
  encoding = "UTF-8",
  object = "data_tidy/BDD_PA_MDG.csv",
  bucket = "projet-afd-eva-ap",
  opts = list("region" = ""))

# The list of countries (ISO3 codes) to analyze. This can be define manually or from the the dataset loaded.
#List of countries in the sample
# list_iso_africa = unique(data_pa[data_pa$region == "Africa", iso3])
list_iso = "MDG"
      
# Specify buffer width in meter
buffer_m = 10000
# Specify the grid cell size in meter
#gridSize = 10000 
# Specify to sampling : the ideal, minimal number of pixels in a protected area. 
## Note that by design this number is indicative, as the pixel size is defined from the protected area reported surface and sampling number, but the area considered in the analysis is the terrestrial area. For PAs with a marine part, the area analyzed is smaller and the number of pixels mechanically lower.
n_sampling = 1000 

#Specify the period of study to create the mapme.bidiversity portfolio
## Start year
yr_first = 2000
## End year
yr_last = 2021

#Minimum treatment year
#At least two pre-treatment periods of forest cover are needed to compute average pre-treatment deforestation, used as a matching variable.
yr_min = yr_first+2

# Define column names of matching covariates
colname.travelTime = "minutes_median_5k_110mio"
colname.clayContent = "clay_0_5cm_mean"
colname.elevation = "elevation_mean"
colname.tri = "tri_mean"
colname.fcIni = "treecover_2000"
colname.flAvg = "avgLoss_pre_treat"

#Matching 
## Parameters
match_method = "cem"
cutoff_method = "sturges"
k2k_method = "mahalanobis"
is_k2k = TRUE
## Criteria to assess matching quality
### Standardized absolte mean difference : threshold
th_mean = 0.1
### Variance ratio : thresholds
th_var_min = 0.5
th_var_max = 2
       
```

## Matching process

The following code is divided into pre- and post-processing steps (see above). At pre-processing stage, computations are done country-by-country. At post-proccessing stage, computations are done country-by-country and protected areas by protected areas. To facilitate the reading, each step consists in a call of a function define in an other R script.

During the process, a text file (so-called log) is edited to keep track of the differents steps. Then after each critical step, the code checks whether an error occured by interrogating the variable is_ok (defined in the function corresponding to the step). If the step is ok (is_ok = TRUE) then the processing continues. Otherwise, the code goes to the next iteration (next country for pre-processing, next protected area for post-processing). This is useful in a multi-country, multi-PA analysis, to avoid the code to stop when an error occurs. Instead, the code continue and the analyst can see in the log whether there have been errors during the processing, where it happened and whether he or she needs to launch the analysis again for a specific country/PA. Generally speaking, this log is useful to remember what has been analyzed and assess everything was fine after the processing (warnings, processing of all the countries and PAs, etc.).

For more details about the each step, please refer to the definition of the functions.

```{r message=FALSE, warning=FALSE, eval = FALSE}


##########
### PRE-PROCESSING
##########

#For each country in the list, the different steps of the pre-processing are performed, and the process duration computed
count = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_pre = tic() #Start timer

#Create a log to track progress of the analysis
log = fn_pre_log(list_iso,
                 buffer = buffer_m,
                 sampling = n_sampling,
                 yr_first = yr_first,
                 yr_last = yr_last,
                 yr_min = yr_min,
                 name = paste0("log-", Sys.Date(), "-NAME.txt"),
                 notes = "Specific notes or remarks.")

# Perform pre-processing steps country-by-country
for (i in list_iso)            
{
  #Update counter and display progress
  count = count+1
  print(paste0(i, " : country ", count, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n#####\n\n"), file = log, append = TRUE)
     
  #Generate observation units
  print("--Generating observation units")
  output_grid = fn_pre_grid(iso = i, 
                            yr_min = yr_min,
                            path_tmp = tmp_pre, 
                            data_pa = data_pa,
                            sampling = n_sampling,
                            log = log,
                            save_dir = save_dir)
  if(output_grid$is_ok == FALSE) {next}  
  
  #Load the outputs 
  utm_code = output_grid$utm_code #UTM code 
  gadm_prj = output_grid$ctry_shp_prj #The country polygon with relevant projection
  grid = output_grid$grid #The country gridding
  gridSize = output_grid$gridSize #The spatial resolution of the gridding
  
  #Determining Group IDs and WDPA IDs for all observation units
  print("--Determining Group IDs and WDPA IDs")
  output_group = fn_pre_group(iso = i, wdpa_raw = wdpa_wld_raw,
                              status = c("Proposed", "Designated", "Inscribed", "Established"),
                            yr_min = yr_min,
                            path_tmp = tmp_pre, utm_code = utm_code,
                            buffer_m = buffer_m, data_pa = data_pa,
                            gadm_prj = gadm_prj, grid = grid, 
                            gridSize = gridSize,
                            log = log,
                            save_dir = save_dir)
  if(output_group$is_ok == FALSE) {next} else grid_param = output_group$grid.param

  #Calculating outcome and other covariates for all observation units
  print("--Calculating outcome and other covariates")
  output_mf = 
    fn_pre_mf_parallel(grid.param = grid_param, 
                       path_tmp = tmp_pre, 
                       iso = i,
                       name_output = paste0("matching_frame_spling", n_sampling),
                       ext_output = ".gpkg",
                       yr_first = yr_first, yr_last = yr_last,  
                       log = log,
                       save_dir = save_dir)  
  if(output_mf$is_ok == FALSE) {next}                                            
  
  #Remove files in the session memory, to avoid saturation
  tmp_files = list.files(tmp_pre, include.dirs = T, full.names = T, recursive = T)
  file.remove(tmp_files)
                                  
}                            
  
  #End timer for pre-processing
  toc_pre = toc()
  
  #Append the log
  cat(paste("END OF PRE-PROCESSING :", toc_pre$callback_msg, "\n\n"), 
      file = log, append = TRUE)

  
##########
### POST-PROCESSING
##########
  
           
#For each country in the list, the different steps of the post-processing are performed, and duration of the processing computed
count_i = 0 #Initialize counter
max_i = length(list_iso) #Max value of the counter
tic_post = tic() #start timer

#Append the log, and specify matching parameters and quality assessment
cat(paste("##########\nPOST-PROCESSING\n##########\n\nPARAMETERS :\nMatching\n#Parameters\n##Method :", match_method, "\n##Automatic cutoffs :", cutoff_method, "\n##Is it K2K matching ?", is_k2k, "\n##K2K method :", k2k_method, "\n#Quality assessement\n##Absolute standardized mean difference (threshold)", th_mean, "\n##Variance ratio between", th_var_min, "and", th_var_max), 
    file = log, append = TRUE)
  
# Perform post-processing steps country-by-country, area-by-area
## Loop over country
for (i in list_iso)
{
  #Update counter and show progress
  count_i = count_i+1
  print(paste0(i, " : country ", count_i, "/", max_i))
  
  #Append the log to track progress of the process on country i
  cat(paste("#####\nCOUNTRY :", i, "\n"), file = log, append = TRUE)
  
  #Load the matching frame
  print("--Loading the matching frame")
  output_load = fn_post_load_mf(iso = i, 
                           yr_min = yr_min,
                           name_input = paste0("matching_frame_spling", n_sampling),
                           ext_input = ".gpkg",
                           log = log,
                           save_dir = save_dir)
  if(output_load$is_ok == FALSE) {next} else mf_ini = output_load$mf
  
  list_pa = unique(mf_ini[mf_ini$wdpaid != 0, ]$wdpaid)
  
    #Append the log : list of PAs analyzed in the matching frame
  cat(paste("LIST OF WDPAIDs :", paste(list_pa, collapse = ", "), "\n#####\n\n"), 
      file = log, append = TRUE)
    
  #Initialization
  ##Counter
  count_j = 0
  max_j = length(list_pa)
  ##List of control and treatment pixels matched
  df_pix_matched = data.frame()
  
  #Loop over the different PAs
  for (j in list_pa)
  {
    #Update counter and show progress
    count_j = count_j+1
    print(paste0("WDPAID : ", j, " : ", count_j, "/", max_j))
    
    #Append the log to track progress of the process on PA j
    cat(paste("###\nWDPAID :", j, "\n###\n\n"), file = log, append = TRUE)
  
    mf_ini_j = mf_ini %>%
      filter(group == 1 | (group == 2 & wdpaid == j))
    
    #Add average pre-loss
    print("--Add covariate : average tree loss pre-funding")
    output_avgLoss = fn_post_avgLoss_prefund(mf = mf_ini_j, 
                                             log = log)
    if(output_avgLoss$is_ok == FALSE) {next} else mf_j = output_avgLoss$mf
    
    #Run Coarsened Exact Matching
    print("--Run CEM")
    output_cem = fn_post_match_auto(mf = mf_j, iso = i, 
                                   dummy_int = FALSE,
                                   match_method = match_method,
                                   cutoff_method = cutoff_method,
                                   is_k2k = is_k2k,
                                   k2k_method = k2k_method,
                                     th_mean = th_mean, 
                                     th_var_min = th_var_min, th_var_max = th_var_max,
                                   colname.travelTime = colname.travelTime, 
                                   colname.clayContent = colname.clayContent, 
                                   colname.elevation = colname.elevation,
                                   colname.tri = colname.tri, 
                                   colname.fcIni = colname.fcIni, 
                                   colname.flAvg = colname.flAvg,
                                   log = log)
    if(output_cem$is_ok == FALSE) {next} else out_cem_j = output_cem$out.cem
    
    #Plots : covariates
    print("--Some plots : covariates")
    print("----Covariate balance")
    output_covbal = fn_post_covbal(out.cem = out_cem_j,
                   mf = mf_j,
                   colname.travelTime = colname.travelTime, 
                   colname.clayContent = colname.clayContent,
                   colname.fcIni = colname.fcIni, 
                   colname.flAvg = colname.flAvg,
                   colname.tri = colname.tri,
                   colname.elevation = colname.elevation,
                   iso = i,
                   path_tmp = tmp_post,
                   wdpaid = j,
                   log = log,
                   save_dir = save_dir)
  if(output_covbal$is_ok == FALSE) {next}
    
    print("----Density plots")
    output_density = fn_post_plot_density(out.cem = out_cem_j,  
                                         mf = mf_j,
                                      colname.travelTime = colname.travelTime, 
                                       colname.clayContent = colname.clayContent,
                                       colname.fcIni = colname.fcIni, 
                                       colname.flAvg = colname.flAvg,
                                    colname.tri = colname.tri,
                                   colname.elevation = colname.elevation,
                                      iso = i,
                                      path_tmp = tmp_post,
                                      wdpaid = j,
                                   log = log,
                                   save_dir = save_dir)
     if(output_density$is_ok == FALSE) {next}
    
    #Panelize dataframes
    print("----Panelize (Un-)Matched Dataframe")
    output_panel = fn_post_panel(out.cem = out_cem_j, 
                                  mf = mf_j, 
                                  ext_output = ".csv", 
                                  iso = i,
                                  wdpaid = j,
                                  log = log,
                                 save_dir = save_dir)
     if(output_panel$is_ok == FALSE) {next}
    
    matched.wide.j = output_panel$matched.wide
    unmatched.wide.j = output_panel$unmatched.wide
    matched.long.j = output_panel$matched.long
    unmatched.long.j = output_panel$unmatched.long 
    
    #Extract matched units and plot them on a grid
    print("----Extract matched units and plot them on a grid")
    
    ##Extract ID of treated and control pixels
    df_pix_matched_j = matched.wide.j %>%
      st_drop_geometry() %>%
      as.data.frame() %>%
      dplyr::select(c(group, assetid)) %>%
      rename("group_matched" = "group") 
    df_pix_matched = rbind(df_pix_matched, df_pix_matched_j)
    
    ##Plot the grid with matched control and treated for the PA
    output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                      is_pa = TRUE,
                      df_pix_matched = df_pix_matched_j,
                      path_tmp = tmp_post,
                      log = log,
                      save_dir = save_dir)
     if(output_grid$is_ok == FALSE) {next}

    #Plots the evolution of forest cover for treated and control units, before and after matching
    print("----Plots again : trend")
    output_trend = fn_post_plot_trend(matched.long = matched.long.j, 
                       unmatched.long = unmatched.long.j, 
                       mf = mf_j,
                       data_pa = data_pa,
                       iso = i,
                       wdpaid = j,
                       log = log,
                       save_dir = save_dir)
    if(output_trend$is_ok == FALSE) {next}
  }
    
  # Plot the grid with matched control and treated for the country 
  output_grid = fn_post_plot_grid(iso = i, wdpaid = j,
                    is_pa = FALSE,
                    df_pix_matched = df_pix_matched,
                    path_tmp = tmp_post,
                    log = log,
                    save_dir = save_dir)
   if(output_grid$is_ok == FALSE) {next}
  
}       

#End post-processing timer
toc_post = toc()

#Append the log and save it
cat(paste("END OF POST-PROCESSING :", toc_post$callback_msg, "\n\n"),
    file = log, append = TRUE)
aws.s3::put_object(file = log,
                   bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                   region = "",
                   show_progress = FALSE)
                 
                               
#Notes on what to do next
## Automate the definition of cutoffs for CEM
### Coder 5.5.3 de Iacus et al. 2012 ? Permet de savoir le gain de matched units pour une modification des seuils d'une variable
## Allow to enter a list of any covariates to perform the matching
## Function to plot Fig. 3 in Iacus et al. 2012
## On veut ATE ou ATT ?? Je dirai ATT car on ne veut pas estimer l'effet de mettre une AP, mais l'effet des AP financés par l'AFD 
                                                                           
                               
```

<!--chapter:end:02_matching.Rmd-->

# (APPENDIX) Appendix {-}

# Functions for matching pre- and post-processing

```{r}

#####
#Functions for matching process
#####

#For each function, the aim of the function, inputs, outputs, data saved and notes are detailed. This takes the following form :
#Aim of the function
##INPUTS : the arguments needed in the function
###INPUT 1 to N
##OUTPUTS : the information returned by the function (data frames, numeric, characters, etc.) and necessary to pursue to processing
### OUTPUT 1 to N
##DATA SAVED : information put in the storage but not necessarily need to pursue the processing (figures, tables, data frames, etc.)
### ...
##NOTES : any useful remark
### ...

#Remarks :
##most functions are adapted for errors handling using base::withCallingHandlers(). Basically, the computation steps are declared in a block of withCallingHandlers function, while two other blocks specify what to do in case the first block face a warning or error. In our case, errors led to return a boolean indicating an error has occured and append the log with the error message. Warnings return a boolean but do not block the iteration. They also edit the log with the warning message.
##PA is used for "protected area(s)".
##To save plots and tables : save on temporary folder in the R session then put the saved object in the storage. Indeed print() and ggplot::ggsave() cannot write directly on s3 storage
###


#Pre-processing
###

#Create a log to track progress of the processing (warnings, errors, parameters, country and PAs analyzed, etc.)
##INPUTS :
###list_iso : the list of ISO3 code corresponding to the countries analyzed
### buffer : the buffer width in meter
### sampling : the sampling specified by the user for the smaller area in the country considered
### yr_first : the first year of the period where the analysis takes place
### yr_last : the last year of the period where the analysis takes place
### yr_min : the minimum treatment year to be considered in the analysis. As some matching covariates are defined with pre-treatment data (e.g average tree cover loss before treatment), this minimal year is greater than yr_first
### name : specify the name of the log file to save
### notes : any notes on the analysis performed
##OUTPUTS :
###log : a text file in the R session memory that will be edited through the data processing
fn_pre_log = function(list_iso, buffer, sampling, yr_first, yr_last, yr_min, name, notes)
{
  str_iso = paste(list_iso, collapse = ", ")
  log = paste(tempdir(), name, sep = "/")
  file.create(log)
  #Do not forget to end the writing with a \n to avoid warnings
  #cat(paste("#####\nCOUNTRY :", iso, "\nTIME :", print(Sys.time(), tz = "UTC-2"), "\n#####\n\n###\nPRE-PROCESSING\n###\n\n"), file = log, append = TRUE)
  cat(paste("STARTING TIME :", print(Sys.time(), tz = "UTC-2"), "\nPARAMETERS : buffer =", buffer, "m, sampling size of", sampling, ", period of analysis", yr_first, "to", yr_last, ", minimum treatment year is", yr_min, "\nCOUNTRIES :", str_iso, "\nNOTES :", notes, "\n\n##########\nPRE-PROCESSING\n##########\n\n"), file = log, append = TRUE)
  
  return(log)
}


#Find the UTM code for a given set of coordinates
##INPUTS : 
### lonlat : coordinates
##OUTPUTS : 
### UTM code
fn_lonlat2UTM = function(lonlat) 
{
  utm = (floor((lonlat[1] + 180) / 6) %% 60) + 1
  if (lonlat[2] > 0) {
    utm + 32600
  } else{
    utm + 32700
  }
  
}


#Create the gridding of a given country. 
##INPUTS : 
### iso : ISO code 
### yr_min : the minimum treatment year to be considered in the analysis. As some matching covariates are defined with pre-treatment data (e.g average tree cover loss before treatment), this minimal year is greater than the first year in the period considered
### path_tmp : temporary path for saving figures
### data_pa : dataset with information on protected areas, and especially their surfaces
### sampling : Number of pixels that subdivide the protected area with lowest area in the country considered
### log : a log file to track progress of the processing
### save_dir : saving directory
##OUTPUTS (depending on potential errors)
### gadm_prj : country shapefile 
### grid : gridding of the country
### utm_code : UTM code of the country
### gridSize : the resolution of gridding, defined from the area of the PA with the lowest area
### is_ok : a boolean indicating whether or not an error occured inside the function
##DATA SAVED :
### Gridding of the country considered
fn_pre_grid = function(iso, yr_min, path_tmp, data_pa, sampling, log, save_dir)
{
  
  output = withCallingHandlers(
    
    {
      
  # Download country polygon
  gadm = gadm(country = iso, resolution = 1, level = 0, path = path_tmp) %>% 
    st_as_sf() %>%
    st_make_valid() #Necessary for some polygons : e.g BEN
  
  # Find UTM zone of the country centroid
  centroid = st_coordinates(st_centroid(gadm))
  utm_code = fn_lonlat2UTM(centroid)
  # Reproject GADM
  gadm_prj = gadm %>% 
    st_transform(crs = utm_code)
  
  #Determine relevant grid size
  ##Select the PA in the country with minimum area. PAs with null areas, marine or treatment year before 2000 are discarded (not analyzed anyway)
  pa_min = data_pa %>%
    filter(iso3 == iso & is.na(wdpaid) == FALSE & status_yr >= yr_min & marine %in% c(0,1)) %>%
    arrange(area_km2) %>%
    slice(1)
  ##From this minimum area, define the grid size. 
  ##It depends on the sampling of the minimal area, i.e how many pixels we want to subdivide the PA with lowest area
  ## To avoid a resolution higher than the one of our data, grid size is set to be 30m at least (resolution of tree cover data, Hansen et al. 2013)
  area_min = pa_min$area_km2 #in kilometer
  gridSize = max(1e3, round(sqrt(area_min/sampling)*1000, 0)) #Side of the pixel is expressed in meter and rounded, if above 1km. 
  
  # Make bounding box of projected country polygon
  bbox = st_bbox(gadm_prj) %>% st_as_sfc() %>% st_as_sf() 
  # Make a Grid to the extent of the bounding box
  grid.ini = st_make_grid(bbox, cellsize = c(gridSize,gridSize))
  # Crop Grid to the extent of country boundary by
  # subsetting to the grid cells that intersect with the country
  grid.sub = grid.ini %>% 
    st_intersects(gadm_prj, .) %>% 
    unlist()
  # Filter the grid to the subset
  grid = grid.ini[sort(grid.sub)] %>%
    st_as_sf() %>%
    mutate(gridID = seq(1:nrow(.))) # Add id for grid cells
  
  #Extract country name
  country.name = data_pa %>% 
    filter(iso3 == iso) %>% 
    slice(1)
  country.name = country.name$country_en
  
  #Visualize and save the grid
  fig_grid = ggplot() +
    geom_sf(data = st_geometry(bbox)) +
    geom_sf(data = st_geometry(gadm_prj)) +
    geom_sf(data = st_geometry(grid), alpha = 0) +
    labs(title = paste("Gridding of", country.name))
  fig_save = paste0(path_tmp, "/fig_grid_", iso, ".png")
  ggsave(fig_save,
         plot = fig_grid,
         device = "png",
         height = 6, width = 9)
  aws.s3::put_object(file = fig_save, 
                     bucket = paste("projet-afd-eva-ap", save_dir, iso, sep = "/"), 
                     region = "", 
                     show_progress = FALSE)
  
  #Append the log 
  cat("#Generating observation units\n-> OK\n", file = log, append = TRUE)
  
  #Return outputs
  list_output = list("ctry_shp_prj" = gadm_prj, 
                     "grid" = grid, 
                     "gridSize" = gridSize, 
                     "utm_code" = utm_code,
                     "is_ok" = TRUE)
  return(list_output)
  
    },
  
  error = function(e)
  {
    #Print the error and append the log
    print(e)
    #Append the log 
    cat(paste("#Generating observation units\n-> Error :\n", e, "\n"), file = log, append = TRUE)
    #Return string to inform user to skip
    return(list("is_ok" = FALSE))
  },
  
  warning = function(w)
  {
    #Print the warning and append the log
    print(w)
    #Append the log 
    cat(paste("#Generating observation units\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
    #Return string to inform user to skip
    return(list("is_ok" = TRUE))
  }
  
  )
  
  return(output)
}

#Assign each pixel (observation unit) to a group : PA non-funded, funded and analyzed, funded and not analyzed, buffer, potential control. 
##INPUTS :
### iso : country ISO code
### path_tmp : temporary path to save figures
### utm_code : UTM of the country centroid
### buffer_m : buffer width, in meter
### data : a dataframe with the WDPAID of PAs funded by the AFD
### gadm_prj : country polygon, projected so that crs = UTM code
### grid : gridding of the country
### gridSize : resolution of the gridding
##OUTPUTS (depending on potential errors): 
### grid.param : a raster representing the gridding of the country with two layers. One for the group each pixel belongs to (funded PA, non-funded PA, potential control, buffer), the other for the WDPAID corresponding to each pixel (0 if not a PA)
### is_ok : a boolean indicating whether or not an error occured inside the function
##DATA SAVED :
### grid.param
### A plot of the country gridding with group of each pixel
### The share of PAs in the portfolio considered that are reported in the WDPA
### In the country considered, the share of PAs in the portfolio and analyzed, not analyzed or not in the portfolio
### Share of PAs reported in the WDPA and analyzed in the country considered
##NOTES :
### Errors can arise from the wdpa_clean() function, during "formatting attribute data" step. Can be settled playing with geometry_precision parameter
fn_pre_group = function(iso, wdpa_raw, status, yr_min, path_tmp, utm_code, buffer_m, data_pa, gadm_prj, grid, gridSize, log, save_dir)
{
  
  output = withCallingHandlers(
    
    {

  # The polygons of PAs are taken from WDPA, cleaned
  wdpa_prj = wdpa_raw %>%
    filter(ISO3 == iso) %>%
    #st_make_valid() %>%
    #celanign of PAs from the wdap_clean function :
    #Status filtering is performed manually juste after. 
    #The geometry precision is set to default. Used to be 1000 in Kemmeng code
    # Overlaps are not erased because we rasterize polygons
    #UNESCO Biosphere Reserves are not excluded so that our analysis of AFD portfolio is the most extensive
    wdpa_clean(retain_status = status, #NULL to remove proposed
               erase_overlaps = FALSE,
               exclude_unesco = FALSE,
               verbose = TRUE) %>% 
    # Remove the PAs that are only proposed, or have geometry type "point"
    #filter(STATUS != "Proposed") %>%  #24/08/2023 : "Proposed" status concerns only 6 PAs in the sample, including one implemented after 2000.
    filter(GEOMETRY_TYPE != "POINT") %>%
    # Project PA polygons to the previously determined UTM zone
    st_transform(crs = utm_code) 
  
  # Make Buffers around all protected areas
  buffer = st_buffer(wdpa_prj, dist = buffer_m) %>% 
    # Assign an ID "5" to the buffer group
    mutate(group=5,
           group_name = "Buffer")
  
  # Separate funded and non-funded protected areas
  ##PAs funded by AFD 
  ###... which can bu used in impact evaluation : in the country of interest, wdpaid known, area above 1km² (Wolf et al. 2021), implemented after yr_min defined by the user, non-marine (terrestrial or coastal, Wolf et al. 2021)
  pa_afd_ie = data_pa %>%
    filter(iso3 == iso & is.na(wdpaid) == FALSE & area_km2 > 1 & status_yr >= yr_min & marine %in% c(0,1))
  wdpaID_afd_ie = pa_afd_ie[pa_afd_ie$iso3 == iso,]$wdpaid
  wdpa_afd_ie = wdpa_prj %>% filter(WDPAID %in% wdpaID_afd_ie) %>%
    mutate(group=2,
           group_name = "Funded PA, analyzed") # Assign an ID "2" to the funded PA group
  ###...which cannot
  pa_afd_no_ie = data_pa %>%
    filter(iso3 == iso & (is.na(wdpaid) == TRUE | area_km2 <= 1 | is.na(area_km2) | status_yr < yr_min | marine == 2)) #PAs not in WDPA, of area less than 1km2 (Wolf et al 2020), not terrestrial/coastal or implemented after yr_min are not analyzed
  wdpaID_afd_no_ie = pa_afd_no_ie[pa_afd_no_ie$iso3 == iso,]$wdpaid 
  wdpa_afd_no_ie = wdpa_prj %>% filter(WDPAID %in% wdpaID_afd_no_ie) %>%
    mutate(group=3,
           group_name = "Funded PA, not analyzed") # Assign an ID "3" to the funded PA group which cannot be stuided in the impact evaluation
  ##PAs not funded by AFD
  wdpa_no_afd = wdpa_prj %>% filter(!WDPAID %in% c(wdpaID_afd_ie, wdpaID_afd_no_ie)) %>% 
    mutate(group=4,
           group_name = "Non-funded PA") # Assign an ID "4" to the non-funded PA group
  wdpaID_no_afd = wdpa_no_afd$WDPAID
  
  # Merge the dataframes of funded PAs, non-funded PAs and buffers
  # CAREFUL : the order of the arguments does matter. 
  ## During rasterization, in case a cell of the raster is on both funded analysed and non-funded, we want to cell to take the WDPAID of the funded analysed.
  ## Same funded, not analyzed. As the first layer is taken, wdpa_afd_ie needs to be first !
  wdpa_groups = rbind(wdpa_afd_ie, wdpa_afd_no_ie, wdpa_no_afd, buffer)
  # Subset to polygons that intersect with country boundary
  wdpa.sub = wdpa_groups %>% 
    st_intersects(gadm_prj, .) %>% 
    unlist()
  # Filter the PA+buffer to the subset
  wdpa_groups = wdpa_groups[sort(wdpa.sub),] %>%
    st_as_sf()
  
  # Initialize an empty raster to the spatial extent of the country
  r.ini = raster()
  extent(r.ini) = extent(gadm_prj)
  # Specify the raster resolution as same as the pre-defined 'gridSize'
  res(r.ini) = gridSize
  # Assign the raster pixels with "Group" values, 
  # Take the minimal value if a pixel is covered by overlapped polygons, so that PA Group ID has higher priority than Buffer ID.
  # Assign value "0" to the background pixels (control candidates group)
  # fun = "min" can lead to bad group assignment. This issue is developed and tackled below
  r.group = rasterize(wdpa_groups, r.ini, field="group", fun="min", background=0) %>%
    mask(., gadm_prj)
  # Rename Layer
  names(r.group) = "group"
  
  # Rasterize wdpaid
  ## CAREFUL : as stated above, the wdpa_groups raster is ordered so that the first layer is the one of funded, analyzed PA. Thus one needs to have fun = "first"
  r.wdpaid = rasterize(wdpa_groups, r.ini, field="WDPAID", fun="first", background=0) %>%
    mask(., gadm_prj)
  names(r.wdpaid) = "wdpaid"
  
  # Aggregate pixel values by taking the majority
  grid.group.ini = exact_extract(x=r.group, y=grid, fun='mode', append_cols="gridID") %>%
    rename(group = mode)
  grid.wdpaid = exact_extract(x=r.wdpaid, y=grid, fun="mode", append_cols="gridID") %>%
    rename(wdpaid = mode)

  # Randomly select background pixels as potential control pixels
  ##Take the list of background pixels, the  number of background and treatment pixels
  list_back_ID = grid.group.ini[grid.group.ini$group == 0 & is.na(grid.group.ini$group) == FALSE,]$gridID
  n_back_ID = length(list_back_ID)
  n_treat = length(grid.group.ini[grid.group.ini$group == 2 & is.na(grid.group.ini$group) == FALSE,]$gridID)
  ##The number of potential control units is five times the number of treatment units
  n_control = min(n_back_ID, n_treat*5)
  ##Select randomly the list of background pixels selected as controls
  ### Note that we control for the case n_back_ID = 1, which causes weird behavior using sample()
  set.seed(0) #To ensure reproductibility of the random sampling
  if(n_back_ID <= 1) list_control_ID = list_back_ID else list_control_ID = sample(x = list_back_ID, size = n_control, replace = FALSE)
  ## Finally, assign the background pixel chosen to the control group, characterized by group = 1
  grid.group = grid.group.ini %>%
    mutate(group = case_when(gridID %in% list_control_ID ~ 1,
                             TRUE ~ group))
  

  # Merge data frames
  grid.param.ini = grid.group %>%
    merge(., grid.wdpaid, by="gridID") %>%
    merge(., grid, by="gridID") %>%
    # drop rows having "NA" in column "group"
    drop_na(group) %>%
    st_as_sf() %>%
    # Grid is projected to WGS84 because mapme.biodiverty package merely works with this CRS
    st_transform(crs=4326) %>%
    #Add treatment year variable
    left_join(dplyr::select(data_pa, c(region_afd, region, sub_region, country_en, iso3, wdpaid, status_yr, year_funding_first, year_funding_all)), by = "wdpaid")
  
  # If two PAs in different groups overlap, then the rasterization with fun = "min" (as in r.group definition) can lead to bad assignment of pixels.
  # For instance, if a PA non-funded (group = 4) overlaps with a funded, analyzed one (group = 2), then the pixel will be assigned to the group 2
  # Same for group 3 (funded, not analyzed). Then, the following correction is applied.
  # Finally, each group is given a name for later plotting
  # grid.param = grid.param.ini %>%
  #   mutate(group = case_when(wdpaid %in% wdpaID_no_afd & group == 2 ~ 4,
  #                            wdpaid %in% wdpaID_afd_no_ie & group == 2 ~3,
  #                            TRUE ~ group)) %>%
  
  #/!\ For the moment, a pixel both non-funded and funded is considered funded !
  #But if funded not analyzed AND funded analyzed, then funded not analyzed.
  #Idea : the pixel could be treated out of the period considered, so not comparable to toher treatment pixels considered in funded, analyzed.
  # -> Check with Léa, Ingrid and PY if that seems OK
  grid.param = grid.param.ini %>%
    mutate(group = case_when(wdpaid %in% wdpaID_afd_no_ie & group == 2 ~ 3,
                             TRUE ~ group)) %>%
    #Add name for the group
    mutate(group_name = case_when(group == 0 ~ "Background",
                                  group == 1 ~ "Potential control",
                                  group == 2 ~ "Funded PA, analyzed (potential treatment)",
                                  group == 3 ~ "Funded PA, not analyzed",
                                  group == 4 ~ "Non-funded PA",
                                  group == 5 ~ "Buffer")) %>%
  #Add spatial resolution in m : useful to compute share of forest area in a given pixel and extrapolate to the PA for instance
  mutate(res_m = gridSize)
  
  
  #Save the grid
  s3write_using(grid.param,
                sf::write_sf,
                overwrite = TRUE,
                object = paste0(save_dir, "/", iso, "/", paste0("grid_param_", iso, ".gpkg")),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  
  # Visualize and save grouped grid cells
  
  ## Extract country name
  country.name = grid.param %>% 
    filter(group == 2) %>% 
    slice(1)
  country.name = country.name$country_en
  
  fig_grid_group = 
    ggplot(grid.param) +
    geom_sf(aes(fill = as.factor(group_name)), color = NA) +
    labs(title = paste("Gridding of", country.name)) +
    scale_fill_brewer(name = "Group", type = "qual", palette = "YlGnBu", direction = -1) +
    # scale_color_viridis_d(
    #   # legend title
    #   name="Group", 
    #   # legend label
    #   labels=c("control candidate", "treatment candidate", "non-funded PA", "buffer zone")) +
    theme_bw()
  fig_save = paste0(path_tmp, "/fig_grid_group_", iso, ".png")
  ggsave(fig_save,
         plot = fig_grid_group,
         device = "png",
         height = 6, width = 9)
  aws.s3::put_object(file = fig_save,
                     bucket = paste("projet-afd-eva-ap", save_dir, iso, sep = "/"),
                     region = "", 
                     show_progress = FALSE)
  
  
  # Pie plots
  df_pie_wdpa = data_pa %>%
    filter(iso3 == iso) %>%
    dplyr::select(c(iso3, wdpaid, name_pa, status_yr, area_km2)) %>%
    mutate(group_wdpa = case_when(is.na(wdpaid) == FALSE ~ "WDPA",
                             is.na(wdpaid) == TRUE ~ "Not WDPA")) %>%
    group_by(iso3, group_wdpa) %>%
    summarise(n = n()) %>%
    ungroup() %>%
    mutate(n_tot = sum(n),
           freq = round(n/n_tot*100, 1))
  
  df_pie_ie = wdpa_prj %>%
    st_drop_geometry() %>%
    dplyr::select(c(ISO3, WDPAID)) %>%
    mutate(group_ie = case_when(!WDPAID %in% c(wdpaID_afd_ie, wdpaID_afd_no_ie) ~ "Non-funded",
                                WDPAID %in% wdpaID_afd_ie ~ "Funded, analyzed",
                                WDPAID %in% wdpaID_afd_no_ie ~ "Funded, not analyzed")) %>%
    group_by(ISO3, group_ie) %>%
    summarise(n = n()) %>%
    ungroup() %>%
    mutate(n_tot = sum(n),
           freq = round(n/n_tot*100, 1))
  
  ## PAs funded : reported in the WDPAID or not
  pie_wdpa = ggplot(df_pie_wdpa, 
                        aes(x="", y= freq, fill = group_wdpa)) %>%
    + geom_bar(width = 0.5, stat = "identity", color="white") %>%
    + coord_polar("y", start=0) %>%
    + geom_label_repel(aes(x=1.1, label = paste0(round(freq, 1), "% (", n, ")")), 
                       color = "black", 
                       position = position_stack(vjust = 0.55), 
                       size=4, show.legend = FALSE) %>%
    # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
    #              color = "white", 
    #              position = position_stack(vjust = 0.7), size=2.5, 
    #              show.legend = FALSE) %>%
    + labs(x = "", y = "",
           title = "Share of PAs funded and reported in the WDPA",
           subtitle = paste("Sample :", sum(df_pie_wdpa$n), "funded protected areas in", country.name)) %>%
    + scale_fill_brewer(name = "", palette = "Greens") %>%
    + theme_void()
  
  ## PAs in the WDPA : analyzed or not
  pie_ie = ggplot(df_pie_ie, 
                    aes(x="", y= freq, fill = group_ie)) %>%
    + geom_bar(width = 0.5, stat = "identity", color="white") %>%
    + coord_polar("y", start=0) %>%
    + geom_label_repel(aes(x=1.1, label = paste0(round(freq, 1), "% (", n, ")")), 
                       color = "black", 
                       position = position_stack(vjust = 0.55), 
                       size=4, show.legend = FALSE) %>%
    # + geom_label(aes(x=1.4, label = paste0(freq_iucn, "%")), 
    #              color = "white", 
    #              position = position_stack(vjust = 0.7), size=2.5, 
    #              show.legend = FALSE) %>%
    + labs(x = "", y = "",
           title = "Share of PAs reported in the WDPA and analyzed",
           subtitle = paste("Sample :", sum(df_pie_ie$n), "funded protected areas in", country.name)) %>%
    + scale_fill_brewer(name = "", palette = "Greens") %>%
    + theme_void()
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  ggsave(paste(tmp, paste0("pie_funded_wdpa_", iso, ".png"), sep = "/"),
         plot = pie_wdpa,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("pie_wdpa_ie_", iso, ".png"), sep = "/"),
         plot = pie_ie,
         device = "png",
         height = 6, width = 9)
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f,
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
  
  #Append the log 
  cat("#Determining Group IDs and WDPA IDs\n-> OK\n", file = log, append = TRUE)
  
  #Return the output
  list_output = list("grid.param" = grid.param, "is_ok" = TRUE)
  return(list_output)
  
    },
  
  error = function(e)
  {
    #Print the error and append the log
    print(e)
    #Append the log 
    cat(paste("#Determining Group IDs and WDPA IDs\n-> Error :\n", e, "\n"), file = log, append = TRUE)
    #Return string to inform user to skip
    return(list("is_ok" = FALSE))
  },
  
  warning = function(w)
  {
    #Print the warning and append the log
    print(w)
    #Append the log 
    cat(paste("#Determining Group IDs and WDPA IDs\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
    #Return string to inform user to skip
    return(list("is_ok" = TRUE))
  }
  
  )
  
  #Return outputs
  return(output)
  
}



#Building a matching dataframe for the country considered : for each pixel in treated and control groups, the data needed for the analysis are downloaded and the indicators computed. Eventually a dataset is obtained that is ready to enter a matching algorithm
##INPUTS :
### grid.param : a raster representing the gridding of the country with two layers. One for the group each pixel belongs to (funded PA, non-funded PA, potential control, buffer), the other for the WDPAID corresponding to each pixel (0 if not a PA)
### path_tmp : a temporary folder to store figures
### iso : ISO code of the country of interest
### name_output : the name of the matching frame to save
### ext_output : the file extension of the matching to save 
### yr_first : the first year of the period where the analysis takes place
### yr_last : the last year of the period where the analysis takes place
### log : a log file to track progress of the processing
### save_dir : saving directory
##OUTPUTS :
### is_ok : a boolean indicating whether or not an error occured inside the function
##DATA SAVED
### pivot.all : a dataframe with variables of interest (outcome, matching covariates) for all treated and potential control pixels

fn_pre_mf_parallel = function(grid.param, path_tmp, iso, name_output, ext_output, yr_first, yr_last, log, save_dir) 
{
  output = tryCatch(
    
    {
  tic = tic()
  
  print("----Initialize portfolio")
  # Take only potential control (group = 1) and treatment (group = 2) in the country gridding to lower the number of computations to perform
  grid.aoi = grid.param %>%
    filter(group %in% c(1,2))
  # Create a mapme.biodiversity portfolio for the area of interest (aoi). This specifies the period considered and the geospatial units where data are downloaded and indicators computed (here, the treated and control pixels in the country gridding)
  aoi = init_portfolio(grid.aoi,
                       years = yr_first:yr_last,
                       outdir = path_tmp,
                       add_resources = FALSE)
  
  #Extract a dataframe with pixels ID in the grid and the portfolio : useful for latter plotting of matched control and treated units. 
  df_gridID_assetID = aoi %>%
    st_drop_geometry() %>%
    as.data.frame() %>%
    dplyr::select(c(gridID, assetid))
  s3write_using(df_gridID_assetID,
                data.table::fwrite,
                object = paste0(save_dir, "/", iso, "/", "df_gridID_assetID_", iso, ".csv"),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  
  print("----Download data")
  # Download Data
  ## Version of Global Forest Cover data to consider
  list_version_gfc = mapme.biodiversity:::.available_gfw_versions() #all versions available
  version_gfc = list_version_gfc[length(list_version_gfc)] #last version considered
  ## Soil characteristics
  dl.soil = get_resources(aoi, 
                          resources = c("soilgrids"), 
                          layers = c("clay"), # resource specific argument
                          depths = c("0-5cm"), # resource specific argument
                          stats = c("mean"))
  ## Accessibility
  dl.travelT = get_resources(aoi, resources = "nelson_et_al",
                             range_traveltime = c("5k_110mio"))
  ## Tree cover evolution on the period
  dl.tree = get_resources(aoi, 
                          resources = c("gfw_treecover", "gfw_lossyear"),
                          vers_treecover = version_gfc,
                          vers_lossyear = version_gfc)
  ## Elevation
  dl.elevation = get_resources(aoi, "nasa_srtm")
  ## Terrain Ruggedness Index
  dl.tri = get_resources(aoi, "nasa_srtm")
  
  print("----Compute indicators")
  #Compute indicators
  
  #Begin multisession : use of parallel computing (computations performed in separate R sessions in background) to speed up the computations of indicators
  # gc : optimize memory management for the background sessions.
  # Multisession with workers = 6 as in mapme.biodiversity tutorial : https://mapme-initiative.github.io/mapme.biodiversity/articles/quickstart.html?q=parall#enabling-parallel-computing
  # Careful to the format of command to call parallel computations here : VALUE TO COMPUTE %<-% {EXPRESSION}.
  plan(multisession, workers = 6, gc = TRUE)
  with_progress({
    get.soil %<-% {calc_indicators(dl.soil,
                                indicators = "soilproperties",
                                stats_soil = c("mean"),
                                engine = "exactextract")} # the "exactextract" engine is chosen as it is the faster one for large rasters (https://tmieno2.github.io/R-as-GIS-for-Economists/extraction-speed-comparison.html)

    get.travelT  %<-% {calc_indicators(dl.travelT,
                                  indicators = "traveltime",
                                  stats_accessibility = c("mean"),  #Note KfW use "median" here, but for no specific reason a priori (mail to Kemmeng Liu, 28/09/2023). Mean is chosen coherently with the other covariates, though we could test in a second time whether this changes anything to the results.
                                  engine = "exactextract")}

    get.tree  %<-% {calc_indicators(dl.tree,
                               indicators = "treecover_area",
                               min_size=0.5, # FAO definition of forest :  Minimum treecover = 10%, minimum size =0.5 hectare (FAO 2020 Global Fores Resources Assessment, https://www.fao.org/3/I8661EN/i8661en.pdf)
                               min_cover=10)}
  
    get.elevation %<-% {calc_indicators(dl.elevation,
                      indicators = "elevation",
                      stats_elevation = c("mean"),
                      engine = "exactextract")}
    
    get.tri %<-% {calc_indicators(dl.tri,
                      indicators = "tri",
                      stats_tri = c("mean"),
                      engine = "exactextract")}
    
    })
  
  print("----Build indicators' datasets")
  #Build indicators' datasets
  ## Transform the output dataframe into a -ore convenient format
  data.soil = unnest(get.soil, soilproperties) %>%
    #mutate(across(c("mean"), \(x) round(x, 3))) %>% # Round numeric columns --> rounding before the matching algorithm is irrelevant to me
    pivot_wider(names_from = c("layer", "depth", "stat"), values_from = "mean") %>%
    rename("clay_0_5cm_mean" = "clay_0-5cm_mean") %>%
    mutate(clay_0_5cm_mean = case_when(is.nan(clay_0_5cm_mean) ~ NA,
                                       TRUE ~ clay_0_5cm_mean))
  
  data.travelT = unnest(get.travelT, traveltime) %>%
    pivot_wider(names_from = "distance", values_from = "minutes_median", names_prefix = "minutes_median_") %>%
    mutate(minutes_median_5k_110mio = case_when(is.nan(minutes_median_5k_110mio) ~ NA,
                                       TRUE ~ minutes_median_5k_110mio))
  
  data.tree = unnest(get.tree, treecover_area) %>%
    drop_na(treecover) %>% #get rid of units with NA values 
    #mutate(across(c("treecover"), \(x) round(x, 3))) %>% # Round numeric columns
    pivot_wider(names_from = "years", values_from = "treecover", names_prefix = "treecover_")
  
  data.tri = unnest(get.tri, tri) %>%
    mutate(tri_mean = case_when(is.nan(tri_mean) ~ NA,
                                TRUE ~ tri_mean))
  
  data.elevation = unnest(get.elevation, elevation) %>%
    mutate(elevation_mean = case_when(is.nan(elevation_mean) ~ NA,
                                TRUE ~ elevation_mean))
  
  ## End parallel plan : close parallel sessions, so must be done once indicators' datasets are built
  plan(sequential)
  
  # The calculation of tree loss area is performed at dataframe base
  # Get the column names of tree cover time series
  colnames_tree = names(data.tree)[startsWith(names(data.tree), "treecover")]
  # Drop the first year
  dropFirst = tail(colnames_tree, -1)
  # Drop the last year
  dropLast = head(colnames_tree, -1)
  # Set list of new column names for tree loss time series
  colnames_loss = dropFirst %>% str_split(., "_")
  
  # Add new columns: treeloss_tn = treecover_tn - treecover_t(n-1)  
  for (i in 1:length(dropFirst)) 
  {
    new_colname = paste0("treeloss_", colnames_loss[[i]][2]) 
    data.tree[[new_colname]] = data.tree[[dropFirst[i]]] - data.tree[[dropLast[i]]]
  }
  
  print("----Export Matching Frame")
  # Remove "geometry" column from dataframes
  df.tree = data.tree %>% mutate(x = NULL) %>% as.data.frame()
  df.travelT = data.travelT %>% mutate(x = NULL) %>% as.data.frame()
  df.soil = data.soil %>% mutate(x = NULL) %>% as.data.frame()
  df.elevation = data.elevation %>% mutate(x = NULL) %>% as.data.frame()
  df.tri = data.tri %>% mutate(x=NULL) %>% as.data.frame()
  
  # Make a dataframe containing only "assetid" and geometry
  # Use data.soil instead of data.tree, as some pixels are removed in data.tree (NA values from get.tree)
  df.geom = data.soil[, c("assetid", "x")] %>% as.data.frame() 
  
  # Merge all output dataframes 
  pivot.all = Reduce(dplyr::full_join, list(df.travelT, df.soil, df.tree, df.elevation, df.tri, df.geom)) %>%
    st_as_sf()

  # Make column Group ID and WDPA ID have data type "integer"
  pivot.all$group = as.integer(pivot.all$group)
  pivot.all$wdpaid = as.integer(pivot.all$wdpaid)

  # Save this matching dataframe
  name_save = paste0(name_output, "_", iso, ext_output)
  s3write_using(pivot.all,
                sf::st_write,
                object = paste0(save_dir, "/", iso, "/", name_save),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  
  #Removing files in the temporary folder
  do.call(file.remove, list(list.files(tmp_pre, include.dirs = F, full.names = T, recursive = T)))
  
  #End timer
  toc = toc()
  
  #Append the log
  cat(paste("#Calculating outcome and other covariates\n-> OK :", toc$callback_msg, "\n\n"), file = log, append = TRUE)

  #Return the output
  return(list("is_ok" = TRUE))
  
    },
  
  error = function(e)
  {
    #Print the error and append the log
    print(e)
    #Append the log 
    cat(paste("#Calculating outcome and other covariates\n-> Error :\n", e, "\n\n"), file = log, append = TRUE)
    #Return string to inform user to skip
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("#Calculating outcome and other covariates\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  
  return(output)
}


#####
###Post-processing
#####


#Load the matching dataframe obtained during pre-processing
##INPUTS :
### iso : the ISO code of the country considered
### name_input : name of the file to import
### ext_output : extension fo the file to import
### yr_min : the minimum treatment year to be considered in the analysis. As some matching covariates are defined with pre-treatment data (e.g average tree cover loss before treatment), this minimal year is greater than the first year in the period considered
### log : a log file to track progress of the processing
### save_dir : saving directory
##OUTPUTS :
### mf : matching dataframe. More precisely, it gives for each observation units in a country values of different covariates to perform matching.
### is_ok : a boolean indicating whether or not an error occured inside the function
##DATA SAVED
### The list of PAs in the matching frame, characterized by their WDPAID. Useful to loop over each PAs we want to analyze in a given country
fn_post_load_mf = function(iso, yr_min, name_input, ext_input, log, save_dir)
{
  output = tryCatch(
    
    {
      
  #Load the matching dataframe
  object = paste(save_dir, iso, paste0(name_input, "_", iso, ext_input), sep = "/")
  mf = s3read_using(sf::st_read,
                      bucket = "projet-afd-eva-ap",
                      object = object,
                      opts = list("region" = "")) 
  
  #Subset to control and treatment units with year of treatment >= yr_min
  mf = mf %>%
    filter(group==1 | group==2) %>%
    #Remove observations with NA values only for covariates :
    ## except for creation year, funding years, geographical location, country ISO and name, pixel resolution which are NA for control units
    drop_na(-c(status_yr, year_funding_first, year_funding_all, region_afd, region, sub_region, iso3, country_en, res_m)) #%>%
     #filter(status_yr >= yr_min | is.na(status_yr))
  
  #Write the list of PAs matched
  list_pa = mf %>%
    st_drop_geometry() %>%
    as.data.frame() %>%
    dplyr::select(c(region_afd, region, sub_region, country_en, iso3, wdpaid, status_yr, year_funding_first, year_funding_all)) %>%
    mutate(iso3 = iso, .before = "wdpaid") %>%
    filter(wdpaid != 0) %>%
    group_by(wdpaid) %>%
    slice(1) %>%
    ungroup()
  
  s3write_using(list_pa,
                data.table::fwrite,
                bucket = "projet-afd-eva-ap",
                object = paste(save_dir, iso, paste0("list_pa_matched_", iso, ".csv"), sep = "/"),
                opts = list("region" = ""))
  
  #Append the log
  cat("Loading the matching frame -> OK\n", file = log, append = TRUE)
  
  #Return output
  return(list("mf" = mf, "is_ok" = TRUE))
  
    },
  
  error = function(e)
  {
    print(e)
    cat(paste("Error in loading the matching frame :\n", e, "\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("Warining while loading the matching frame :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  
  )
  
  return(output)
}


#Compute average forest loss before PA creation, and add it to the matching frame as a covariate
##INPUTS : 
### mf : the matching dataframe
### colname.flAvg : name of the average forest loss variable
### log : a log file to track progress of the processing
## OUTPUTS :
### mf : matching frame with the new covariate
### is_ok : a boolean indicating whether or not an error occured inside the function

fn_post_avgLoss_prefund = function(mf, colname.flAvg, log)
{
  
  output = tryCatch(
    
    {
      
  #Extract treatment year
  treatment.year = mf %>% 
    filter(group == 2) %>% 
    slice(1)
  treatment.year = treatment.year$status_yr
  
  #Extract first year treeloss is computed
  ##Select cols with "treeloss" in mf, drop geometry, replace "treeloss_" by "", convert to num and take min
  treeloss.ini.year = mf[grepl("treeloss", names(mf))] %>%
    st_drop_geometry() %>%
    names() %>%
    gsub(paste0("treeloss", "_"), "", .) %>%
    as.numeric() %>%
    min()
  
  #Define period to compute average loss
  ##If 5 pre-treatment periods are available at least, then average pre-treatment deforestation is computed on this 5 years range
  ## If less than 5 are available, compute on this restricted period
  ## Note that by construction, treatment.year >= treeloss.ini.year +1 (as yr_min = yr_first+2 in the parameters)
  if((treatment.year-treeloss.ini.year) >=5)
  {yr_start = (treatment.year)-5
  yr_end = (treatment.year)-1} else if((treatment.year-treeloss.ini.year <5) & (treatment.year-treeloss.ini.year >0))
  {yr_start = treeloss.ini.year
  yr_end = (treatment.year)-1} 
  #Transform it in variable suffix
  var_start = yr_start - 2000
  var_end = yr_end - 2000
  #Select only relevant variables
  df_fl = mf[grepl("treeloss", names(mf))][var_start:var_end] %>% 
    st_drop_geometry()
  #Compute average loss for each pixel and store it in mf. Also add the start and end years of pre-treatment period where average loss is computed.
  mf$avgLoss_pre_fund = round(rowMeans(df_fl), 2)
  mf$start_pre_fund = yr_start
  mf$end_pre_fund = yr_end
  #Remove NA values
  mf = mf %>% drop_na(avgLoss_pre_fund)
  
  #Append the log
  cat("#Add average pre-treatment treecover loss\n-> OK\n", file = log, append = TRUE)
  
  #Return output
  return(list("mf" = mf, "is_ok" = TRUE))
  
    },
  
  error = function(e)
  {
    print(e)
    cat(paste("#Add average pre-treatment treecover loss\n-> Error :\n", e, "\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("#Add average pre-treatment treecover loss\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  
  return(output)
}


#Perform matching of treated and potential control units. 
##INPUTS :
### mf : the matching dataframe
### iso : the ISO code of the country considered
### dummy_int : should we consider the interaction of variables for matching ? Is recommended generally speaking (https://cran.r-project.org/web/packages/MatchIt/vignettes/assessing-balance.html). When using CEM matching, variables are binned then exact matching is performed on binned values. As a first approximation we can argue that if two units have the same binned values for two variables, then they likely have the same binned interaction value. It is not necessarily true though, as binned(A)*binned(B) can be different from binned(A*B).  
### match_method : the matching method to use. See https://cran.r-project.org/web/packages/MatchIt/vignettes/matching-methods.html for a list of matching methods we can use with the MatchIT package 
### cutoff_method : the method to use for automatic histogram binning of the variables. See Iacus, King and Porro 2011 (https://gking.harvard.edu/files/political_analysis-2011-iacus-pan_mpr013.pdf), 5.5.1, or MathIT documentation. "Sturges" tend to have the best outcomes (number of matched units) in our case (Antoine Vuillot, 28/09/2023)
### is_k2k : boolean. Should we use k2k matching ? If yes, each treated unit is eventually matched with a single control. For CEM matching, a treated unit is potentially associated with more than one control unit (exact matching on binned variables), and then the "closest' one is chosen with a metric defined in k2k_method
### k2k_method : metric to use to choose the closest control among the control units matched with a treated unit in CEM matching.
### th_mean :the maximum acceptable value for absolute standardized mean difference of covariates between matched treated and control units. Typically 0.1 (https://cran.r-project.org/web/packages/MatchIt/vignettes/assessing-balance.html) or 0.25 in conservation literature (e.g https://conbio.onlinelibrary.wiley.com/doi/abs/10.1111/cobi.13728) 
### th_var_min, th_var_max : the range of acceptable value for covariate variance ratio between matched treated and control units. Typicall 0.5 and 2, respectively (https://cran.r-project.org/web/packages/MatchIt/vignettes/assessing-balance.html)
### colname.travelTime, colname.clayContent, colname.elevation, colname.tri, colname.fcIni, colname.flAvg : name of the matching covariates
### log : a log file to track progress of the processing
##OUTPUTS : 
### out.cem : an object with all information on matching (parameters, results, etc.)
### df.cov.m : for each matching covariate, statistics to assess the quality of the match
### is_ok : a boolean indicating whether or not an error occured inside the function
##NOTES
### The matching method chosen is CEM though other exists. For a presentation of the different matching algorithms, see https://cran.r-project.org/web/packages/MatchIt/vignettes/matching-methods.html
fn_post_match_auto = function(mf,
                              iso,
                              dummy_int,
                              match_method,
                              cutoff_method,
                              is_k2k,
                              k2k_method,
                              th_mean, 
                              th_var_min, th_var_max,
                              colname.travelTime, colname.clayContent, colname.elevation, colname.tri, colname.fcIni, colname.flAvg,
                              log)
{

  #Append the log file : CEM step
  cat("#Run Coarsened Exact Matching\n", 
      file = log, append = TRUE)
  
  ## Matching handling errors due to absence of matching
  output = 
    tryCatch(
    {
      # Formula
      formula = eval(bquote(group ~ .(as.name(colname.travelTime)) 
                            + .(as.name(colname.clayContent))  
                            +  .(as.name(colname.fcIni)) 
                            + .(as.name(colname.flAvg))
                            + .(as.name(colname.tri))
                            + .(as.name(colname.elevation))))
      
      #Try to perform matching
      out.cem = matchit(formula,
                        data = mf,
                        method = match_method,
                        cutpoints = cutoff_method,
                        k2k = is_k2k,
                        k2k.method = k2k_method)
      
      # Then the performance of the matching is assessed, based on https://cran.r-project.org/web/packages/MatchIt/vignettes/assessing-balance.html
      ## Covariate balance : standardized mean difference and variance ratio
      ## For both tests and the joint one, a dummy variable is defined, with value TRUE is the test is passed
      df.cov.m = summary(out.cem, interactions = dummy_int)$sum.matched %>%
        as.data.frame() %>%
        clean_names() %>%
        mutate(is_var_ok = var_ratio < th_var_max & var_ratio > th_var_min, #Check variance ratio between treated and controls
               is_mean_ok = abs(std_mean_diff) < th_mean, #Check absolute standardized mean difference
               is_bal_ok = as.logical(is_var_ok*is_mean_ok), #Binary : TRUE if both variance and mean difference check pass, 0 if at least one does not
               .after = "std_mean_diff")
      
      #Add a warning if covariate balance tests are not passed
      if(sum(df.cov.m$is_bal_ok) < nrow(df.cov.m) | is.na(sum(df.cov.m$is_bal_ok)) == TRUE)
      {
        message("Matched control and treated units are not balanced enough. Increase sample size, turn to less restrictive tests or visually check balance.")
        cat("-> Careful : matched control and treated units are not balanced enough. Increase sample size, turn to less restrictive tests or visually check balance.\n", 
            file = log, append = TRUE)
      }
      
      #Append the log : note the step has already been appended at the beginning of the function
      cat("-> OK\n", file = log, append = TRUE)
      
      return(list("out.cem" = out.cem, "df.cov.m" = df.cov.m, "is_ok" = TRUE))
      
    },
    
    error=function(e)
    {
      print(e)
      cat(paste("-> Error :\n", e, "\n"), file = log, append = TRUE)
      return(list("is_ok" = FALSE))
    },
    
    warning = function(w)
    {
      #Print the warning and append the log
      #Append the log 
      cat(paste("-> Warning :\n", w, "\n"),
          file = log, append = TRUE)
      return(list("is_ok" = FALSE)) #Here warning comes from an absence of matching : thus must skip to next country
    }
    
  )
  
  return(output)
  
}
    


#Plot covariates balance (plots and summary table)
## INPUTS :
### out.cem : list of results from the CEM matching
### mf : the matching dataframe
### colname.travelTime, colname.clayContent, colname.elevation, colname.tri, colname.fcIni, colname.flAvg : name of the matching covariates
### iso : ISO code of the country considered
### path_tmp : temporary folder to store figures
### wdpaid : the WDPA ID of the protected area considered
### log : a log file to track progress of the processing
### save_dir : saving directory
##OUTPUTS :
### is_ok : a boolean indicating whether or not an error occured inside the function
## DATA SAVED :
### A covariate love plot
### A table with number of treated and control units, before and after matching
### A table with statistics on matched control and treated units 
### A table with statistics on unmatched control and treated units,
fn_post_covbal = function(out.cem, mf, 
                          colname.travelTime, colname.clayContent, colname.fcIni, colname.flAvg, colname.tri, colname.elevation, 
                          iso, path_tmp, wdpaid, log,
                          save_dir)
{
  
  output = tryCatch(
    
    {
      
  #Save summary table from matching
  smry_cem = summary(out.cem)
  tbl_cem_nn = smry_cem$nn
  tbl_cem_m = smry_cem$sum.matched
  tbl_cem_all = smry_cem$sum.all
  
  #Extract country name
  country.name = mf %>% 
    filter(group == 2) %>% 
    slice(1)
  country.name = country.name$country_en
  
  #Extract start and end years of pre-treatment period where average loss is computed
  year.start.prefund = mf %>%
    filter(group == 2) %>% 
    slice(1)
  year.start.prefund = year.start.prefund$start_pre_fund
  
  year.end.prefund = mf %>%
    filter(group == 2) %>% 
    slice(1)
  year.end.prefund = year.end.prefund$end_pre_fund
  
  #Plot covariate balance
  colname.flAvg.new = paste0("Avg. Annual Forest \n Loss ",  year.start.prefund, "-", year.end.prefund)
  c_name = data.frame(old = c(colname.travelTime, colname.clayContent, colname.tri, colname.elevation,
                              colname.fcIni, colname.flAvg),
                      new = c("Accessibility", "Clay Content", "Terrain Ruggedness Index (TRI)", "Elevation (m)", "Forest Cover in 2000",
                              colname.flAvg.new))
  
  # Refer to cobalt::love.plot()
  # https://cloud.r-project.org/web/packages/cobalt/vignettes/cobalt.html#love.plot
  fig_covbal = love.plot(out.cem, 
                       binary = "std", 
                       abs = TRUE,
                       #thresholds = c(m = .1),
                       var.order = "unadjusted",
                       var.names = c_name,
                       title = paste0("Covariate balance for WDPA ID ", wdpaid, " in ", country.name),
                       sample.names = c("Discarded", "Selected"),
                       wrap = 25 # at how many characters does axis label break to new line
  )
  # Finetune Layouts using ggplot
  fig_covbal + 
    geom_vline(aes(xintercept=0.1, linetype="Acceptable \n Balance \n (x=0.1)"), color=c("#2ecc71"), linewidth=0.35) +
    theme_bw() +
    theme(
      plot.title = element_text(family="Arial Black", size=16, hjust=0.5),
      
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      legend.spacing.x = unit(0.5, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      
      axis.text.x = element_text(angle = 20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=12),
      axis.title=element_text(size=14),
      axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
      axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.3, linetype = 2)
    ) + guides(linetype = guide_legend(override.aes = list(color = "#2ecc71"))) # Add legend for geom_vline
  

  #Saving files
  
  ggsave(paste0(path_tmp, "/CovBal/fig_covbal", "_", iso, "_", wdpaid, ".png"),
         plot = fig_covbal,
         device = "png",
         height = 6, width = 9)
  print(xtable(tbl_cem_nn, type = "latex"),
        file = paste0(path_tmp, "/CovBal/tbl_cem_nn", "_", iso, "_", wdpaid, ".tex"))
  print(xtable(tbl_cem_m, type = "latex"),
        file = paste0(path_tmp, "/CovBal/tbl_cem_m", "_", iso, "_", wdpaid, ".tex"))
  print(xtable(tbl_cem_all, type = "latex"),
        file = paste0(path_tmp, "/CovBal/tbl_cem_all", "_", iso, "_", wdpaid, ".tex"))
  
  #Export to S3 storage
  ##List of files to save in the temp folder
  files <- list.files(paste(path_tmp, "CovBal", sep = "/"), full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(paste(path_tmp, "CovBal", sep = "/"), full.names = TRUE)))
  
  #Append the log
  cat("#Plot covariates balance\n->OK\n", file = log, append = TRUE)
  
  return(list("is_ok" = TRUE))
  
    },
  
  error=function(e)
  {
    print(e)
    cat(paste("#Plot covariates balance\n-> Error :\n", e, "\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("#Plot covariates balance\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  
  return(output)

}


#Density plots of covariates for control and treatment units, before and after matching
## INPUTS :
### out.cem : list of results from the CEM matching
### mf : the matching dataframe
### colname.travelTime, colname.clayContent, colname.elevation, colname.tri, colname.fcIni, colname.flAvg : name of the matching covariates
### iso : ISO code of the country considered
### path_tmp : temporary folder to store figures
### wdpaid : the WDPA ID of the protected area considered
### log : a log file to track progress of the processing
### save_dir : saving directory
## OUTPUTS :
### is_ok : a boolean indicating whether or not an error occured inside the function
## DATA SAVED :
### Density plots of the matching covariates considered, for matched treated and control units
fn_post_plot_density = function(out.cem, mf, 
                                colname.travelTime, colname.clayContent, colname.fcIni, colname.flAvg, colname.tri, colname.elevation, 
                                iso, path_tmp, wdpaid, log, save_dir)
{
  output = tryCatch(
    
    {
      
  # Define Facet Labels
  fnl = c(`Unadjusted Sample` = "Before Matching",
          `Adjusted Sample` = "After Matching")
  
  #Extract country name
  country.name = mf %>% 
    filter(group == 2) %>% 
    slice(1)
  country.name = country.name$country_en
  
  #Define plots
  ## Density plot for Travel Time
  fig_travel = bal.plot(out.cem, 
                      var.name = colname.travelTime,
                      #sample.names = c("Control", "Treatment"),
                      which = "both") +
    facet_wrap(.~which, labeller = as_labeller(fnl)) +
    #scale_fill_viridis(discrete = T) +
    scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
    labs(title = "Distributional balance for accessibility",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         x = "Accessibility (min)",
         fill = "Group") +
    theme_bw() +
    theme(
      plot.title = element_text(family="Arial Black", size=16, hjust = 0),
      
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      legend.spacing.x = unit(0.5, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      
      axis.text=element_text(size=12),
      axis.title=element_text(size=14),
      axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
      axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),
      
      strip.text.x = element_text(size = 12) # Facet Label
    )
  
  ## Density plot for Clay Content
  fig_clay = bal.plot(out.cem, 
                    var.name = colname.clayContent,
                    which = "both") +
    facet_wrap(.~which, labeller = as_labeller(fnl)) +
    #scale_fill_viridis(discrete = T) +
    scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
    labs(title = "Distributional balance for clay content",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         x = "Clay content at 0~20cm soil depth (%)",
         fill = "Group") +
    theme_bw() +
    theme(
      plot.title = element_text(family="Arial Black", size=16, hjust=0),
      
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      legend.spacing.x = unit(0.5, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      
      axis.text=element_text(size=12),
      axis.title=element_text(size=14),
      axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
      axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),
      
      strip.text.x = element_text(size = 12) # Facet Label
    )
  
  ## Density plot for Elevation
  fig_elevation = bal.plot(out.cem,
                      var.name = colname.elevation,
                      which = "both") +
      facet_wrap(.~which, labeller = as_labeller(fnl)) +
      #scale_fill_viridis(discrete = T) +
      scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
      labs(title = "Distributional balance for elevation",
           subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
           x = "Elevation (m)",
           fill = "Group") +
      theme_bw() +
      theme(
          plot.title = element_text(family="Arial Black", size=16, hjust=0),
          legend.title = element_blank(),
          legend.text=element_text(size=14),
          legend.spacing.x = unit(0.5, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),

          axis.text=element_text(size=12),
          axis.title=element_text(size=14),
          axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
          axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),

          strip.text.x = element_text(size = 12) # Facet Label
      )
  
  ## Density plot for TRI
  fig_tri = bal.plot(out.cem,
                      var.name = colname.tri,
                      which = "both") +
      facet_wrap(.~which, labeller = as_labeller(fnl)) +
      #scale_fill_viridis(discrete = T) +
      scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
      labs(title = "Distributional balance for Terrain Ruggedness Index (TRI)",
          subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
           x = "TRI",
           fill = "Group") +
      theme_bw() +
      theme(
          plot.title = element_text(family="Arial Black", size=16, hjust=0),

          legend.title = element_blank(),
          legend.text=element_text(size=14),
          legend.spacing.x = unit(0.5, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),

          axis.text=element_text(size=12),
          axis.title=element_text(size=14),
          axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
          axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),

          strip.text.x = element_text(size = 12) # Facet Label
      )
  
  ## Density plot for covariate "forest cover 2000"
  fig_fc = bal.plot(out.cem, 
                  var.name = colname.fcIni,
                  which = "both") +
    facet_wrap(.~which, labeller = as_labeller(fnl)) +
    scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
    # scale_x_continuous(trans = "log10") +
    labs(title = "Distributional balance for forest cover in 2000",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         x = "Forest cover (ha)",
         fill = "Group") +
    theme_bw() +
    theme(
      plot.title = element_text(family="Arial Black", size=16, hjust=0),
      
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      legend.spacing.x = unit(0.5, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      
      axis.text=element_text(size=12),
      axis.title=element_text(size=14),
      axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
      axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),
      
      strip.text.x = element_text(size = 12) # Facet Label
    )
  
  ## Density plot for covariate "avg. annual forest loss prior funding"
  fig_fl = bal.plot(out.cem, 
                  var.name = colname.flAvg,
                  which = "both") +
    facet_wrap(.~which, labeller = as_labeller(fnl)) +
    #scale_fill_viridis(discrete = T) +
    scale_fill_manual(labels = c("Control", "Treatment"), values = c("#f5b041","#5dade2")) +
    labs(title = "Distributional balance for average pre-treatment forest loss",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         x = "Forest loss (%)",
         fill = "Group") +
    theme_bw() +
    theme(
      plot.title = element_text(family="Arial Black", size=16, hjust=0),
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      legend.spacing.x = unit(0.5, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      
      axis.text=element_text(size=12),
      axis.title=element_text(size=14),
      axis.title.y = element_text(margin = margin(unit = 'cm', r = 0.5)),
      axis.title.x = element_text(margin = margin(unit = 'cm', t = 0.5)),
      
      strip.text.x = element_text(size = 12) # Facet Label
    )
  
  #Saving plots
  
  tmp = paste(tempdir(), "fig", sep = "/")
  ggsave(paste(tmp, paste0("fig_travel_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_travel,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_clay_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_clay,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_elevation_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_elevation,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_tri_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_tri,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_fc_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_fc,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_fl_dplot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_fl,
         device = "png",
         height = 6, width = 9)
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
  
  #Append the log
  cat("#Plot covariates density\n->OK\n", file = log, append = TRUE)
  
  return(list("is_ok" = TRUE))
  
    },
  
  error=function(e)
  {
    print(e)
    cat(paste("#Plot covariates density\n-> Error :\n", e, "\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("#Plot covariates density\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  
  return(output)
  
}


#Define panel datasets (long, wide format) for control and treatment observation units, before and after matching.
## INPUTS :
### out.cem : list of results from the CEM matching
### mf : the matching dataframe
### ext_output : extension fo the file to import
### iso : ISO code of the country considered
### wdpaid : the WDPA ID of the protected area considered
### log : a log file to track progress of the processing
### save_dir : saving directory
## OUTPUTS :
### a list of dataframes : (un)matched.wide/long. They contain covariates and outcomes for treatment and control units, before and after matching, in a wide or long format
### is_ok : a boolean indicating whether or not an error occured inside the function
## DATA SAVED
### (un)matched.wide/long dataframes. They contain covariates and outcomes for treatment and control units, before and after matching, in a wide or long format

fn_post_panel = function(out.cem, mf, ext_output, wdpaid, iso, log, save_dir)
{
  
  output = tryCatch(
    
    {
      
  # Convert dataframe of matched objects to pivot wide form
  matched.wide = match.data(object=out.cem, data=mf)
  
  # Pivot Wide ==> Pivot Long
  matched.long = matched.wide %>%
    dplyr::select(c(region_afd, region, sub_region, country_en, iso3, group, wdpaid, status_yr, year_funding_first, year_funding_all, assetid, weights, starts_with("treecover"), res_m)) %>%
    pivot_longer(cols = c(starts_with("treecover")),
                 names_to = c("var", "year"),
                 names_sep = "_",
                 values_to = "fc_ha")
  
  # Pivot wide Dataframe of un-matched objects
  unmatched.wide = mf
  
  # Pivot Wide ==> Pivot Long
  unmatched.long = unmatched.wide %>%
    dplyr::select(c(region_afd, region, sub_region, iso3, country_en, group, wdpaid, status_yr, year_funding_first, year_funding_all, assetid, starts_with(treecover), res_m)) %>%
    pivot_longer(cols = c(starts_with(treecover)),
                 names_to = c("var", "year"),
                 names_sep = "_",
                 values_to = "fc_ha")
  
  #Save the dataframes
  s3write_using(matched.wide,
                sf::st_write,
                object = paste0(save_dir, "/", iso, "/", wdpaid, "/", paste0("matched_wide", "_", iso, "_", wdpaid, ext_output)),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  s3write_using(unmatched.wide,
                sf::st_write,
                object = paste0(save_dir, "/", iso, "/", wdpaid, "/", paste0("unmatched_wide", "_", iso, "_", wdpaid, ext_output)),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  s3write_using(matched.long,
                sf::st_write,
                object = paste0(save_dir, "/", iso, "/", wdpaid, "/", paste0("matched_long", "_", iso, "_", wdpaid, ext_output)),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  s3write_using(unmatched.long,
                sf::st_write,
                object = paste0(save_dir, "/", iso, "/", wdpaid, "/", paste0("unmatched_long", "_", iso, "_", wdpaid, ext_output)),
                bucket = "projet-afd-eva-ap",
                opts = list("region" = ""))
  
  #Append the log
  cat("#Panelize dataframe\n-> OK\n", file = log, append = TRUE)
  
  #Return outputs
  list_output = list("matched.wide" = matched.wide, "matched.long" = matched.long,
                     "unmatched.wide" = unmatched.wide, "unmatched.long" = unmatched.long,
                     "is_ok" = TRUE)
  return(list_output)
  
    },
  
  error=function(e)
{
  print(e)
  cat(paste("#Panelize dataframe\n-> Error :\n", e, "\n"), file = log, append = TRUE)
  return(list("is_ok" = FALSE))
}

# warning = function(w)
# {
#   #Print the warning and append the log
#   print(w)
#   #Append the log 
#   cat(paste("#Panelize dataframe\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
#   #Return string to inform user to skip
#   return(list("is_ok" = TRUE))
# }

  )
  
  return(output)
  
}   

#Plot the average trend of control and treated units in a given country, before and after the matching
## INPUTS :
### (un)matched.long : dataframe with covariates and outcomes for each treatment and control unit, before and after matching, in a long format (one row : pixel+year)
### mf : the matching dataframe
### data_pa : dataframe with information on each PA considered in the analysis
### iso : ISO code of the country considered
### wdpaid : the WDPA ID of the protected area considered
### log : a log file to track progress of the processing
### save_dir : saving directory
## OUTPUTS : 
### is_ok : a boolean indicating whether or not an error occured inside the function
## DATA SAVED :
### Evolution of forest cover in a treated and control pixel on average, before and after matching
### Same for total forest cover (pixel*# of pixels in the PA)
### Cumulated deforestation relative to 2000 forest cover, in treated and control pixels, before and after matching
fn_post_plot_trend = function(matched.long, unmatched.long, mf, data_pa, iso, wdpaid, log, save_dir) 
{
    
  output = tryCatch(
    
    {
      #First extract some relevant information
      #Extract spatial resolution of pixels res_m and define pixel area in ha
      res_m = unique(mf$res_m)
      res_ha = res_m^2*1e-4
        
      #Extract treatment year
      treatment.year = mf %>% 
        filter(group == 2) %>% 
        slice(1)
      treatment.year = treatment.year$status_yr
      
      #Extract funding years
      funding.years = mf %>% 
        filter(group == 2) %>% 
        slice(1)
      funding.years = funding.years$year_funding_first
      #funding.years = as.numeric(unlist(strsplit(funding.years$year_funding_all, split = ",")))
      
      #Extract country name
      country.name = mf %>% 
        filter(group == 2) %>% 
        slice(1)
      country.name = country.name$country_en
      
      ##Area of the PA
      wdpa_id = wdpaid #Need to give a name to wdpaid (function argument) different from the varaible in the dataset (wdpaid)
      area_ha = data_pa[data_pa$wdpaid == wdpa_id,]$area_km2*100
      
      #Extract number of pixels in the PA
      #n_pix_pa = length(unique(filter(unmatched.long, group == 2)$assetid))
      n_pix_pa = area_ha/res_ha #This measure is imperfect for extrapolation of total deforestation avoided, as part of a PA can be coastal. Indeed, this extrapolation assumes implicitly that all the PA is covered by forest potentially deforested in absence of the conservation 
      
     #Open a multisession for dataframe computations
      #Note the computations on unmatched units are the slowest here due to the number of observations relatively higher than for matched units
      plan(multisession, gc = TRUE, workers = 6)
      with_progress({
 
  # Make dataframe for plotting trend
  ## Matched units
  df.matched.trend  %<-% {matched.long %>%
    #First, compute deforestation relative to 2000 for each pixel (deforestation as computed in Wolf et al. 2021)
    group_by(assetid) %>%
    mutate(FL_2000_cum = (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100) %>%
    ungroup() %>%
    #Then compute the average forest cover and deforestation in each year, for treated and control groups
    #Standard deviation and 95% confidence interval is also computed for each variable
    group_by(group, year) %>%
    summarise(n = n(),
              avgFC = mean(fc_ha, na.rm=TRUE), #Compute average forest cover in a pixel, its sd and ci
              sdFC = sd(fc_ha, na.rm = TRUE),
              ciFC_low = avgFC - qt(0.975,df=n-1)*sdFC/sqrt(n),
              ciFC_up = avgFC + qt(0.975,df=n-1)*sdFC/sqrt(n),
              avgFC_tot = n_pix_pa*mean(fc_ha, na.rm=TRUE), #Compute total average forest cover, sd and CI
              sdFC_tot = n_pix_pa*sdFC,
              ciFC_tot_low = avgFC_tot - qt(0.975,df=n-1)*sdFC_tot/sqrt(n),
              ciFC_tot_up = avgFC_tot + qt(0.975,df=n-1)*sdFC_tot/sqrt(n),
              avgFL_2000_cum = mean(FL_2000_cum, na.rm = TRUE), #Compute average forest loss relative to 2000 (Wolf et al 2021), sd and CI
              sdFL_2000_cum = sd(FL_2000_cum, na.rm = TRUE),
              ciFL_low = avgFL_2000_cum - qt(0.975,df=n-1)*sdFL_2000_cum/sqrt(n),
              ciFL_up = avgFL_2000_cum + qt(0.975,df=n-1)*sdFL_2000_cum/sqrt(n),
              matched = TRUE) %>%
    ungroup() %>%
    st_drop_geometry() }
  
  ##Unmatched
  df.unmatched.trend  %<-% {unmatched.long %>%
      #First, compute deforestation relative to 2000 for each pixel (deforestation as computed in Wolf et al. 2021); compute percentage of forest cover in the pixel in 2000
      group_by(assetid) %>%
      mutate(FL_2000_cum = (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100) %>%
      ungroup() %>% #Compute average percentage of FC in a pixel in 2000, for each group. Compute also standard deviation
    #Then compute the average forest cover, average forest cover percentage, and deforestation in each year, for treated and control groups
    #Standard deviation and 95% confidence interval is also computed for each variable
    group_by(group, year) %>%
    summarise(n = n(),
              avgFC = mean(fc_ha, na.rm=TRUE), #Compute average forest cover in a pixel, its sd and ci
              sdFC = sd(fc_ha, na.rm = TRUE),
              ciFC_low = avgFC - qt(0.975,df=n-1)*sdFC/sqrt(n),
              ciFC_up = avgFC + qt(0.975,df=n-1)*sdFC/sqrt(n),
              avgFC_tot = n_pix_pa*mean(fc_ha, na.rm=TRUE), #Compute total average forest cover, sd and CI
              sdFC_tot = n_pix_pa*sdFC,
              ciFC_tot_low = avgFC_tot - qt(0.975,df=n-1)*sdFC_tot/sqrt(n),
              ciFC_tot_up = avgFC_tot + qt(0.975,df=n-1)*sdFC_tot/sqrt(n),
              avgFL_2000_cum = mean(FL_2000_cum, na.rm = TRUE), #Compute average forest loss relative to 2000 (Wolf et al 2021), sd and CI
              sdFL_2000_cum = sd(FL_2000_cum, na.rm = TRUE),
              ciFL_low = avgFL_2000_cum - qt(0.975,df=n-1)*sdFL_2000_cum/sqrt(n),
              ciFL_up = avgFL_2000_cum + qt(0.975,df=n-1)*sdFL_2000_cum/sqrt(n),
              matched = FALSE) %>%
      #Compute total forest cover loss, knowing area of the PA and average forest cover in 2000 in treated pixels
    ungroup() %>%
    st_drop_geometry() }
  
      })
  
  df.trend = rbind(df.matched.trend, df.unmatched.trend)
     
  
  #Close multisession
  plan(sequential)
  
  #Plot
  ## Change Facet Labels
  fct.labs <- c("Before Matching", "After Matching")
  names(fct.labs) <- c(FALSE, TRUE)
  
  ## Trend Plot for unmatched data
  ### Average forest cover in a pixel
  fig_trend_unm_fc_pix = ggplot(data = df.trend, aes(x = year, y = avgFC)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFC_low, ymax = ciFC_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) + 
    scale_color_hue(labels = c("Control", "Treatment")) +
    facet_wrap(matched~., ncol = 2, #scales = 'free_x',
               labeller = labeller(matched = fct.labs)) +
    labs(title = "Evolution of forest cover in a pixel on average (unmatched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals.\nThe protected area has a surface of", format(area_ha, big.mark  = ","), "ha and pixels have a resolution of", res_ha, "ha."),
         x = "Year", y = "Forest cover (ha)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
      ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  ### Total forest cover
  fig_trend_unm_fc_tot = ggplot(data = df.trend, aes(x = year, y = avgFC_tot)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFC_tot_low, ymax = ciFC_tot_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) +
    scale_color_hue(labels = c("Control", "Treatment")) +
    facet_wrap(matched~., ncol = 2, #scales = 'free_x',
               labeller = labeller(matched = fct.labs)) +
    labs(title = "Evolution of total forest cover (unmatched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals. The protected area has a surface of", format(area_ha, big.mark = ","), "ha.\nTotal forest cover is extrapolated from average pixel forest cover, multiplied by the number of pixel in the protected area."),
         x = "Year", y = "Forest cover (ha)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
    ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  ### Cumulative deforestation relative to 2000
  fig_trend_unm_defo = ggplot(data = df.trend, aes(x = year, y = avgFL_2000_cum)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFL_low, ymax = ciFL_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) +
    scale_color_hue(labels = c("Control", "Treatment")) +
    facet_wrap(matched~., ncol = 2, #scales = 'free_x',
               labeller = labeller(matched = fct.labs)) +
    labs(title = "Cumulated deforestation relative to 2000 (unmatched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals. The protected area has a surface of", format(area_ha, big.mark = ","), "ha."),
         x = "Year", y = "Forest loss relative to 2000 (%)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
    ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  
  # Trend Plot for matched data
  ### Average forest cover in a pixel
  fig_trend_m_fc_pix = ggplot(data = df.matched.trend, aes(x = year, y = avgFC)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFC_low, ymax = ciFC_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) + 
    scale_color_hue(labels = c("Control", "Treatment")) +
    labs(title = "Evolution of forest cover in a pixel on average (matched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals.\nThe protected area has a surface of", format(area_ha, big.mark  = ","), "ha and pixels have a resolution of", res_ha, "ha."),
         x = "Year", y = "Forest cover (ha)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
    ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  ### Total forest cover
  fig_trend_m_fc_tot = ggplot(data = df.matched.trend, aes(x = year, y = avgFC_tot)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFC_tot_low, ymax = ciFC_tot_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) +
    scale_color_hue(labels = c("Control", "Treatment")) +
    labs(title = "Evolution of total forest cover (matched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals. The protected area has a surface of", format(area_ha, big.mark = ","), "ha.\nTotal forest cover is extrapolated from average pixel forest cover, multiplied by the number of pixel in the protected area."),
         x = "Year", y = "Total forest cover (ha)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
    ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  ### Cumulative deforestation relative to 2000
  fig_trend_m_defo = ggplot(data = df.matched.trend, aes(x = year, y = avgFL_2000_cum)) +
    geom_line(aes(group = group, color = as.character(group))) +
    geom_point(aes(color = as.character(group))) +
    geom_ribbon(aes(ymin = ciFL_low, ymax = ciFL_up, group = group, fill = as.character(group)), alpha = .1, show.legend = FALSE) +
    geom_vline(aes(xintercept=as.character(treatment.year), size="Treatment year"), linetype=1, linewidth=0.5, color="orange") +
    geom_vline(aes(xintercept=as.character(funding.years), size="Funding year"), linetype=2, linewidth=0.5, color="grey30") +
    scale_x_discrete(breaks=seq(2000,2020,5), labels=paste(seq(2000,2020,5))) +
    scale_color_hue(labels = c("Control", "Treatment")) +
    labs(title = "Cumulated deforestation relative to 2000 (matched units)",
         subtitle = paste0("Protected area in ", country.name, ", WDPAID ", wdpaid),
         caption = paste("Ribbons represent 95% confidence intervals. The protected area has a surface of", format(area_ha, big.mark = ","), "ha."),
         x = "Year", y = "Forest loss relative to 2000 (%)", color = "Group") +
    theme_bw() +
    theme(
      axis.text.x = element_text(angle = -20, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11),
      axis.title=element_text(size=14),
      
      plot.caption = element_text(hjust = 0),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=14),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      
      panel.grid.major.x = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey', linewidth = 0.2, linetype = 2),
      
      strip.text.x = element_text(size = 12) # Facet Label
    ) +
    guides(size = guide_legend(override.aes = list(color = c("grey30", "orange")))) # Add legend for geom_vline
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  
  ggsave(paste(tmp, paste0("fig_trend_unmatched_avgFC_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_unm_fc_pix,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_trend_matched_avgFC_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_m_fc_pix,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, paste0("fig_trend_unmatched_avgFC_tot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_unm_fc_tot,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_trend_matched_avgFC_tot_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_m_fc_tot,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, paste0("fig_trend_unmatched_avgFL_cum_2000_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_unm_defo,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_trend_matched_avgFL_cum_2000_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_trend_m_defo,
         device = "png",
         height = 6, width = 9)
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
  
  #Append the log
  cat("#Plot matched and unmatched trends\n-> OK\n\n", file = log, append = TRUE)
  
  return(list("is_ok" = TRUE))
  
    },
  
  error=function(e)
  {
    print(e)
    cat(paste("#Plot matched and unmatched trends\n-> Error :\n", e, "\n\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   #Append the log 
  #   cat(paste("#Plot matched and unmatched trends\n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   #Return string to inform user to skip
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  return(output)
  
}


# Plot the country grid with matched control and treated, for a given protected area (PA) or all protected areas in a country
##INPUTS
### iso : the ISO3 code of the country considered
### wdpaid : the WDPA ID of the PA considered
### is_pa : logical, whether the plotted grid is for a unique PA or all the PAs in the country considered
### df_pix_matched : dataframe with ID of matched pixels (ID from mapme.biodiversity portfolio)
### path_tmp : temporary folder to store figures
### log : a log file to track progress of the processing
### save_dir : saving directory
##OUTPUTS
### is_ok : a boolean indicating whether or not an error occured inside the function
##DATA SAVED
### Country grid with matched control and treated, for a given protected area (PA) or all protected areas in a country
fn_post_plot_grid = function(iso, wdpaid, is_pa, df_pix_matched, path_tmp, log, save_dir)
{
  
  output = tryCatch(
    
    {
      
  #Import dataframe where each pixel in the grid has both its grid ID and asset ID from the portfolio creation
  df_gridID_assetID = s3read_using(data.table::fread,
                                   object = paste0(save_dir, "/", iso, "/", paste0("df_gridID_assetID_", iso, ".csv")),
                                   bucket = "projet-afd-eva-ap",
                                   opts = list("region" = ""))
  
  #Importing the gridding of the country (funded and analyzed PAs, funded not analyzed PAs, non-funded PAs, buffer, control)
  #Merge with a dataframe so that each pixel in the grid has both its grid ID and asset ID from the portfolio creation
  #Merge with matched pixels dataframe
  grid =  s3read_using(sf::read_sf,
                       object = paste0(save_dir, "/", iso, "/", paste0("grid_param_", iso, ".gpkg")),
                       bucket = "projet-afd-eva-ap",
                       opts = list("region" = "")) %>%
    left_join(df_gridID_assetID, by = "gridID") %>%
    left_join(df_pix_matched, by = "assetid") %>%
    mutate(group_plot = case_when(group_matched == 1 ~ "Control (matched)",
                                  group_matched == 2 ~ "Treatment (matched)",
                                  TRUE ~ group_name))
  
  #Extract country name
  country.name = grid %>% 
    filter(group == 2) %>% 
    slice(1)
  country.name = country.name$country_en
  
  # Visualize and save grouped grid cells
  fig_grid = 
    ggplot(grid) +
    #The original gridding as a first layer
    geom_sf(aes(fill = as.factor(group_plot)), color = NA) +
    scale_fill_brewer(name = "Group", type = "qual", palette = "BrBG", direction = 1) +
    labs(title = paste("Gridding of", country.name, ": matched units"),
         subtitle = ifelse(is_pa == TRUE,
                            yes = paste("Focus on WDPAID", wdpaid),
                            no = "All protected areas analyzed")) +
    theme_bw()
  
  fig_save = ifelse(is_pa == TRUE,
                    yes = paste0(path_tmp, "/fig_grid_group_", iso, "_matched_", wdpaid, ".png"),
                    no = paste0(path_tmp, "/fig_grid_group_", iso, "_matched_all", ".png"))
  ggsave(fig_save,
         plot = fig_grid,
         device = "png",
         height = 6, width = 9)
  aws.s3::put_object(file = fig_save, 
                     bucket = ifelse(is_pa == TRUE,
                                     yes = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                                     no = paste("projet-afd-eva-ap", save_dir, iso, sep = "/")),
                     region = "", 
                     show_progress = FALSE)
  
  #Append the log
  if(is_pa == TRUE)
  {
    cat("#Plot the grid with matched control and treated for the PA \n-> OK\n", file = log, append = TRUE)
  } else cat("#Plot the grid with matched control and treated for all PAs in the country \n-> OK\n", file = log, append = TRUE)

  
  return(list("is_ok" = TRUE))
  
    },
  
  error = function(e)
  {
    print(e)
    if(is_pa == TRUE)
    {
      cat(paste("#Plot the grid with matched control and treated for the PA \n-> Error :\n", e, "\n"), file = log, append = TRUE)
    } else cat(paste("#Plot the grid with matched control and treated for all the PAs in the country \n-> Error :\n", e, "\n"), file = log, append = TRUE)
    return(list("is_ok" = FALSE))
  }
  
  # warning = function(w)
  # {
  #   #Print the warning and append the log
  #   print(w)
  #   if(is_pa == TRUE)
  #   {
  #     cat(paste("#Plot the grid with matched control and treated for the PA \n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   } else cat(paste("#Plot the grid with matched control and treated for all the PAs in the country \n-> Warning :\n", w, "\n"), file = log, append = TRUE)
  #   return(list("is_ok" = TRUE))
  # }
  
  )
  
  return(output)
}


```

# Functions for difference-in-difference computations

```{r}
#####
#Functions to perform difference-in-difference and plot results
#####

#For each function, the aim of the function, inputs, outputs, data saved and notes are detailed. This takes the following form :
#Aim of the function
##INPUTS : the arguments needed in the function
###INPUT 1 to N
##OUTPUTS : the information returned by the function (data frames, numeric, characters, etc.) and necessary to pursue to processing
### OUTPUT 1 to N
##DATA SAVED : information put in the storage but not necessarily need to pursue the processing (figures, tables, data frames, etc.)
### ...
##NOTES : any useful remark
### ...

#Remarks :
##most functions are adapted for errors handling using base::withCallingHandlers(). Basically, the computation steps are declared in a block of withCallingHandlers function, while two other blocks specify what to do in case the first block face a warning or error. In our case, errors led to return a boolean indicating an error has occured and append the log with the error message. Warnings return a boolean but do not block the iteration. They also edit the log with the warning message.
##PA is used for "protected area(s)".
##To save plots and tables : save on temporary folder in the R session then put the saved object in the storage. Indeed print() and ggplot::ggsave() cannot write directly on s3 storage
###


#Load the list of PA matched during the matchign process
##INPUTS :
### iso : the ISO code of the country considered
##OUTPUTS :
### list_pa : a dataframe with the PA matched
### is_ok : a boolean indicating whether or not an error occured inside the function
fn_did_list_pa = function(iso, load_dir)
{
  output = tryCatch(
    
    {
      
  list_pa = s3read_using(data.table::fread,
                         bucket = "projet-afd-eva-ap",
                         object = paste(load_dir, iso, paste0("list_pa_matched_", iso, ".csv"), sep = "/"),
                         opts = list("region" = ""))
  list_pa = unique(list_pa$wdpaid)
  
  return(list("list_pa" = list_pa, "is_ok" = TRUE))
    },
  
  error = function(e)
  {
    print(e)
    #cat(paste("Error in loading the list of protected areas :\n", e, "\n"), file = log, append = TRUE)
    print(paste("Error in loading the list of protected areas :\n", e, "\n"))
    return(list("is_ok" = FALSE))
  }
  
  )
  
  return(output)
}


#For a protected area, compute annual deforestation rates à la Wolf et al. 2021, before and after treatment
## INPUTS 
### iso : the iso3 code for the country considered
### wdpaid : the WDPAID of the PA considered
### alpha : the margin of error to define confidence interval
### load_dir : a path to load matching frame
### ext_output : the output extension
## OUTPUTS
### df_fl_annual_wolf : a dataframe with statistics on annual deforestation in matched treated and control units, computed à la Wolf et al. 2021
### is_ok : a boolean indicating whether or not an error occured inside the function 
fn_fl_wolf = function(iso, wdpaid, alpha, load_dir, ext_input)
{
  output = tryCatch(
    
    {
      
  #Import matched units
  df_long = s3read_using(data.table::fread,
                           object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("matched_long", "_", iso, "_", wdpaid, ext_input)),
                           bucket = "projet-afd-eva-ap",
                           opts = list("region" = "")) %>%
    dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, res_m, year, var, fc_ha))
  #select(c(region, country_en, iso3, wdpaid, group, status_yr, year_funding_first, year_funding_all, year, var, fc_ha))
  
  ##Extract country iso
  country.iso = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  country.iso = country.iso$iso3
  
  ##Extract region name
  region.name = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  region.name = region.name$region
  
  #Compute annual deforestation rates à la Wolf et al. 2021 before and after treatment for treated, and for all the period for controls. This is averaged across pixels.
  df_fl_annual_wolf = df_long %>%
    mutate(treatment_year = case_when(group == 1 ~0,
                                      group == 2 ~status_yr), #Set treatment year to 0 for control units (required by did::att_gt)
           time = ifelse(group == 2, yes = year-treatment_year, no = NA),
           .after = status_yr) %>%
    group_by(assetid) %>%
    # mutate(FL_2000_cum = (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100,
    #        fc_2000 = fc_ha[year == 2000]) %>%
    mutate(FL_annual_wolf_pre = ifelse(group == 2, yes = ((fc_ha[time == -1]/fc_ha[year == 2000])^(1/(year[time == -1] - 2000))-1)*100, no = NA),
           FL_annual_wolf_post = ifelse(group == 2, yes = ((fc_ha[time == max(time)]/fc_ha[time == 0])^(1/max(time))-1)*100, no = NA),
           FL_annual_wolf_tot = ((fc_ha[year == 2021]/fc_ha[year == 2000])^(1/(2021-2000))-1)*100) %>%
    slice(1) %>%
    ungroup() %>%
    group_by(group) %>%
    summarize(avgFL_annual_wolf_pre = mean(FL_annual_wolf_pre, na.rm = TRUE),
              avgFL_annual_wolf_post = mean(FL_annual_wolf_post, na.rm = TRUE),
              avgFL_annual_wolf_tot = mean(FL_annual_wolf_tot, na.rm = TRUE),
              medFL_annual_wolf_pre = median(FL_annual_wolf_pre, na.rm = TRUE),
              medFL_annual_wolf_post = median(FL_annual_wolf_post, na.rm = TRUE),
              medFL_annual_wolf_tot = median(FL_annual_wolf_tot, na.rm = TRUE),
              sdFL_annual_wolf_pre = sd(FL_annual_wolf_pre, na.rm = TRUE),
              sdFL_annual_wolf_post = sd(FL_annual_wolf_post, na.rm = TRUE),
              sdFL_annual_wolf_tot = sd(FL_annual_wolf_tot, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(region = region.name, iso3 = country.iso, wdpaid = wdpaid, .before = "group") %>%
    mutate(group = case_when(group == 1 ~ "Control",
                             group == 2 ~ "Treated"))
  
  return(list("df_fl_annual_wolf" = df_fl_annual_wolf, "is_ok" = TRUE))
    },
  
  error = function(e)
  {
    print(e)
    #cat(paste("Error while computing annual deforestation à la Wolf et al. 2021 :\n", e, "\n"), file = log, append = TRUE)
    print(paste("Error while annual deforestation à la Wolf et al. 2021 :\n", e, "\n"))
    return(list("is_ok" = FALSE))
  }
  
  )
}

#Compute the treatment effect for a given protected area that is supported by the AFD. This function specifically includes information related to funding we obtain from AFD internal services.
## INPUTS : 
### iso : the iso3 code for the country considered
### wdpaid : the WDPAID of the PA considered
### data_pa : dataset with information on protected areas, and especially their surfaces
### data_fund : information on funding from AFD internal datasets, on AFD funded projects related to protected areas.
### data_report : list of projects related to protected areas in AFD, reported by technical departments
### alpha : the threshold for confidence interval
### is_m : boolean stating whether we compute treatment effects from matched (TRUE) or unmatched treated and control units (FALSE)
### save_dir : the saving directory in the remote storage
### load_dir : the loading directory in the remote storage
### ext_input : the extension of input dataframe
## OUTPUTS :
### df_fc_attgt : treatment effect computed for the protected area considered, expressed in avoided deforestation (hectare)
### df_fl_attgt : treatment effect computed for the protected area considered, expressed in change of deforestation rate
### is_ok : a boolean indicating whether or not an error occured inside the function 
## DATA SAVED :
### Dynamic treatment effects : avoided deforestation in an average pixel (in ha), avoided deforestation relative to 2000 forest cover, avoided deforestation extrapolated to the entire protected area (in ha), change in deforestation rate (in percentage points)
fn_did_att_afd = function(iso, wdpaid, data_pa, data_fund, data_report, alpha, is_m, load_dir, ext_input, save_dir)
{
  
  output = tryCatch(
    
    {
      
  #Loading matched and unmatched datasets
  df_long_m = s3read_using(data.table::fread,
                           object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("matched_long", "_", iso, "_", wdpaid, ext_input)),
                           bucket = "projet-afd-eva-ap",
                           opts = list("region" = "")) %>%
    dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, res_m, year, var, fc_ha))
  #dplyr::select(c(region, country_en, iso3, wdpaid, group, status_yr, year_funding_first, year_funding_all, year, var, fc_ha))
  
  df_long_unm = s3read_using(data.table::fread,
                             object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("unmatched_long", "_", iso, "_", wdpaid, ext_input)),
                             bucket = "projet-afd-eva-ap",
                             opts = list("region" = "")) %>%
    dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, year, res_m, var, fc_ha))
  #dplyr::select(c(region, country_en, iso3, wdpaid, group, status_yr, year_funding_first, year_funding_all, year, var, fc_ha))
  
  # Define the working datasets depending on the is_m value
  if(is_m == TRUE)
  {
    df_long = df_long_m
  } else{df_long = df_long_unm 
  }
  
  #Extract some relevant variables for later plots and treatment effect computations
  ##Extract spatial resolution of pixels res_m and define pixel area in ha
  res_m = unique(df_long$res_m)
  res_ha = res_m^2*1e-4
  
  ##Extract treatment year
  treatment.year = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  treatment.year = treatment.year$status_yr
  
  ##Extract funding years
  df_fund_yr = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  funding.years = df_fund_yr$year_funding_first
  list.funding.years = df_fund_yr$year_funding_all
  
  ##Extract country name
  # country.name = df_long %>% 
  #   filter(group == 2) %>% 
  #   slice(1)
  # country.name = country.name$country_en
  
  ##Extract country iso
  country.iso = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  country.iso = country.iso$iso3
  
  ##Extract region name
  region.name = df_long %>% 
    filter(group == 2) %>% 
    slice(1)
  region.name = region.name$region
  
  ##Extract more information not in the matched dataframe
  ### Area
  wdpa_id = wdpaid #Need to give a name to wdpaid (function argument) different from the varaible in the dataset (wdpaid)
  area_ha = data_pa[data_pa$wdpaid == wdpa_id,]$area_km2*100
  ### Name of the PA
  pa.name = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  pa.name = pa.name$name_pa
  ### Country name
  country.name = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  country.name = country.name$country_en
  ### AFD project ID
  # id.project = data_pa %>% 
  #   filter(wdpaid == wdpa_id) %>% 
  #   slice(1)
  # id.project = id.project$id_projet
  ### WDPA status
  status.wdpa = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  status.wdpa = status.wdpa$status
  ### IUCN category and description
  iucn.wdpa = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  iucn.cat = iucn.wdpa$iucn_cat
  iucn.des = iucn.wdpa$iucn_des_en
  ### Ecosystem
  eco.wdpa = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  eco.wdpa = eco.wdpa$marine
  ### Governance
  gov.wdpa = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  gov.wdpa = gov.wdpa$gov_type
  ### Owner
  own.wdpa = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  own.wdpa = own.wdpa$own_type
  
  ## Extract information on funding
  ### Type of funding
  fund.type = data_fund %>%
    filter(id_projet == id.project) %>%
    slice(1)
  fund.type = fund.type$libelle_produit
  ### Cofunders
  cofund = data_fund %>%
    filter(id_projet == id.project) %>%
    slice(1)
  cofund = cofund$cofinanciers
  ### KfW ?
  kfw = data_fund %>%
    filter(id_projet == id.project) %>%
    slice(1)
  kfw = kfw$kfw
  ### FFEM ?
  ffem = data_fund %>%
    filter(id_projet == id.project) %>%
    slice(1)
  ffem = ffem$ffem

  ## Extract reporting department
  reporter = data_report %>%
    filter(wdpaid == wdpa_id & id_projet == id.project & nom_ap == pa.name) %>%
    slice(1)
  reporter = reporter$auteur_entree
  
  #Extract number of pixels in the PA
  #n_pix_pa = length(unique(filter(df_long_unm, group == 2)$assetid))
  n_pix_pa = area_ha/res_ha
  
  #Average forest cover in a treated pixel in 2000
  ## For matched 
  avgFC_2000_m = df_long_m %>% 
    filter(group == 2 & year == 2000) 
  avgFC_2000_m = mean(avgFC_2000_m$fc_ha, na.rm = TRUE)
  ## For unmatched
  avgFC_2000_unm = df_long_unm %>% 
    filter(group == 2 & year == 2000) 
  avgFC_2000_unm = mean(avgFC_2000_unm$fc_ha, na.rm = TRUE)
  
  #Then modify the dataframe before difference-in-difference computations
  ## Set treatment year = 0 for controls (necessary for did package to consider "never treated" units)
  ## Compute cumulative deforestation relative to 2000 forest cover (outcome where TE is computed)
  df_did = df_long %>%
    mutate(treatment_year = case_when(group == 1 ~0,
                                      group == 2 ~status_yr), #Set treatment year to 0 for control units (required by did::att_gt)
           time = ifelse(group == 2, yes = year-treatment_year, no = NA),
           .after = status_yr) %>%
    group_by(assetid) %>%
    # mutate(FL_2000_cum = (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100,
    #        fc_2000 = fc_ha[year == 2000]) %>%
    mutate(FL_2000_cum = case_when(fc_ha[year == 2000] > 0 ~ (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100, 
                                   TRUE ~ NA)) %>%
    ungroup()
  

  ##Average forest cover in 2000 in a pixel, and average share of forest cover in a pixel
  # fc_2000_avg = mean(df_did[df_did$group == 2,]$fc_2000, na.rm = TRUE)
  # per_fc_2000_avg = min(fc_2000_avg/res_ha, 1) #Take the min as in some cases, reported forest cover is higher than pixel area
  
  #Compute dynamic treatment effect with did package. 
  ## Control are "never treated" units, no covariate is added in the regression estimated with doubly-robust method
  ## standard errors are computed with bootstrap, and confidence intervals computed from it.
  ## No clustering is performed as it does not seem relevant in our case (https://blogs.worldbank.org/impactevaluations/when-should-you-cluster-standard-errors-new-wisdom-econometrics-oracle)
  ## Pseudo treatment effects are computed for each pre-treatment year (varying base period)
  
  ##For forest cover (ha and %)
  ### treatment effect computation
  fc_attgt = did::att_gt(yname = "fc_ha",
                         gname = "treatment_year",
                         idname = "assetid",
                         tname = "year",
                         control_group = "nevertreated", #Thsi corresponds to control pixels as defined in the matching , with treatment year set to 0
                         xformla = ~1,
                         alp = alpha, #For 95% confidence interval
                         allow_unbalanced_panel = TRUE, #Ensure no unit is dropped, though every pixel should have data for all years in the period
                         bstrap=TRUE, #Compute bootstrap CI
                         biters = 1000, #The number of bootstrap iteration, 1000 is default
                         cband = TRUE, #Compute CI
                         clustervars = NULL, #No clustering seems relevant to me 
                         base_period = "varying",
                         data = df_did,
                         print_details = F)
  ##For change in deforestation rate (percentage points)
  ### treatment effect computation
  fl_attgt = did::att_gt(yname = "FL_2000_cum",
                         gname = "treatment_year",
                         idname = "assetid",
                         tname = "year",
                         control_group = "nevertreated", #Thsi corresponds to control pixels as defined in the matching , with treatment year set to 0
                         xformla = ~1,
                         alp = alpha, #For 95% confidence interval
                         allow_unbalanced_panel = TRUE, #Ensure no unit is dropped, though every pixel should have data for all years in the period
                         bstrap=TRUE, #Compute bootstrap CI
                         biters = 1000, #The number of bootstrap iteration, 1000 is default
                         cband = TRUE, #Compute CI
                         clustervars = NULL, #No clustering seems relevant to me
                         base_period = "varying",
                         data = df_did,
                         print_details = F)
  
  
  ### Report results in a dataframe
  ### The computed is at pixel level
  ### This treatment effect is aggregated to protected area by multiplying treatment effect by the number of pixel in the PA. It is also expressed in percentage of pixel area (avoided deforestation in share of pixel area)
  ### confidence intervals (at pixel level) are computed from bootstrap standard errors after a coefficient is applied.
  ### This computation takes the one from did:::summary.MP function, line 15 and 16. 
  ### They are multiplied by the number of pixels to compute confidence intervals for treatment effect at protected area level 
  ### They are divided by the pixel area to compute CI for treatment effect in percentage of pixel area
  df_fc_attgt = data.frame("treatment_year" = fc_attgt$group,
                           "year" = fc_attgt$t,
                           "att_pix" = fc_attgt$att,
                           "c" = fc_attgt$c,
                           "se" = fc_attgt$se,  
                           "n" = fc_attgt$n) %>%
    #Compute treatment effect at PA level and in share of pixel area
    ## att_pa : the total avoided deforestation is the avoided deforestation in ha in a given pixel, multiplied by the number of pixel in the PA.
    ## att_per : avoided deforestation in a pixel, as a share of average forest cover in 2000 in matched treated. Can be extrapolated to full PA in principle (avoided deforestation in share of 2000 forest cover)
    mutate(att_pa = att_pix*n_pix_pa,
           att_per = att_pix/avgFC_2000_m*100) %>% 
    #Compute time relative to treatment year
    mutate(time = year - treatment_year,
           .before = year) %>%
    #Compute confidence intervals
    mutate(cband_lower_pix = round(att_pix-c*se, 4),
           cband_upper_pix = round(att_pix+c*se, 4),
           cband_lower_pa = cband_lower_pix*n_pix_pa,
           cband_upper_pa = cband_upper_pix*n_pix_pa,
           cband_lower_per = cband_lower_pix/avgFC_2000_m*100,
           cband_upper_per = cband_upper_pix/avgFC_2000_m*100,
           sig = sign(cband_lower_pix) == sign(cband_upper_pix),
           sig_5 = ifelse(max(time) >=5, yes = sig[time == 5] == TRUE, no = NA),
           sig_10 = ifelse(max(time) >= 10, yes = sig[time == 10] == TRUE, no = NA),
           sig_end = sig[time == max(time)] == TRUE,
           alpha = alpha) %>%
    #Add relevant information
    mutate(region = region.name,
           country_en = country.name,
           iso3 = country.iso,
           name_pa = pa.name,
           wdpaid = wdpaid,
           res_ha = res_ha,
           id_projet = id.project,
           status_wdpa = status.wdpa,
           iucn_cat = iucn.cat,
           iucn_des_en = iucn.des,
           gov_type = gov.wdpa,
           own_type = own.wdpa,
           marine = eco.wdpa,
           cofund = cofund,
           kfw = kfw,
           ffem = ffem,
           fund_type = fund.type,
           dept_report = reporter,
           funding_year = funding.years,
           funding_year_list = list.funding.years,
           .before = "treatment_year")
  
  # Same for change in deforestation rate
  df_fl_attgt = data.frame("treatment_year" = fl_attgt$group,
                           "year" = fl_attgt$t,
                           "att" = fl_attgt$att,
                           "c" = fl_attgt$c,
                           "se" = fl_attgt$se,
                           "n" = fl_attgt$n) %>%
    #Compute time relative to treatment year
    mutate(time = year - treatment_year,
           .before = year) %>%
    mutate(cband_lower = round(att-c*se, 4),
           cband_upper = round(att+c*se, 4),
           sig = sign(cband_lower) == sign(cband_upper),
           sig_5 = ifelse(max(time) >=5, yes = sig[time == 5] == TRUE, no = NA),
           sig_10 = ifelse(max(time) >= 10, yes = sig[time == 10] == TRUE, no = NA),
           sig_end = sig[time == max(time)] == TRUE,
           alpha = alpha) %>%
    #Compute time relative to treatment year
    mutate(time = year - treatment_year,
           .before = year) %>%
    #Add relevant information
    mutate(region = region.name,
           country_en = country.name,
           iso3 = country.iso,
           name_pa = pa.name,
           wdpaid = wdpaid,
           res_ha = res_ha,
           id_projet = id.project,
           status_wdpa = status.wdpa,
           iucn_cat = iucn.cat,
           iucn_des_en = iucn.des,
           gov_type = gov.wdpa,
           own_type = own.wdpa,
           marine = eco.wdpa,
           cofund = cofund,
           kfw = kfw,
           ffem = ffem,
           fund_type = fund.type,
           dept_report = reporter,
           funding_year = funding.years,
           funding_year_list = list.funding.years,
           .before = "treatment_year")
  
  ###Plot results
  ## treatment effect : avoided deforestation at pixel level (in ha)
  fig_att_pix = ggplot(data = df_fc_attgt,
                       aes(x = time, y = att_pix)) %>%
    + geom_line(color = "#08519C") %>%
    + geom_point(color = "#08519C") %>%
    + geom_ribbon(aes(ymin = cband_lower_pix, ymax = cband_upper_pix),
                  alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
    + labs(title = ifelse(is_m == TRUE, 
                          yes = "Deforestation avoided in a pixel,on average (matched)",
                          no = "Deforestation avoided in a pixel,on average (unmatched)"),
           subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
           caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the deforestation avoided at pixel level in hectare, due to the conservation program.\nA negative effect means the conservation program has caused higher deforestation."),
           y = "Area (ha)",
           x = "Year relative to treatment (t = 0)") %>%
    + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_blank(),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  # treatment effect : avoided deforestation in terms of 2000 forest cover
  fig_att_per = ggplot(data = df_fc_attgt,
                       aes(x = time, y = att_per)) %>%
    + geom_line(color = "#08519C") %>%
    + geom_point(color = "#08519C") %>%
    + geom_ribbon(aes(ymin = cband_lower_per, ymax = cband_upper_per),
                  alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
    + labs(title = ifelse(is_m == TRUE, 
                          yes = "Average deforestation avoided relative to 2000 forest cover (matched)",
                          no = "Average deforestation avoided relative to 2000 forest cover (unmatched)"),
           subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
           caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the deforestation avoided in percentage of 2000 forest cover.\nA negative effect means the conservation program has caused higher deforestation."),
           y = "%",
           x = "Year relative to treatment (t = 0)") %>%
    + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_blank(),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  # treatment effect : avoided deforestation in the PA
  fig_att_pa = ggplot(data = df_fc_attgt,
                      aes(x = time, y = att_pa)) %>%
    + geom_line(color = "#08519C") %>%
    + geom_point(color = "#08519C") %>%
    + geom_ribbon(aes(ymin = cband_lower_pa, ymax = cband_upper_pa),
                  alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
    + labs(title = ifelse(is_m == TRUE, 
                          yes = "Total deforestation avoided (matched)",
                          no = "Total deforestation avoided (unmatched)"),
           subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
           caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha",  "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the total deforestation avoided in the protected areas, in hectare (ha).\nThis measure is an extrapolation to the full protected area of average avoided deforestation at pixel level.\nA negative effect means the conservation program has caused higher deforestation."),
           y = "Forest area (ha)",
           x = "Year relative to treatment (t = 0)") %>%
    + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_blank(),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  

  # treatment effect : change in deforestation rate
  fig_fl_att = ggplot(data = df_fl_attgt,
                      aes(x = time, y = att)) %>%
    + geom_line(color = "#08519C") %>%
    + geom_point(color = "#08519C") %>%
    + geom_ribbon(aes(ymin = cband_lower, ymax = cband_upper),
                  alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
    + labs(title = "Effect of the conservation on the deforestation rate, relative to 2000",
           subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
           caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents ", (1-alpha)*100, " % confidence interval.\nTreatment effect is interpreted as the reduction of cumulated deforestation rate (relative to 2000 forest cover) in percentage points (pp).\nA negative effect means the conservation program has caused higher deforestation."),
           y = "Reduction of deforestation (p.p)",
           x = "Year relative to treatment (t = 0)") %>%
    + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_blank(),
      
      #legend.position = "bottom",
      legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  
  ggsave(ifelse(is_m == TRUE,
                yes = paste(tmp, paste0("fig_att_pix_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                no = paste(tmp, paste0("fig_att_pix_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
         plot = fig_att_pix,
         device = "png",
         height = 6, width = 9)
  ggsave(ifelse(is_m == TRUE,
                yes = paste(tmp, paste0("fig_att_pa_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                no = paste(tmp, paste0("fig_att_pa_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
         plot = fig_att_pa,
         device = "png",
         height = 6, width = 9)
  ggsave(ifelse(is_m == TRUE,
                yes = paste(tmp, paste0("fig_att_per_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                no = paste(tmp, paste0("fig_att_per_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
         plot = fig_att_per,
         device = "png",
         height = 6, width = 9)
  ggsave(paste(tmp, paste0("fig_fl_att_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig_fl_att,
         device = "png",
         height = 6, width = 9)
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
  
  
  
  #Return outputs
  return(list("df_fc_att" = df_fc_attgt, "df_fl_att"  = df_fl_attgt, "is_ok" = TRUE))
  
    },
  
  error = function(e)
  {
    print(e)
    #cat(paste("Error while computing/plotting DiD :\n", e, "\n"), file = log, append = TRUE)
    print(paste("Error while computing/plotting DiD :\n", e, "\n"))
    return(list("is_ok" = FALSE))
  }
  
  )
  
  return(output)
  
  #TEST : is treatment effect computed by the did package coherent with manual computations ? 
  # --> YES :D
  # test = df_did %>% 
  #   group_by(group, year) %>%
  #   summarize(avgFL_2000_cum = mean(FL_2000_cum, na.rm = TRUE),
  #             avgFC_ha = mean(fc_ha, na.rm = TRUE)) %>%
  #   ungroup() %>%
  #   mutate(fc_te2 = (avgFC_ha[year == 2009 & group == 2] - avgFC_ha[year == 2006 & group == 2]) - (avgFC_ha[year == 2009 & group == 1] - avgFC_ha[year == 2006 & group == 1]),
  #          fl_te2 = (avgFL_2000_cum[year == 2009 & group == 2] - avgFL_2000_cum[year == 2006 & group == 2]) - (avgFL_2000_cum[year == 2009 & group == 1] - avgFL_2000_cum[year == 2006 & group == 1]))
  # 
  
  
}


#Compute the treatment effect for a given protected area. This function can be used on any protected area for which, though no funding information will be displayed contrary to fn_did_att_afd.
## INPUTS 
### iso : the iso3 code for the country considered
### wdpaid : the WDPAID of the PA considered
### data_pa : dataset with information on protected areas, and especially their surfaces
### alpha : the threshold for confidence interval
### is_m : boolean stating whether we compute treatment effects from matched (TRUE) or unmatched treated and control units (FALSE)
### save_dir : the saving directory in the remote storage
### load_dir : the loading directory in the remote storage
### ext_input : the extension of input dataframe
## OUTPUTS
### df_fc_attgt : treatment effect computed for the protected area considered, expressed in avoided deforestation (hectare)
### df_fl_attgt : treatment effect computed for the protected area considered, expressed in change of deforestation rate
### is_ok : a boolean indicating whether or not an error occured inside the function 
## DATA SAVED :
### Dynamic treatment effects : avoided deforestation in an average pixel (in ha), avoided deforestation relative to 2000 forest cover, avoided deforestation extrapolated to the entire protected area (in ha), change in deforestation rate (in percentage points)
fn_did_att_general = function(iso, wdpaid, data_pa, alpha, is_m, load_dir, ext_input, save_dir)
{
  
  output = tryCatch(
    
    {
      
      #Loading matched and unmatched datasets
      df_long_m = s3read_using(data.table::fread,
                               object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("matched_long", "_", iso, "_", wdpaid, ext_input)),
                               bucket = "projet-afd-eva-ap",
                               opts = list("region" = "")) %>%
        dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, res_m, year, var, fc_ha))
      #dplyr::select(c(region, country_en, iso3, wdpaid, group, status_yr, year_funding_first, year_funding_all, year, var, fc_ha))
      
      df_long_unm = s3read_using(data.table::fread,
                                 object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("unmatched_long", "_", iso, "_", wdpaid, ext_input)),
                                 bucket = "projet-afd-eva-ap",
                                 opts = list("region" = "")) %>%
        dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, year, res_m, var, fc_ha))
      #dplyr::select(c(region, country_en, iso3, wdpaid, group, status_yr, year_funding_first, year_funding_all, year, var, fc_ha))
      
      # Define the working datasets depending on the is_m value
      if(is_m == TRUE)
      {
        df_long = df_long_m
      } else{df_long = df_long_unm 
      }
      
      #Extract some relevant variables
      ##Extract spatial resolution of pixels res_m and define pixel area in ha
      res_m = unique(df_long$res_m)
      res_ha = res_m^2*1e-4
      
      ##Extract treatment year
      treatment.year = df_long %>% 
        filter(group == 2) %>% 
        slice(1)
      treatment.year = treatment.year$status_yr
      
      ##Extract funding years
      df_fund_yr = df_long %>% 
        filter(group == 2) %>% 
        slice(1)
      funding.years = df_fund_yr$year_funding_first
      list.funding.years = df_fund_yr$year_funding_all
      
      ##Extract country name
      # country.name = df_long %>% 
      #   filter(group == 2) %>% 
      #   slice(1)
      # country.name = country.name$country_en
      
      ##Extract country iso
      country.iso = df_long %>% 
        filter(group == 2) %>% 
        slice(1)
      country.iso = country.iso$iso3
      
      ##Extract region name
      region.name = df_long %>% 
        filter(group == 2) %>% 
        slice(1)
      region.name = region.name$region
      
      ##Extract more information not in the matched dataframe
      ### Area
      wdpa_id = wdpaid #Need to give a name to wdpaid (function argument) different from the varaible in the dataset (wdpaid)
      area_ha = data_pa[data_pa$wdpaid == wdpa_id,]$area_km2*100
      ### Name of the PA
      pa.name = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      pa.name = pa.name$name_pa
      ### Country name
      country.name = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      country.name = country.name$country_en
      ### WDPA status
      status.wdpa = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      status.wdpa = status.wdpa$status
      ### IUCN category and description
      iucn.wdpa = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      iucn.cat = iucn.wdpa$iucn_cat
      iucn.des = iucn.wdpa$iucn_des_en
      ### Ecosystem
      eco.wdpa = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      eco.wdpa = eco.wdpa$marine
      ### Governance
      gov.wdpa = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      gov.wdpa = gov.wdpa$gov_type
      ### Owner
      own.wdpa = data_pa %>% 
        filter(wdpaid == wdpa_id) %>% 
        slice(1)
      own.wdpa = own.wdpa$own_type
      
      #Extract number of pixels in the PA
      #n_pix_pa = length(unique(filter(df_long_unm, group == 2)$assetid))
      n_pix_pa = area_ha/res_ha
      
      #Average forest cover in a treated pixel in 2000
      ## For matched 
      avgFC_2000_m = df_long_m %>% 
        filter(group == 2 & year == 2000) 
      avgFC_2000_m = mean(avgFC_2000_m$fc_ha, na.rm = TRUE)
      ## For unmatched
      avgFC_2000_unm = df_long_unm %>% 
        filter(group == 2 & year == 2000) 
      avgFC_2000_unm = mean(avgFC_2000_unm$fc_ha, na.rm = TRUE)
      
      #Then modify the dataframe before DiD computations
      ## Set treatment year = 0 for controls (necessary for did package to consider "never treated" units)
      ## Compute cumulative deforestation relative to 2000 forest cover (outcome where TE is computed)
      df_did = df_long %>%
        mutate(treatment_year = case_when(group == 1 ~0,
                                          group == 2 ~status_yr), #Set treatment year to 0 for control units (required by did::att_gt)
               time = ifelse(group == 2, yes = year-treatment_year, no = NA),
               .after = status_yr) %>%
        group_by(assetid) %>%
        # mutate(FL_2000_cum = (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100,
        #        fc_2000 = fc_ha[year == 2000]) %>%
        mutate(FL_2000_cum = case_when(fc_ha[year == 2000] > 0 ~ (fc_ha-fc_ha[year == 2000])/fc_ha[year == 2000]*100, 
                                       TRUE ~ NA)) %>%
        ungroup()
      
      
      ##Average forest cover in 2000 in a pixel, and average share of forest cover in a pixel
      # fc_2000_avg = mean(df_did[df_did$group == 2,]$fc_2000, na.rm = TRUE)
      # per_fc_2000_avg = min(fc_2000_avg/res_ha, 1) #Take the min as in some cases, reported forest cover is higher than pixel area
      
      #Compute dynamic TE with did package. 
      ## Control are "never treated" units, no covariate is added in the regression estimated with doubly-robust method
      ## standard errors are computed with bootstrap, and confidence intervals computed from it.
      ## No clustering is performed as it does not seem relevant in our case (https://blogs.worldbank.org/impactevaluations/when-should-you-cluster-standard-errors-new-wisdom-econometrics-oracle)
      ## Pseudo treatment effect are computed for each pre-treatment year (varying base period)
      
      ##For forest cover (ha and %)
      ### treatment effect computation
      fc_attgt = did::att_gt(yname = "fc_ha",
                             gname = "treatment_year",
                             idname = "assetid",
                             tname = "year",
                             control_group = "nevertreated", #Thsi corresponds to control pixels as defined in the matching , with treatment year set to 0
                             xformla = ~1,
                             alp = alpha, #For 95% confidence interval
                             allow_unbalanced_panel = TRUE, #Ensure no unit is dropped, though every pixel should have data for all years in the period
                             bstrap=TRUE, #Compute bootstrap CI
                             biters = 1000, #The number of bootstrap iteration, 1000 is default
                             cband = TRUE, #Compute CI
                             clustervars = NULL, #No clustering seems relevant to me 
                             base_period = "varying",
                             data = df_did,
                             print_details = F)
      ##For change in deforestation rate (percentage points)
      fl_attgt = did::att_gt(yname = "FL_2000_cum",
                             gname = "treatment_year",
                             idname = "assetid",
                             tname = "year",
                             control_group = "nevertreated", #Thsi corresponds to control pixels as defined in the matching , with treatment year set to 0
                             xformla = ~1,
                             alp = alpha, #For 95% confidence interval
                             allow_unbalanced_panel = TRUE, #Ensure no unit is dropped, though every pixel should have data for all years in the period
                             bstrap=TRUE, #Compute bootstrap CI
                             biters = 1000, #The number of bootstrap iteration, 1000 is default
                             cband = TRUE, #Compute CI
                             clustervars = NULL, #No clustering seems relevant to me
                             base_period = "varying",
                             data = df_did,
                             print_details = F)
      
      
      ### Report results in a dataframe
      ### The treatment effect computed is at pixel level (avoided deforestation in a pixel, in ha)
      ### This treatment effect is aggregated to PA by multiplying treatment effect by the number of pixel in the PA. It is also expressed in percentage of pixel area (avoided deforestation in share of pixel area)
      ### confidence intervals (at pixel level) are computed from bootstrap standard errors after a coefficient is applied.
      ### This computation takes the one from did:::summary.MP function, line 15 and 16. 
      ### They are multiplied by the number of pixels to compute CI for treatment effect at PA level 
      ### They are divided by the pixel area to compute CI for treatment effect in percentage of pixel area
      df_fc_attgt = data.frame("treatment_year" = fc_attgt$group,
                               "year" = fc_attgt$t,
                               "att_pix" = fc_attgt$att,
                               "c" = fc_attgt$c,
                               "se" = fc_attgt$se,  
                               "n" = fc_attgt$n) %>%
        #Compute treatment effect at PA level and in share of pixel area
        ## att_pa : the total avoided deforestation is the avoided deforestation in ha in a given pixel, multiplied by the number of pixel in the PA.
        ## att_per : avoided deforestation in a pixel, as a share of average forest cover in 2000 in matched treated. Can be extrapolated to full PA in principle (avoided deforestation in share of 2000 forest cover)
        mutate(att_pa = att_pix*n_pix_pa,
               att_per = att_pix/avgFC_2000_m*100) %>% 
        #Compute time relative to treatment year
        mutate(time = year - treatment_year,
               .before = year) %>%
        #Compute confidence intervals
        mutate(cband_lower_pix = round(att_pix-c*se, 4),
               cband_upper_pix = round(att_pix+c*se, 4),
               cband_lower_pa = cband_lower_pix*n_pix_pa,
               cband_upper_pa = cband_upper_pix*n_pix_pa,
               cband_lower_per = cband_lower_pix/avgFC_2000_m*100,
               cband_upper_per = cband_upper_pix/avgFC_2000_m*100,
               sig = sign(cband_lower_pix) == sign(cband_upper_pix),
               sig_5 = ifelse(max(time) >=5, yes = sig[time == 5] == TRUE, no = NA),
               sig_10 = ifelse(max(time) >= 10, yes = sig[time == 10] == TRUE, no = NA),
               sig_end = sig[time == max(time)] == TRUE,
               alpha = alpha) %>%
        #Add relevant information
        mutate(region = region.name,
               country_en = country.name,
               iso3 = country.iso,
               name_pa = pa.name,
               wdpaid = wdpaid,
               res_ha = res_ha,
               status_wdpa = status.wdpa,
               iucn_cat = iucn.cat,
               iucn_des_en = iucn.des,
               gov_type = gov.wdpa,
               own_type = own.wdpa,
               marine = eco.wdpa,
               funding_year = funding.years,
               funding_year_list = list.funding.years,
               .before = "treatment_year")
      # Same for treatment effect expressed as a change in deforestation rate
      df_fl_attgt = data.frame("treatment_year" = fl_attgt$group,
                               "year" = fl_attgt$t,
                               "att" = fl_attgt$att,
                               "c" = fl_attgt$c,
                               "se" = fl_attgt$se,
                               "n" = fl_attgt$n) %>%
        #Compute time relative to treatment year
        mutate(time = year - treatment_year,
               .before = year) %>%
        mutate(cband_lower = round(att-c*se, 4),
               cband_upper = round(att+c*se, 4),
               sig = sign(cband_lower) == sign(cband_upper),
               sig_5 = ifelse(max(time) >=5, yes = sig[time == 5] == TRUE, no = NA),
               sig_10 = ifelse(max(time) >= 10, yes = sig[time == 10] == TRUE, no = NA),
               sig_end = sig[time == max(time)] == TRUE,
               alpha = alpha) %>%
        #Compute time relative to treatment year
        mutate(time = year - treatment_year,
               .before = year) %>%
        #Add relevant information
        mutate(region = region.name,
               country_en = country.name,
               iso3 = country.iso,
               name_pa = pa.name,
               wdpaid = wdpaid,
               res_ha = res_ha,
               status_wdpa = status.wdpa,
               iucn_cat = iucn.cat,
               iucn_des_en = iucn.des,
               gov_type = gov.wdpa,
               own_type = own.wdpa,
               marine = eco.wdpa,
               funding_year = funding.years,
               funding_year_list = list.funding.years,
               .before = "treatment_year")
      
      ###Plot results
      ## treatment effect : avoided deforestation at pixel level (in ha)
      fig_att_pix = ggplot(data = df_fc_attgt,
                           aes(x = time, y = att_pix)) %>%
        + geom_line(color = "#08519C") %>%
        + geom_point(color = "#08519C") %>%
        + geom_ribbon(aes(ymin = cband_lower_pix, ymax = cband_upper_pix),
                      alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
        + labs(title = ifelse(is_m == TRUE, 
                              yes = "Deforestation avoided in a pixel,on average (matched)",
                              no = "Deforestation avoided in a pixel,on average (unmatched)"),
               subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
               caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the deforestation avoided at pixel level in hectare, due to the conservation program.\nA negative effect means the conservation program has caused higher deforestation."),
               y = "Area (ha)",
               x = "Year relative to treatment (t = 0)") %>%
        + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
        + theme_minimal() %>%
        + theme(
          axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
          axis.text=element_text(size=11, color = "black"),
          axis.title=element_text(size=14, color = "black", face = "plain"),
          
          plot.caption = element_text(hjust = 0),
          plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
          plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
          
          strip.text = element_blank(),
          
          #legend.position = "bottom",
          legend.title = element_blank(),
          legend.text=element_text(size=10),
          #legend.spacing.x = unit(1.0, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),
          legend.key.size = unit(2, 'line'),
          
          panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
          panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
        )
      
      # treatment effect : avoided deforestation in terms of 2000 forest cover
      fig_att_per = ggplot(data = df_fc_attgt,
                           aes(x = time, y = att_per)) %>%
        + geom_line(color = "#08519C") %>%
        + geom_point(color = "#08519C") %>%
        + geom_ribbon(aes(ymin = cband_lower_per, ymax = cband_upper_per),
                      alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
        + labs(title = ifelse(is_m == TRUE, 
                              yes = "Average deforestation avoided relative to 2000 forest cover (matched)",
                              no = "Average deforestation avoided relative to 2000 forest cover (unmatched)"),
               subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
               caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the deforestation avoided in percentage of 2000 forest cover.\nA negative effect means the conservation program has caused higher deforestation."),
               y = "%",
               x = "Year relative to treatment (t = 0)") %>%
        + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
        + theme_minimal() %>%
        + theme(
          axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
          axis.text=element_text(size=11, color = "black"),
          axis.title=element_text(size=14, color = "black", face = "plain"),
          
          plot.caption = element_text(hjust = 0),
          plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
          plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
          
          strip.text = element_blank(),
          
          #legend.position = "bottom",
          legend.title = element_blank(),
          legend.text=element_text(size=10),
          #legend.spacing.x = unit(1.0, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),
          legend.key.size = unit(2, 'line'),
          
          panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
          panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
        )
      
      # treatment effect : avoided deforestation in the PA
      fig_att_pa = ggplot(data = df_fc_attgt,
                          aes(x = time, y = att_pa)) %>%
        + geom_line(color = "#08519C") %>%
        + geom_point(color = "#08519C") %>%
        + geom_ribbon(aes(ymin = cband_lower_pa, ymax = cband_upper_pa),
                      alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
        + labs(title = ifelse(is_m == TRUE, 
                              yes = "Total deforestation avoided (matched)",
                              no = "Total deforestation avoided (unmatched)"),
               subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
               caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha",  "\nRibbon represents", (1-alpha)*100, "% confidence interval.\nTreatment effect is interpreted as the total deforestation avoided in the protected areas, in hectare (ha).\nThis measure is an extrapolation to the full protected area of average avoided deforestation at pixel level.\nA negative effect means the conservation program has caused higher deforestation."),
               y = "Forest area (ha)",
               x = "Year relative to treatment (t = 0)") %>%
        + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
        + theme_minimal() %>%
        + theme(
          axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
          axis.text=element_text(size=11, color = "black"),
          axis.title=element_text(size=14, color = "black", face = "plain"),
          
          plot.caption = element_text(hjust = 0),
          plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
          plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
          
          strip.text = element_blank(),
          
          #legend.position = "bottom",
          legend.title = element_blank(),
          legend.text=element_text(size=10),
          #legend.spacing.x = unit(1.0, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),
          legend.key.size = unit(2, 'line'),
          
          panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
          panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
        )
      
      
      # treatment effect : change in deforestation rate
      fig_fl_att = ggplot(data = df_fl_attgt,
                          aes(x = time, y = att)) %>%
        + geom_line(color = "#08519C") %>%
        + geom_point(color = "#08519C") %>%
        + geom_ribbon(aes(ymin = cband_lower, ymax = cband_upper),
                      alpha=0.1, fill = "#FB6A4A", color = "black", linetype = "dotted") %>%
        + labs(title = "Effect of the conservation on the deforestation rate, relative to 2000",
               subtitle = paste0(pa.name, ", ", country.name, ", implemented in ", treatment.year),
               caption = paste("WDPA ID :", wdpa_id, "|", format(area_ha, big.mark = ","), "ha |", "Pixel resolution :", res_ha, "ha", "\nRibbon represents ", (1-alpha)*100, " % confidence interval.\nTreatment effect is interpreted as the reduction of cumulated deforestation rate (relative to 2000 forest cover) in percentage points (pp).\nA negative effect means the conservation program has caused higher deforestation."),
               y = "Reduction of deforestation (p.p)",
               x = "Year relative to treatment (t = 0)") %>%
        + scale_x_continuous(breaks=seq(min(df_fc_attgt$time),max(df_fc_attgt$time),by=1)) %>%
        + theme_minimal() %>%
        + theme(
          axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
          axis.text=element_text(size=11, color = "black"),
          axis.title=element_text(size=14, color = "black", face = "plain"),
          
          plot.caption = element_text(hjust = 0),
          plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
          plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
          
          strip.text = element_blank(),
          
          #legend.position = "bottom",
          legend.title = element_blank(),
          legend.text=element_text(size=10),
          #legend.spacing.x = unit(1.0, 'cm'),
          legend.spacing.y = unit(0.75, 'cm'),
          legend.key.size = unit(2, 'line'),
          
          panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
          panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
          panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
        )
      
      
      
      ##Saving plots
      tmp = paste(tempdir(), "fig", sep = "/")
      
      ggsave(ifelse(is_m == TRUE,
                    yes = paste(tmp, paste0("fig_att_pix_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                    no = paste(tmp, paste0("fig_att_pix_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
             plot = fig_att_pix,
             device = "png",
             height = 6, width = 9)
      ggsave(ifelse(is_m == TRUE,
                    yes = paste(tmp, paste0("fig_att_pa_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                    no = paste(tmp, paste0("fig_att_pa_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
             plot = fig_att_pa,
             device = "png",
             height = 6, width = 9)
      ggsave(ifelse(is_m == TRUE,
                    yes = paste(tmp, paste0("fig_att_per_", iso, "_", wdpaid, "_m", ".png"), sep = "/"),
                    no = paste(tmp, paste0("fig_att_per_", iso, "_", wdpaid, "_unm", ".png"), sep = "/")),
             plot = fig_att_per,
             device = "png",
             height = 6, width = 9)
      ggsave(paste(tmp, paste0("fig_fl_att_", iso, "_", wdpaid, ".png"), sep = "/"),
             plot = fig_fl_att,
             device = "png",
             height = 6, width = 9)
      
      files <- list.files(tmp, full.names = TRUE)
      ##Add each file in the bucket (same foler for every file in the temp)
      for(f in files) 
      {
        cat("Uploading file", paste0("'", f, "'"), "\n")
        aws.s3::put_object(file = f, 
                           bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                           region = "", show_progress = TRUE)
      }
      do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
      
      
      
      #Return outputs
      return(list("df_fc_att" = df_fc_attgt, "df_fl_att"  = df_fl_attgt, "is_ok" = TRUE))
      
    },
    
    error = function(e)
    {
      print(e)
      #cat(paste("Error while computing/plotting DiD :\n", e, "\n"), file = log, append = TRUE)
      print(paste("Error while computing/plotting DiD :\n", e, "\n"))
      return(list("is_ok" = FALSE))
    }
    
  )
  
  return(output)
  
  #TEST : is treatment effect computed by the did package coherent with manual computations ? 
  # --> YES :D
  # test = df_did %>% 
  #   group_by(group, year) %>%
  #   summarize(avgFL_2000_cum = mean(FL_2000_cum, na.rm = TRUE),
  #             avgFC_ha = mean(fc_ha, na.rm = TRUE)) %>%
  #   ungroup() %>%
  #   mutate(fc_te2 = (avgFC_ha[year == 2009 & group == 2] - avgFC_ha[year == 2006 & group == 2]) - (avgFC_ha[year == 2009 & group == 1] - avgFC_ha[year == 2006 & group == 1]),
  #          fl_te2 = (avgFL_2000_cum[year == 2009 & group == 2] - avgFL_2000_cum[year == 2006 & group == 2]) - (avgFL_2000_cum[year == 2009 & group == 1] - avgFL_2000_cum[year == 2006 & group == 1]))
  # 
  
  
}


#Plot the forest cover loss with 2000 as a base year in treated and control units, before and after matching
##INPUTS
### iso : the iso3 code for the country considered
### wdpaid : the WDPAID of the PA considered
### data_pa : dataset with information on protected areas, and especially their surfaces
### alpha : the threshold for confidence interval
### save_dir : the saving directory in the remote storage
### load_dir : the loading directory in the remote storage
### ext_input : the extension of input dataframe
## DATA SAVED
### Plot of forest cover loss with 2000 as a base year in treated and control units, before and after matching
fn_plot_forest_loss = function(iso, wdpaid, data_pa, alpha, load_dir, ext_input, save_dir)
{
  
  #Loading matched and unmatched data frames
  df_long_m_raw = s3read_using(data.table::fread,
                               object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("matched_long", "_", iso, "_", wdpaid, ext_input)),
                               bucket = "projet-afd-eva-ap",
                               opts = list("region" = "")) %>%
    dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, res_m, year, var, fc_ha))
  
  df_long_unm_raw = s3read_using(data.table::fread,
                                 object = paste0(load_dir, "/", iso, "/", wdpaid, "/", paste0("unmatched_long", "_", iso, "_", wdpaid, ext_input)),
                                 bucket = "projet-afd-eva-ap",
                                 opts = list("region" = "")) %>%
    dplyr::select(c(region, iso3, wdpaid, group, assetid, status_yr, year_funding_first, year_funding_all, year, res_m, var, fc_ha))
  
  wdpa_id = wdpaid
  #Extract relevant information
  ##Spatial resolution of pixels res_m and define pixel area in ha
  res_m = unique(df_long_m_raw$res_m)
  res_ha = res_m^2*1e-4
  
  ##treatment year
  treatment.year = df_long_m_raw %>% 
    filter(group == 2) %>% 
    slice(1)
  treatment.year = treatment.year$status_yr
  
  ##funding years
  funding.years = df_long_m_raw %>% 
    filter(group == 2) %>% 
    slice(1)
  funding.years = funding.years$year_funding_first
  #funding.years = as.numeric(unlist(strsplit(funding.years$year_funding_all, split = ",")))
  
  ##country iso
  country.iso = df_long_m_raw %>% 
    filter(group == 2) %>% 
    slice(1)
  country.iso = country.iso$iso3
  
  ##region name
  region.name = df_long_m_raw %>% 
    filter(group == 2) %>% 
    slice(1)
  region.name = region.name$region
  
  ##Area of the PA and PA/country name
  area_ha = data_pa[data_pa$wdpaid == wdpa_id,]$area_km2*100
  country.name = data_pa %>% 
    filter(iso3 == iso) %>% 
    slice(1)
  country.name = country.name$country_en
  pa.name = data_pa %>% 
    filter(wdpaid == wdpa_id) %>% 
    slice(1)
  pa.name = pa.name$name_pa
  
  
  #Forest cover loss is computed for each pixel relative to 2000, then average forest cover evolution and loss is computed for treated and controls
  df_long_m = df_long_m_raw %>%
    #Compute forest loss relative to 2000 in ha for each pixel
    group_by(assetid) %>%
    mutate(fc_rel00_ha = fc_ha - fc_ha[year == 2000],
           .after = "fc_ha") %>%
    ungroup() %>%
    #Compute average forest cover and forest cover loss relative to 2000 for each group, year
    group_by(group, year) %>%
    summarise(n= n(),
              avgfc_ha = mean(fc_ha, na.rm = TRUE),
              sdfc_ha = sd(fc_ha, na.rm = TRUE),
              avgfc_rel00_ha = mean(fc_rel00_ha, na.rm = TRUE),
              sdfc_rel00_ha = sd(fc_rel00_ha, na.rm = TRUE),
              fc_ha_ci_upper = avgfc_ha + qt((1-alpha)/2,df=n-1)*sdfc_ha/sqrt(n),
              fc_ha_ci_lower = avgfc_ha - qt((1-alpha)/2,df=n-1)*sdfc_ha/sqrt(n),
              fc_rel00_ha_ci_upper = avgfc_rel00_ha + qt((1-alpha)/2,df=n-1)*sdfc_rel00_ha/sqrt(n),
              fc_rel00_ha_ci_lower = avgfc_rel00_ha - qt((1-alpha)/2,df=n-1)*sdfc_rel00_ha/sqrt(n),
              matched = T) %>%
    #Compute total forest cover and forest loss relative to 2000, knowing area of the PA and average forest share in a pixel in 2000
    #CI are computed at 95% confidence level
    ungroup() %>%
    mutate(#per_fc_2000_avg = min(fc_ha[year == 2000]/res_ha, 1),
      #fc_tot_ha = fc_ha*(area_ha*per_fc_2000_avg/res_ha),
      fc_tot_ha = avgfc_ha*(area_ha/res_ha),
      #fc_tot_rel00_ha = avgfc_rel00_ha*(area_ha*per_fc_2000_avg/res_ha),
      fc_tot_rel00_ha = avgfc_rel00_ha*(area_ha/res_ha),
      fc_tot_ha_ci_upper = fc_ha_ci_upper*(area_ha/res_ha),
      fc_tot_ha_ci_upper = fc_ha_ci_lower*(area_ha/res_ha),
      fc_tot_rel00_ha_ci_upper = fc_rel00_ha_ci_upper*(area_ha/res_ha),
      fc_tot_rel00_ha_ci_lower = fc_rel00_ha_ci_lower*(area_ha/res_ha),
      alpha = alpha)
  
  df_long_unm = df_long_unm_raw %>%
    #Compute forest loss relative to 2000 in ha for each pixel
    group_by(assetid) %>%
    mutate(fc_rel00_ha = fc_ha - fc_ha[year == 2000],
           .after = "fc_ha") %>%
    ungroup() %>%
    #Compute average forest cover and forest cover loss relative to 2000 for each group, year
    group_by(group, year) %>%
    summarise(n= n(),
              avgfc_ha = mean(fc_ha, na.rm = TRUE),
              sdfc_ha = sd(fc_ha, na.rm = TRUE),
              avgfc_rel00_ha = mean(fc_rel00_ha, na.rm = TRUE),
              sdfc_rel00_ha = sd(fc_rel00_ha, na.rm = TRUE),
              fc_ha_ci_upper = avgfc_ha + qt((1-alpha)/2,df=n-1)*sdfc_ha/sqrt(n),
              fc_ha_ci_lower = avgfc_ha - qt((1-alpha)/2,df=n-1)*sdfc_ha/sqrt(n),
              fc_rel00_ha_ci_upper = avgfc_rel00_ha + qt((1-alpha)/2,df=n-1)*sdfc_rel00_ha/sqrt(n),
              fc_rel00_ha_ci_lower = avgfc_rel00_ha - qt((1-alpha)/2,df=n-1)*sdfc_rel00_ha/sqrt(n),
              matched = F) %>%
    #Compute total forest cover and forest loss relative to 2000, knowing area of the PA and average forest share in a pixel in 2000
    #CI are computed at 95% confidence level
    ungroup() %>%
    mutate(#per_fc_2000_avg = min(fc_ha[year == 2000]/res_ha, 1),
      #fc_tot_ha = fc_ha*(area_ha*per_fc_2000_avg/res_ha),
      fc_tot_ha = avgfc_ha*(area_ha/res_ha),
      #fc_tot_rel00_ha = avgfc_rel00_ha*(area_ha*per_fc_2000_avg/res_ha),
      fc_tot_rel00_ha = avgfc_rel00_ha*(area_ha/res_ha),
      fc_tot_ha_ci_upper = fc_ha_ci_upper*(area_ha/res_ha),
      fc_tot_ha_ci_upper = fc_ha_ci_lower*(area_ha/res_ha),
      fc_tot_rel00_ha_ci_upper = fc_rel00_ha_ci_upper*(area_ha/res_ha),
      fc_tot_rel00_ha_ci_lower = fc_rel00_ha_ci_lower*(area_ha/res_ha),
      alpha = alpha)
  
  
  #Define plotting dataset
  df_plot = rbind(df_long_m, df_long_unm) %>%
    mutate(group = case_when(group == 1 ~"Control",
                             group == 2 ~"Treated"),
           region = region.name,
           country_en = country.name,
           iso3 = country.iso,
           wdpaid = wdpaid, 
           name_pa = pa.name,
           area_ha = area_ha)
  
  #The period where deforestation is plotted
  year.max = max(df_long_m$year)
  
  #Plot
  fct.labs <- c("Before Matching", "After Matching")
  names(fct.labs) <- c(FALSE, TRUE)
  
  fig = ggplot(data = filter(df_plot, year == year.max),
               aes(y = abs(fc_tot_rel00_ha), fill = as.factor(group), x = group)) %>%
    + geom_bar(position =  position_dodge(width = 0.8), stat = "identity", show.legend = FALSE) %>% 
    + geom_errorbar(aes(ymax=abs(fc_tot_rel00_ha_ci_upper), ymin=abs(fc_tot_rel00_ha_ci_lower)), width=0.4, colour="grey60", alpha=0.9, size=1.3) %>%
    + geom_label(aes(label = format(round(abs(fc_tot_rel00_ha), 0), big.mark = ","), y = abs(fc_tot_rel00_ha)), 
                 color = "black",
                 show.legend = FALSE) %>%
    + scale_fill_brewer(name = "Group", palette = "Blues") %>%
    + labs(x = "",
           y = "Forest cover loss (ha)",
           title = paste("Average area deforested between 2000 and", year.max),
           subtitle = paste("WDPA ID", wdpaid, "in", country.iso, ",implemented in", treatment.year, "and covering", format(area_ha, big.mark = ","), "ha"),
           caption = paste((1-alpha)*100, "% confidence intervals.")) %>%
    + facet_wrap(~matched,
                 labeller = labeller(matched = fct.labs))  %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      
      #legend.position = "bottom",
      #legend.title = element_blank(),
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  
  ggsave(paste(tmp, paste0("fig_fl_2000_", year.max, "_m_unm_", iso, "_", wdpaid, ".png"), sep = "/"),
         plot = fig,
         device = "png",
         height = 6, width = 9)
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, iso, wdpaid, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
  
  return(df_plot)
}


# Plotting the treatment effect of each protected area analyzed in the same graph. This function suits for AFD supported protected areas : it includes funding information to the table and figures
## INPUTS
### df_fc_att : a dataset with treatment effects for each protected area in the sample, expressed as avoided deforestation (hectare)
### df_fl_att : a dataset with treatment effects for each protected area in the sample, expressed as change in deforestation rate
### alpha : the threshold for confidence interval
### save_dir : the saving directory in the remote storage
## DATA SAVED
### Tables and figures : treatment effects computed for each protected area in the sample, expressed as avoided deforestaion (hectare and percentage of 2000 forest cover) and change in deforestation rate.
fn_plot_att_afd = function(df_fc_att, df_fl_att, alpha = alpha, save_dir)
{
  
  #list of PAs and two time periods
  list_ctry_plot = df_fc_att %>%
    dplyr::select(iso3, country_en, wdpaid, iucn_cat) %>%
    unique() %>%
    group_by(iso3, country_en, wdpaid) %>%
    summarize(time = c(5, 10),
              iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                    iucn_cat %in% c("V", "VI") ~ "Non strict",
                                    grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown")) %>%
    ungroup()
  
  #treatment effect for each wdpa (some have not on the two time periods)
  temp_fc = df_fc_att %>%
    dplyr::select(c(region, iso3, country_en, wdpaid, name_pa, iucn_cat, treatment_year, time, year, att_per, cband_lower_per, cband_upper_per, att_pa, cband_lower_pa, cband_upper_pa)) %>%
    mutate(sig_pa = sign(cband_lower_pa) == sign(cband_upper_pa),
           sig_per = sign(cband_lower_per) == sign(cband_upper_per)) %>%
    filter(time %in% c(5, 10)) 
  temp_fl = df_fl_att %>%
    dplyr::select(c(region, iso3, country_en, wdpaid, name_pa, iucn_cat, treatment_year, time, year, att, cband_lower, cband_upper)) %>%
    mutate(sig = sign(cband_lower) == sign(cband_upper)) %>%
    filter(time %in% c(5, 10)) 
  
  #Att for each WDPAID, for each period (NA if no value)
  df_plot_fc_att = left_join(list_ctry_plot, temp_fc, by = c("iso3", "country_en", "wdpaid", "time")) %>%
    group_by(time, country_en) %>%
    arrange(country_en) %>%
    mutate(country_en = paste0(country_en, " (", LETTERS[row_number()], ")")) %>%
    ungroup() 
  df_plot_fl_att = left_join(list_ctry_plot, temp_fl, by = c("iso3", "country_en", "wdpaid", "time"))%>%
    group_by(time, country_en) %>%
    arrange(country_en) %>%
    mutate(country_en = paste0(country_en, " (", LETTERS[row_number()], ")")) %>%
    ungroup()
  
  #Plots
  names = c(`5` = "5 years after treatment",
            `10` = "10 years after treatment",
            `Strict` = "Strict\nIUCN cat. I-IV",
            `Non strict` = "Non strict\nIUCN V-VI",
            `Unknown` = "Unknown")
  
  ## Att in share of 2000 forest cover
  fig_att_per = ggplot(df_plot_fc_att, 
                       aes(x = att_per, 
                           y = factor(country_en, levels = unique(rev(sort(country_en)))),
                           xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_per_iucn = ggplot(df_plot_fc_att, 
                       aes(x = att_per, 
                           y = factor(country_en, levels = unique(rev(sort(country_en)))),
                           xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(iucn_wolf~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )

    
  ##treatment effect : total deforestation avoided
  fig_att_pa = ggplot(df_plot_fc_att, 
                      aes(x = att_pa, 
                          y = factor(country_en, levels = unique(rev(sort(country_en)))),
                          xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_pa_iucn = ggplot(df_plot_fc_att, 
                      aes(x = att_pa, 
                          y = factor(country_en, levels = unique(rev(sort(country_en)))),
                          xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(iucn_wolf~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  ##treatment effect : avoided deforestation in percentage points
  fig_att_fl = ggplot(df_plot_fl_att, 
                      aes(x = att, 
                          y = factor(country_en, levels = unique(rev(sort(country_en)))),
                          xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_fl_iucn = ggplot(df_plot_fl_att, 
                      aes(x = att, 
                          y = factor(country_en, levels = unique(rev(sort(country_en)))),
                          xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(iucn_wolf~time, scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  
  #Tables 
  ## treatment effect : percentage of deforestation avoided
  tbl_fc_att_per = df_fc_att %>%
    mutate(sig_per = case_when(sign(cband_lower_per) == sign(cband_upper_per) ~ "Yes",
                               sign(cband_lower_per) != sign(cband_upper_per) ~ "No"),
           iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                 iucn_cat %in% c("V", "VI") ~ "Non strict",
                                 grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
           dept_report = case_when(dept_report == "Léa Poulin,Pierre-Yves Durand,Ingrid Dallmann" ~ "Unknown",
                                   TRUE ~ dept_report),
           kfw = case_when(kfw == TRUE ~ "Yes", kfw == FALSE ~ "No"),
           ffem = case_when(ffem == TRUE ~ "Yes", ffem == FALSE ~ "No"),
           funding_year_list = case_when(is.na(funding_year_list) == TRUE ~ "Unknown",
                                         TRUE ~ funding_year_list),
           name_pa = case_when(nchar(name_pa) <= 25 ~ stri_trans_general(name_pa, id = "Latin-ASCII"),
                               nchar(name_pa) > 25 ~ stri_trans_general(paste0(substr(name_pa, 1, 25), "..."),  id = "Latin-ASCII"))
    ) %>%
    dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, fund_type, kfw, ffem, iucn_wolf, gov_type, time, att_per, sig_per)) %>%
    filter(time %in% c(5, 10)) %>%
    pivot_wider(values_from = c("att_per", "sig_per"), names_from = c("time", "time")) %>%
    dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, kfw, ffem, iucn_wolf, att_per_5, sig_per_5, att_per_10, sig_per_10)) %>%
    #dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, fund_type, kfw, ffem, iucn_wolf, gov_type, att_per_5, sig_per_5, att_per_10, sig_per_10)) %>%
    mutate(across(.cols = starts_with(c("att", "sig")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ as.character(format(x, digit = 1))))) %>%
    rename("Effect (5 y., %)" = "att_per_5",
           "Signi. (5 y.)" = "sig_per_5",
           "Effect (10 y., %)" = "att_per_10",
           "Signi. (10 y.)" = "sig_per_10") 
  # names(tbl_fc_att_per) = c("Name", "Project ID", "Tech. div.", "Country", "Creation", "Funding year", "Type of funding", "KfW", "FFEM", "Protection", 
  #                           "Governance", "Effect (5 y., %)", "Significance (5 y.)","Effect (10 y., %)", "Significance (10 y.)")
  names(tbl_fc_att_per) = c("Name", "Project ID", "Tech. div.", "Country", "Creation", "Funding year", "KfW", "FFEM", "Protection", 
                            "Effect (5 y., %)", "Signi. (5 y.)","Effect (10 y., %)", "Signi. (10 y.)")
  
  # treatment effect : total deforestation avoided 
  tbl_fc_att_pa = df_fc_att %>%
    mutate(sig_pa = case_when(sign(cband_lower_pa) == sign(cband_upper_pa) ~ "Yes",
                              sign(cband_lower_pa) != sign(cband_upper_pa) ~ "No"),
           iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                 iucn_cat %in% c("V", "VI") ~ "Non strict",
                                 grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
           dept_report = case_when(dept_report == "Léa Poulin,Pierre-Yves Durand,Ingrid Dallmann" ~ "Unknown",
                                   TRUE ~ dept_report),
           kfw = case_when(kfw == TRUE ~ "Yes", kfw == FALSE ~ "No"),
           ffem = case_when(ffem == TRUE ~ "Yes", ffem == FALSE ~ "No"),
           funding_year_list = case_when(is.na(funding_year_list) == TRUE ~ "Unknown",
                                         TRUE ~ funding_year_list),
           name_pa = case_when(nchar(name_pa) <= 25 ~ stri_trans_general(name_pa, id = "Latin-ASCII"),
                               nchar(name_pa) > 25 ~ stri_trans_general(paste0(substr(name_pa, 1, 25), "..."),  id = "Latin-ASCII"))
    ) %>%
    dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, fund_type, kfw, ffem, iucn_wolf, gov_type, time, att_pa, sig_pa)) %>%
    filter(time %in% c(5, 10)) %>%
    pivot_wider(values_from = c("att_pa", "sig_pa"), names_from = c("time", "time")) %>%
    # dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, fund_type, kfw, ffem, iucn_wolf, gov_type, att_pa_5, sig_pa_5, att_pa_10, sig_pa_10)) %>%
    dplyr::select(c(name_pa, id_projet, dept_report, country_en, treatment_year, funding_year_list, kfw, ffem, iucn_wolf, att_pa_5, sig_pa_5, att_pa_10, sig_pa_10)) %>%
    mutate(across(.cols = starts_with(c("att", "sig")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ as.character(format(x, digit = 1))))) %>%
    rename("Effect (5 y., %)" = "att_pa_5",
           "Signi. (5 y.)" = "sig_pa_5",
           "Effect (10 y., %)" = "att_pa_10",
           "Signi. (10 y.)" = "sig_pa_10") 
  # names(tbl_fc_att_pa) = c("Name", "Project ID", "Tech. div.", "Country", "Creation", "Funding year", "Type of funding", "KfW", "FFEM", "Protection", 
  #                           "Governance", "Effect (5 y., ha)", "Significance (5 y.)","Effect (10 y., ha)", "Significance (10 y.)")
  names(tbl_fc_att_pa) = c("Name", "Project ID", "Tech. div.", "Country", "Creation", "Funding year", "KfW", "FFEM", "Protection", 
                           "Effect (5 y., ha)", "Signi. (5 y.)","Effect (10 y., ha)", "Signi. (10 y.)")
  
  
  
  #Saving plots
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  
  ggsave(paste(tmp, "fig_att_per.png", sep = "/"),
         plot = fig_att_per,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_per_iucn.png", sep = "/"),
         plot = fig_att_per_iucn,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_pa.png", sep = "/"),
         plot = fig_att_pa,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_pa_iucn.png", sep = "/"),
         plot = fig_att_pa_iucn,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_fl.png", sep = "/"),
         plot = fig_att_fl,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_fl_iucn.png", sep = "/"),
         plot = fig_att_fl_iucn,
         device = "png",
         height = 6, width = 9)
  
  print(xtable(tbl_fc_att_pa, 
               type = "latex"),
        file = paste(tmp, "tbl_fc_att_pa.tex", sep = "/"))
  
  print(xtable(tbl_fc_att_per, type = "latex"),
        file = paste(tmp, "tbl_fc_att_per.tex", sep = "/"))
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
}


# Plotting the treatment effect of each protected area analyzed in the same graph. This function suits for all protected areas in general, and does not include any information on funding.
## INPUTS
### df_fc_att : a dataset with treatment effects for each protected area in the sample, expressed as avoided deforestation (hectare)
### df_fl_att : a dataset with treatment effects for each protected area in the sample, expressed as change in deforestation rate
### alpha : the threshold for confidence interval
### save_dir : the saving directory in the remote storage
## DATA SAVED
### Tables and figures : treatment effects computed for each protected area in the sample, expressed as avoided deforestaion (hectare and percentage of 2000 forest cover) and change in deforestation rate.
fn_plot_att_general = function(df_fc_att, df_fl_att, list_focus, alpha = alpha, save_dir)
{
  
  #list of PAs and two time periods
  list_ctry_plot = df_fc_att %>%
    dplyr::select(iso3, country_en, wdpaid, name_pa, iucn_cat, gov_type, own_type, treatment_year, status_wdpa) %>%
    unique() %>%
    group_by(iso3, country_en, wdpaid, name_pa) %>%
    summarize(time = c(5, 10),
              iucn_cat = iucn_cat,
              iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                    iucn_cat %in% c("V", "VI") ~ "Non strict",
                                    grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
              treatment_year = treatment_year,
              gov_type = gov_type,
              own_type = own_type,
              status_wdpa = status_wdpa) %>%
    ungroup()
  
  #treatment effect for each wdpa (some have not on the two time periods)
  temp_fc = df_fc_att %>%
    dplyr::select(c(region, iso3, country_en, wdpaid, name_pa, time, year, att_per, cband_lower_per, cband_upper_per, att_pa, cband_lower_pa, cband_upper_pa)) %>%
    mutate(sig_pa = sign(cband_lower_pa) == sign(cband_upper_pa),
           sig_per = sign(cband_lower_per) == sign(cband_upper_per)) %>%
    filter(time %in% c(5, 10)) 
  temp_fl = df_fl_att %>%
    dplyr::select(c(region, iso3, country_en, wdpaid, name_pa, time, year, att, cband_lower, cband_upper)) %>%
    mutate(sig = sign(cband_lower) == sign(cband_upper)) %>%
    filter(time %in% c(5, 10)) 
  
  #Att for each WDPAID, for each period (NA if no value)
  ## For figures
  df_plot_fc_att = left_join(list_ctry_plot, temp_fc, by = c("iso3", "country_en", "wdpaid", "name_pa", "time")) %>%
    mutate(focus = case_when(wdpaid %in% list_focus ~ "focus",
                             !(wdpaid %in% list_focus) ~ "not focus")) %>%
    group_by(time, country_en) %>%
    arrange(country_en, focus) %>%
    mutate(country_en = paste0(country_en, " (", row_number(), ")"),
           n = row_number()) %>%
    ungroup()
  
  df_plot_fl_att = left_join(list_ctry_plot, temp_fl, by = c("iso3", "country_en", "wdpaid", "name_pa", "time"))%>%
    mutate(focus = case_when(wdpaid %in% list_focus ~ "focus",
                             !(wdpaid %in% list_focus) ~ "not focus")) %>%
    group_by(time, country_en) %>%
    arrange(country_en, focus) %>%
    mutate(country_en = paste0(country_en, " (", row_number(), ")"),
           n = row_number()) %>%
    ungroup()
  
  
  #Plots
  names = c(`5` = "5 years after treatment",
            `10` = "10 years after treatment",
            `Strict` = "Strict\nIUCN cat. I-IV",
            `Non strict` = "Non strict\nIUCN V-VI",
            `Unknown` = "Unknown",
            `focus` = "FAPBM funded",
            `not focus` = "Others")
  # df_colors = df_plot_fc_att %>% group_by(n) %>% slice(1)
  # colors = ifelse(df_colors$wdpaid %in% list_focus,"#3182BD","black")
  
  ## Att in share of 2000 forest cover
  fig_att_per = ggplot(df_plot_fc_att, 
                       aes(x = att_per, 
                           y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                           xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           #caption = "FAPBM funded protected areas are in blue, others are in black.",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      #axis.text.y = element_text(color = rev(colors)),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )

  fig_att_per_focus_others = ggplot(df_plot_fc_att, 
                       aes(x = att_per, 
                           y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                           xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(focus~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_per_focus = ggplot(filter(df_plot_fc_att, focus == "focus"),
                                    aes(x = att_per, 
                                        y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                                        xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           subtitle = "Protected areas funded by the FAPBM only",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  
  fig_att_per_iucn = ggplot(df_plot_fc_att, 
                            aes(x = att_per, 
                                y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                                xmin = cband_lower_per, xmax = cband_upper_per)) %>%
    + geom_point(aes(color = sig_per)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_per)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    # + scale_x_continuous(breaks=seq(min(df_plot_fc_att$att_per, na.rm = TRUE),max(df_plot_fc_att$att_per, na.rm = TRUE),by=1)) %>%
    + facet_grid(iucn_wolf~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Deforestation avoided relative to 2000 forest cover",
           x = "%",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      #axis.text.y = element_text(color = rev(colors)),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  
  ##treatment effect : total deforestation avoided
  fig_att_pa = ggplot(df_plot_fc_att, 
                      aes(x = att_pa, 
                          y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                          xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_pa_focus_others = ggplot(df_plot_fc_att, 
                      aes(x = att_pa, 
                          y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                          xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(focus~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_pa_focus = ggplot(filter(df_plot_fc_att, focus == "focus"), 
                                   aes(x = att_pa, 
                                       y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                                       xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(focus~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           subtitle = "Protected areas funded by the FAPBM only",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_pa_iucn = ggplot(df_plot_fc_att, 
                           aes(x = att_pa, 
                               y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                               xmin = cband_lower_pa, xmax = cband_upper_pa)) %>%
    + geom_point(aes(color = sig_pa)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig_pa)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(iucn_wolf~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Total deforestation avoided",
           x = "ha",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  ##treatment effect : avoided deforestation in percentage points
  fig_att_fl = ggplot(df_plot_fl_att, 
                      aes(x = att, 
                          y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                          xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_fl_focus_others = ggplot(df_plot_fl_att, 
                      aes(x = att, 
                          y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                          xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(focus~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_fl_focus = ggplot(filter(df_plot_fl_att, focus == "focus"),
                                   aes(x = att, 
                                       y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                                       xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(focus~time,scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           subtitle = "Protected areas funded by the FAPBM only",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  fig_att_fl_iucn = ggplot(df_plot_fl_att, 
                           aes(x = att, 
                               y = factor(name_pa, levels = unique(rev(sort(name_pa)))),
                               xmin = cband_lower, xmax = cband_upper)) %>%
    + geom_point(aes(color = sig)) %>%
    + geom_vline(xintercept = 0) %>%
    + geom_errorbarh(aes(color = sig)) %>% 
    + scale_color_discrete(name = paste0("Significance\n(", (1-alpha)*100, "% level)"),
                           na.translate = F) %>%
    + facet_grid(iucn_wolf~time, scales="free", space="free",  labeller= as_labeller(names)) %>%
    + labs(title = "Reduction of deforestation due to the conservation",
           x = "p.p.",
           y = "") %>%
    + theme_minimal() %>%
    + theme(
      axis.text.x = element_text(angle = 0, hjust = 0.5, vjust = 0.5),
      axis.text=element_text(size=11, color = "black"),
      axis.title=element_text(size=14, color = "black", face = "plain"),
      
      plot.caption = element_text(hjust = 0),
      plot.title = element_text(size=16, color = "black", face = "plain", hjust = 0),
      plot.subtitle = element_text(size=12, color = "black", face = "plain", hjust = 0),
      
      strip.text = element_text(color = "black", size = 12),
      strip.clip = "off",
      panel.spacing = unit(2, "lines"),
      
      #legend.position = "bottom",
      legend.text=element_text(size=10),
      #legend.spacing.x = unit(1.0, 'cm'),
      #legend.spacing.y = unit(0.75, 'cm'),
      legend.key.size = unit(2, 'line'),
      
      panel.grid.major.x = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.x = element_line(color = 'grey80', linewidth = 0.2, linetype = 2),
      panel.grid.major.y = element_line(color = 'grey80', linewidth = 0.3, linetype = 1),
      panel.grid.minor.y = element_line(color = 'grey80', linewidth = 0.2, linetype = 2)
    )
  
  
  #Tables 
  ## treatment effect : percentage of deforestation avoided
  tbl_fc_att_per = df_plot_fc_att  %>%
    mutate(focus = case_when(wdpaid %in% list_focus ~ "Yes",
                             !(wdpaid %in% list_focus) ~ "No"),
           sig_per = case_when(sign(cband_lower_per) == sign(cband_upper_per) ~ "Yes",
                               sign(cband_lower_per) != sign(cband_upper_per) ~ "No"),
           iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                 iucn_cat %in% c("V", "VI") ~ "Non strict",
                                 grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
           name_pa = case_when(nchar(name_pa) <= 25 ~ stri_trans_general(name_pa, id = "Latin-ASCII"),
                               nchar(name_pa) > 25 ~ stri_trans_general(paste0(substr(name_pa, 1, 25), "..."),  id = "Latin-ASCII"))
    ) %>%
    dplyr::select(c(name_pa, focus, treatment_year, iucn_wolf, gov_type, time, att_per, sig_per)) %>%
    pivot_wider(values_from = c("att_per", "sig_per"), names_from = c("time", "time")) %>%
    dplyr::select(c(name_pa, focus, treatment_year, iucn_wolf, att_per_5, sig_per_5, att_per_10, sig_per_10)) %>%
    #dplyr::select(c(name_pa, country_en, treatment_year, iucn_wolf, gov_type, att_per_5, sig_per_5, att_per_10, sig_per_10)) %>%
    mutate(across(.cols = starts_with(c("att")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ as.character(format(round(x, 2), scientific = FALSE))))) %>%
    mutate(across(.cols = starts_with(c("sig")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ x))) %>%
    rename("Effect (5 y., %)" = "att_per_5",
           "Signi. (5 y.)" = "sig_per_5",
           "Effect (10 y., %)" = "att_per_10",
           "Signi. (10 y.)" = "sig_per_10") %>%
    arrange(focus, name_pa)
  # names(tbl_fc_att_per) = c("Name", "FAPBM", "Creation",  "Protection", 
  #                           "Governance", "Effect (5 y., %)", "Significance (5 y.)","Effect (10 y., %)", "Significance (10 y.)")
  names(tbl_fc_att_per) = c("Name", "FAPBM", "Creation", "Protection", 
                            "Effect (5 y., %)", "Signi. (5 y.)","Effect (10 y., %)", "Signi. (10 y.)")
  
  # treatment effect : total deforestation avoided 
  tbl_fc_att_pa = df_plot_fc_att %>%
    mutate(focus = case_when(wdpaid %in% list_focus ~ "Yes",
                             !(wdpaid %in% list_focus) ~ "No"),
           sig_pa = case_when(sign(cband_lower_pa) == sign(cband_upper_pa) ~ "Yes",
                              sign(cband_lower_pa) != sign(cband_upper_pa) ~ "No"),
           iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                 iucn_cat %in% c("V", "VI") ~ "Non strict",
                                 grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
           name_pa = case_when(nchar(name_pa) <= 25 ~ stri_trans_general(name_pa, id = "Latin-ASCII"),
                               nchar(name_pa) > 25 ~ stri_trans_general(paste0(substr(name_pa, 1, 25), "..."),  id = "Latin-ASCII"))
    ) %>%
    dplyr::select(c(name_pa, focus, country_en, treatment_year, iucn_wolf, gov_type, time, att_pa, sig_pa)) %>%
    pivot_wider(values_from = c("att_pa", "sig_pa"), names_from = c("time", "time")) %>%
    # dplyr::select(c(name_pa, country_en, treatment_year, iucn_wolf, gov_type, att_pa_5, sig_pa_5, att_pa_10, sig_pa_10)) %>%
    dplyr::select(c(name_pa, focus, treatment_year, iucn_wolf, att_pa_5, sig_pa_5, att_pa_10, sig_pa_10)) %>%
    mutate(across(.cols = starts_with(c("att")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ as.character(format(round(x, 2), scientific = FALSE))))) %>%
    mutate(across(.cols = starts_with(c("sig")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ x))) %>%
    rename("Effect (5 y., %)" = "att_pa_5",
           "Signi. (5 y.)" = "sig_pa_5",
           "Effect (10 y., %)" = "att_pa_10",
           "Signi. (10 y.)" = "sig_pa_10") %>%
  arrange(focus, name_pa)
  # names(tbl_fc_att_pa) = c("Name", "FAPBM", "Creation",  "Protection", 
  #                           "Governance", "Effect (5 y., ha)", "Significance (5 y.)","Effect (10 y., ha)", "Significance (10 y.)")
  names(tbl_fc_att_pa) = c("Name", "FAPBM", "Creation", "Protection", 
                            "Effect (5 y., ha)", "Signi. (5 y.)","Effect (10 y., ha)", "Signi. (10 y.)")
  
  # treatment effect : avoided deforestation, in terms of difference in cumultaed deforestation rate 
  tbl_fl_att = df_plot_fl_att %>%
    mutate(focus = case_when(wdpaid %in% list_focus ~ "Yes",
                             !(wdpaid %in% list_focus) ~ "No"),
           sig = case_when(sign(cband_lower) == sign(cband_upper) ~ "Yes",
                              sign(cband_lower) != sign(cband_upper) ~ "No"),
           iucn_wolf = case_when(iucn_cat %in% c("I", "II", "III", "IV") ~ "Strict",
                                 iucn_cat %in% c("V", "VI") ~ "Non strict",
                                 grepl("not", iucn_cat, ignore.case = TRUE) ~ "Unknown"),
           name_pa = case_when(nchar(name_pa) <= 25 ~ stri_trans_general(name_pa, id = "Latin-ASCII"),
                               nchar(name_pa) > 25 ~ stri_trans_general(paste0(substr(name_pa, 1, 25), "..."),  id = "Latin-ASCII"))
    ) %>%
    dplyr::select(c(name_pa, focus, country_en, treatment_year, iucn_wolf, gov_type, time, att, sig)) %>%
    pivot_wider(values_from = c("att", "sig"), names_from = c("time", "time")) %>%
    # dplyr::select(c(name_pa, country_en, treatment_year, iucn_wolf, gov_type, att_5, sig_5, att_10, sig_10)) %>%
    dplyr::select(c(name_pa, focus, treatment_year, iucn_wolf, att_5, sig_5, att_10, sig_10)) %>%
    mutate(across(.cols = starts_with(c("att")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ as.character(format(round(x, 2), scientific = FALSE))))) %>%
    mutate(across(.cols = starts_with(c("sig")),
                  .fns = \(x) case_when(is.na(x) == TRUE ~ "/", TRUE ~ x))) %>%
    rename("Effect (5 y., %)" = "att_5",
           "Signi. (5 y.)" = "sig_5",
           "Effect (10 y., %)" = "att_10",
           "Signi. (10 y.)" = "sig_10") %>%
    arrange(focus, name_pa)
  # names(tbl_fl_att) = c("Name", "FAPBM", "Creation",  "Protection", 
  #                           "Governance", "Effect (5 y., pp)", "Significance (5 y.)","Effect (10 y., pp)", "Significance (10 y.)")
  names(tbl_fl_att) = c("Name", "FAPBM", "Creation", "Protection", 
                           "Effect (5 y., pp)", "Signi. (5 y.)","Effect (10 y., pp)", "Signi. (10 y.)")
  
  #Saving plots
  
  ##Saving plots
  tmp = paste(tempdir(), "fig", sep = "/")
  
  ggsave(paste(tmp, "fig_att_per.png", sep = "/"),
         plot = fig_att_per,
         device = "png",
         height = 8, width = 12)

  ggsave(paste(tmp, "fig_att_per_focus.png", sep = "/"),
         plot = fig_att_per_focus,
         device = "png",
         height = 6, width =9)
  
  ggsave(paste(tmp, "fig_att_per_focus_others.png", sep = "/"),
         plot = fig_att_per_focus_others,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_per_iucn.png", sep = "/"),
         plot = fig_att_per_iucn,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_pa.png", sep = "/"),
         plot = fig_att_pa,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_pa_focus.png", sep = "/"),
         plot = fig_att_pa_focus,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_pa_focus_others.png", sep = "/"),
         plot = fig_att_pa_focus_others,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_pa_iucn.png", sep = "/"),
         plot = fig_att_pa_iucn,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_fl.png", sep = "/"),
         plot = fig_att_fl,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_fl_focus.png", sep = "/"),
         plot = fig_att_fl_focus,
         device = "png",
         height = 6, width = 9)
  
  ggsave(paste(tmp, "fig_att_fl_focus_others.png", sep = "/"),
         plot = fig_att_fl_focus_others,
         device = "png",
         height = 8, width = 12)
  
  ggsave(paste(tmp, "fig_att_fl_iucn.png", sep = "/"),
         plot = fig_att_fl_iucn,
         device = "png",
         height = 8, width = 12)
  
  print(xtable(tbl_fc_att_pa, type = "latex", auto = T),
        file = paste(tmp, "tbl_fc_att_pa.tex", sep = "/"))
  
  print(xtable(tbl_fc_att_per, type = "latex", auto = T),
        file = paste(tmp, "tbl_fc_att_per.tex", sep = "/"))
  
  print(xtable(tbl_fl_att, type = "latex", auto = T),
        file = paste(tmp, "tbl_fl_att.tex", sep = "/"))
  
  files <- list.files(tmp, full.names = TRUE)
  ##Add each file in the bucket (same foler for every file in the temp)
  for(f in files) 
  {
    cat("Uploading file", paste0("'", f, "'"), "\n")
    aws.s3::put_object(file = f, 
                       bucket = paste("projet-afd-eva-ap", save_dir, sep = "/"),
                       region = "", show_progress = TRUE)
  }
  do.call(file.remove, list(list.files(tmp, full.names = TRUE)))
}

```


<!--chapter:end:appendix.Rmd-->

# Introduction

## Test 

blabliblo

<!--chapter:end:introduction.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:references.Rmd-->

